{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1574547513068,
     "user": {
      "displayName": "daniela thyssens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAjESWh9r_JpJu7Y-DtgOWeyh4Y6Cw-yuE0sVSv5Q=s64",
      "userId": "06737456205702308294"
     },
     "user_tz": -60
    },
    "id": "PuuRX58dsI_3",
    "outputId": "1a65fb6b-bc9f-4781-ca2f-97b271ef54b6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVbzKDghsFuf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version\n",
    "#Import Libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "from random import shuffle\n",
    "#TF Version\n",
    "tf.__version__\n",
    "\n",
    "#with warnings.catch_warnings():\n",
    "#    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "#    import h5py\n",
    "\n",
    "##### Prediction Params #####\n",
    "num_periods_output = 2    #to predict\n",
    "num_periods_input = 4       #input\n",
    "#num_periods = 4           #number of periods per vector we are using to predict one period ahead\n",
    "\n",
    "\n",
    "ALL_Test_Data=[]\n",
    "ALL_Test_Prediction=[]\n",
    "Event_Based_StartIndex=11\n",
    "Number_of_EventBased=4\n",
    "Number_of_TimeFeatures=11\n",
    "\n",
    "\n",
    "No_Of_weeks=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VWsYwOysFuq"
   },
   "source": [
    "<h5>Preprocessing data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnP7bj4HsFut"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def preprocessing(df_,num_features):\n",
    "    # get year, month,Day,Hour,Minute\n",
    "    df_['LastUpdated'] = pd.to_datetime(df_['LastUpdated'])\n",
    "    df_['Year'] = df_['LastUpdated'].dt.year\n",
    "    df_['Month'] = df_['LastUpdated'].dt.month\n",
    "    df_['Day'] = df_['LastUpdated'].dt.day\n",
    "    df_['Hour'] = df_['LastUpdated'].dt.hour\n",
    "    df_['Minute'] = df_['LastUpdated'].dt.minute\n",
    "    \n",
    "    #,'Month','Day','Hour','Minute'\n",
    "    # select features\n",
    "    df=df_[['ID','Occ_percent','Month','Day','Hour','Minute',\n",
    "           'temperature','dew_point','humidity','wind_speed',\n",
    "           'feels_like','Events_Football_City','Events_Football_Derby',\n",
    "           'Events_Football_Aston','Events_Rugby']]\n",
    "    \n",
    "    '''df_=df[['ID','Occupancy','Year', 'Month', 'Day', 'Hour','Minute', 'Capacity', \n",
    "    'DayOfWeek','IsWeekend', 'temperature', 'dew_point', 'humidity', 'wind_speed', \n",
    "    'feels_like', 'Status', 'light_snow','snow_shower', 'fog', \n",
    "    'thunder', 'mostly_cloudy','rain', 'heavy_rain', 'mist', 'shallow_fog','light_freezing_rain',\n",
    "    'partly_cloudy', 'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower']]'''\n",
    "    \n",
    "    \n",
    "    ################################################encoding########################\n",
    "    df['Occ_percent'] = pd.to_numeric(df['Occ_percent'],errors='coerce')\n",
    "    df['Occ_percent'] = df['Occ_percent'].abs()\n",
    "    \n",
    "    \n",
    "    Number_Of_Features=num_features\n",
    "    df=df.values\n",
    "    df = df.astype('float32')\n",
    "    split=num_periods_output+num_periods_input\n",
    "    \n",
    "    \n",
    "    ##################################SPLIT##############################################\n",
    "    print('LEN DF BEFORE CUTTING ANYTHING',len(df))\n",
    "     ########################## SPLITTING FOR TESTING & VALIDATION ##########################\n",
    "    #test_len=np.floor(len(df)*0.2)\n",
    "    test_val_len=np.floor(len(df)*0.2)\n",
    "    #mod=test_len%(num_periods_input+num_periods_output)\n",
    "    mod=test_val_len%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    test_val_len=int(test_val_len-mod)\n",
    "    Test_Val=df[(len(df)-test_val_len):,:]\n",
    "    \n",
    "    ############################ VALIDATION & TESTING ##################################\n",
    "    valid_len=np.floor(len(Test_Val)*0.5)\n",
    "    Valid=Test_Val[0:(len(Test_Val)-int(valid_len)),:]\n",
    "    Test=Test_Val[(len(Test_Val)-int(valid_len)):,:]\n",
    "    \n",
    "    ########################### SPLITTING FOR TRAIN ###########################\n",
    "    \n",
    "    new_cutted_df=df[:(len(df)-test_val_len),:]\n",
    "    Start_train_index=17*7*No_Of_weeks\n",
    "    #=2*24*7*No_Of_weeks\n",
    "    #Start_train_index=12*24*1 # 1 day\n",
    "    Start_train_index=np.floor(Start_train_index)\n",
    "    Start_train_index=int(Start_train_index)\n",
    "    print('instances',Start_train_index)\n",
    "    Train=new_cutted_df[len(new_cutted_df)-Start_train_index:,:]\n",
    "    print('len new_cutted - start_train_ind',len(new_cutted_df)-Start_train_index)\n",
    "    train_len=len(Train)\n",
    "    mod=train_len%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    train_len=int(train_len-mod)\n",
    "    Train=Train[0:train_len,:]\n",
    "    print('len Train',len(Train))\n",
    "   \n",
    "        \n",
    "    #############################  Normalization on train and validation separatly  #############\n",
    "     \n",
    "    ID_Train=Train[:,0]\n",
    "    Train=np.delete(Train,[0],1)\n",
    "    #x_batches=x_batches.drop(columns=['ID'], axis=1)\n",
    "    occ_Train=Train[:,0]\n",
    "    Train=np.delete(Train,[0],1)\n",
    "    #x_batches=x_batches.drop(columns=['Occupancy'], axis=1)\n",
    "    #normalizing data\n",
    "    Train = Train.astype('float32')\n",
    "    normalizer = Normalizer().fit(Train)\n",
    "    Train=normalizer.transform(Train)\n",
    "    \n",
    "    ID_Valid=Valid[:,0]\n",
    "    Valid=np.delete(Valid,[0],1)\n",
    "    #X_test=X_test.drop(columns=['ID'], axis=1)\n",
    "    occ_Valid=Valid[:,0]\n",
    "    Valid=np.delete(Valid,[0],1)\n",
    "    #X_test=X_test.drop(columns=['Occupancy'], axis=1)\n",
    "    Valid = Valid.astype('float32')\n",
    "    Valid=normalizer.transform(Valid)\n",
    "    #------------------\n",
    "    ID_Train=np.reshape(ID_Train,(len(ID_Train),1))\n",
    "    occ_Train=np.reshape(occ_Train,(len(occ_Train),1))\n",
    "    \n",
    "    Train=np.append(occ_Train, Train, axis=1)\n",
    "    Train=np.append(ID_Train, Train, axis=1)\n",
    "    #------------------\n",
    "    ID_Valid=np.reshape(ID_Valid,(len(ID_Valid),1))\n",
    "    occ_Valid=np.reshape(occ_Valid,(len(occ_Valid),1))\n",
    "    \n",
    "    Valid=np.append(occ_Valid,Valid, axis=1)\n",
    "    Valid=np.append(ID_Valid, Valid, axis=1)\n",
    "\n",
    "    ############################################ TRAIN minibatches ##################################\n",
    "    \n",
    "    end=len(Train)\n",
    "    start=0\n",
    "    next=0\n",
    "    x_batches=[]\n",
    "    y_batches=[]\n",
    "    \n",
    "    count=0\n",
    "    #print('lennnn',len(Train))\n",
    "    while next+(num_periods_input+num_periods_output)<end:\n",
    "        next=start+num_periods_input\n",
    "        x_batches.append(Train[start:next,:])\n",
    "        y_batches.append(Train[next:next+num_periods_output,1])\n",
    "        start=start+1\n",
    "    y_batches=np.asarray(y_batches)\n",
    "    y_batches = y_batches.reshape(-1, num_periods_output, 1)   \n",
    "    x_batches=np.asarray(x_batches)\n",
    "    x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
    "    print('len x_batches ',len(x_batches))\n",
    "    \n",
    "    ############################################ VALID minibatches ##################################\n",
    "    \n",
    "    end_val=len(Valid)\n",
    "    start_val=0\n",
    "    next_val=0\n",
    "    x_validbatches=[]\n",
    "    y_validbatches=[]\n",
    "    \n",
    "    while next_val+(num_periods_input+num_periods_output)<end_val:\n",
    "        next_val=start_val+num_periods_input\n",
    "        x_validbatches.append(Valid[start_val:next_val,:])\n",
    "        y_validbatches.append(Valid[next_val:next_val+num_periods_output,1])\n",
    "        start_val=start_val+1\n",
    "    y_validbatches=np.asarray(y_validbatches)\n",
    "    y_validbatches = y_validbatches.reshape(-1, num_periods_output, 1)   \n",
    "    x_validbatches=np.asarray(x_validbatches)\n",
    "    x_validbatches = x_validbatches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
    "\n",
    "    ###########################################TEST#####################################\n",
    "    \n",
    "    ID_Test=Test[:,0]\n",
    "    Test=np.delete(Test,[0],1)\n",
    "    #X_test=X_test.drop(columns=['ID'], axis=1)\n",
    "    occ_Test=Test[:,0]\n",
    "    Test=np.delete(Test,[0],1)\n",
    "    #X_test=X_test.drop(columns=['Occupancy'], axis=1)\n",
    "    Test = Test.astype('float32')\n",
    "    Test=normalizer.transform(Test)\n",
    "    \n",
    "    #------------------\n",
    "    ID_Test=np.reshape(ID_Test,(len(ID_Test),1))\n",
    "    occ_Test=np.reshape(occ_Test,(len(occ_Test),1))\n",
    "    \n",
    "    Test=np.append(occ_Test,Test, axis=1)\n",
    "    Test=np.append(ID_Test, Test, axis=1)\n",
    "    \n",
    "    ############################################ TEST minibatches ##################################\n",
    "    end_test=len(Test)\n",
    "    start_test=0\n",
    "    next_test=0\n",
    "    x_testbatches=[]\n",
    "    y_testbatches=[]\n",
    "    \n",
    "    \n",
    "    #print('lennnn',len(Train))\n",
    "    while next_test+(num_periods_input+num_periods_output)<end_test:\n",
    "        next_test=start_test+num_periods_input\n",
    "        x_testbatches.append(Test[start_test:next_test,:])\n",
    "        y_testbatches.append(Test[next_test:next_test+num_periods_output,1])\n",
    "        start_test=start_test+1\n",
    "    y_testbatches=np.asarray(y_testbatches)\n",
    "    y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)   \n",
    "    x_testbatches=np.asarray(x_testbatches)\n",
    "    x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features) \n",
    "    print('len Test',len(Test))\n",
    "    print('len xTestbatches',len(x_testbatches))\n",
    "    ######################## Sampling##########################################\n",
    "    \n",
    "    #x_batches, y_batches, x_validbatches, y_validbatches, x_testbatches, y_testbatches\n",
    "    \n",
    "    return x_batches, y_batches,x_validbatches, y_validbatches, x_testbatches, y_testbatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmhRJEHVsFu1"
   },
   "outputs": [],
   "source": [
    "def load_locationfiles(path,loc_id):\n",
    "    filename=path + '/Birm'+str(loc_id)+'.csv'\n",
    "    print(filename)\n",
    "    data_loc=pd.read_csv(filename)\n",
    "    #mod=len(data_loc)%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    #data_loc=data_loc[:len(data_loc)-mod]\n",
    "    return data_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MYuE1zOsFu8"
   },
   "source": [
    "# Creating Tensorflow Graph + Run Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKje0imlsFu_"
   },
   "source": [
    "##### Training Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nso4-lghsFvB"
   },
   "outputs": [],
   "source": [
    "\n",
    "##### Graph Params #####\n",
    "inputs = Number_of_TimeFeatures-1                #number of vectors submitted\n",
    "hidden = 128               #number of neurons we will recursively work through, can be changed to improve accuracy\n",
    "hidden_event=128\n",
    "output = 1                 #number of output vectors\n",
    "num_layers=1\n",
    "num_layers_EventBased=1\n",
    "\n",
    "##### Static Features #####\n",
    "Number_Of_Static_Features=30\n",
    "no_sequences=128            #re-iterating factor for static features\n",
    "\n",
    "##### Optimization Params #####\n",
    "batchsize=128\n",
    "#init_epoch=3              #number of epochs using the constant init_learning_rate\n",
    "#initial_LR=0.0003\n",
    "#learning_rate_decay=0.95\n",
    "l_rate = 0.00005        #small learning rate so we don't overshoot the minimum\n",
    "keep_prob_static=0.7       #number of epochs using the constant init_learning_rate\n",
    "keep_prob_event=0.7\n",
    "lamda=0.01                #regularization param \n",
    "keep_probab=0.9            #(1-dropout_rate)\n",
    "keep_prob_testval=1.0      #(1-dropout_rate) for testing and validation runs\n",
    "epochs = 500                #number of iterations or training cycles, includes both the FeedFoward and Backpropogation\n",
    "\n",
    "#where to save logs\n",
    "#logs_path = '/tmp/tf_logs_3_LSTM_Fully_0410_ConnEnd_Shift_FSTop3/example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkLBQDYosFvI"
   },
   "outputs": [],
   "source": [
    "# model decaying learning rate, instead of fixed one\n",
    "#def compute_LR(init_epoch,max_epoch,learning_rate_decay,init_learning_rate):\n",
    "#    LR_to_use = [\n",
    "#        init_learning_rate * (\n",
    "#            learning_rate_decay ** max(float(i+1-init_epoch),0.0)\n",
    "#        ) for i in range(max_epoch)\n",
    "#    ]\n",
    "#    print(\"Middle LR:\", LR_to_use[len(LR_to_use) // 2])\n",
    "#    return LR_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdKqxvb4Vcbl"
   },
   "outputs": [],
   "source": [
    "IDs=np.arange(30)\n",
    "Static_Features=np.zeros((30,30))\n",
    "Static_Features[np.arange(30),IDs]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IWGs1v9usFvO",
    "outputId": "0a6f4366-991c-46ea-e184-db7d219846c4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-3310d53d9a8d>:25: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-8-3310d53d9a8d>:27: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-8-3310d53d9a8d>:37: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-3310d53d9a8d>:41: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-3310d53d9a8d>:43: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Time/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0 is illegal; using Time/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Time/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0 is illegal; using Time/rnn/multi_rnn_cell/cell_0/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Time/dense/kernel:0 is illegal; using Time/dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Time/dense/bias:0 is illegal; using Time/dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Event/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0 is illegal; using Event/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Event/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0 is illegal; using Event/rnn/multi_rnn_cell/cell_0/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Event/dense/kernel:0 is illegal; using Event/dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Event/dense/bias:0 is illegal; using Event/dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm1.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm2.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1276\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 352\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 126\n",
      "len xTestbatches 117\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm3.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1294\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 364\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm4.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm5.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 280\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm6.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 280\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm7.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 280\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm9.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm10.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1276\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 352\n",
      "len Train 672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len x_batches  663\n",
      "len Test 126\n",
      "len xTestbatches 117\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm11.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm12.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm13.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1292\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 362\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm14.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1038\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 162\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 102\n",
      "len xTestbatches 93\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm15.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm16.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1291\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 361\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm17.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 280\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm18.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm19.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 280\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm20.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1204\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 292\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 120\n",
      "len xTestbatches 111\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm22.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1204\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 292\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 120\n",
      "len xTestbatches 111\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm23.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm24.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm25.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1294\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 364\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm26.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm27.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm28.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm29.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm30.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 672\n",
      "len new_cutted - start_train_ind 382\n",
      "len Train 672\n",
      "len x_batches  663\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "\tRMSE Training: [49.066086]\n",
      "\tRMSE Validation: [41.35277]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 4\n",
      "\tRMSE Training: [14.294062]\n",
      "\tRMSE Validation: [13.731796]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 7\n",
      "\tRMSE Training: [11.951228]\n",
      "\tRMSE Validation: [11.450155]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 10\n",
      "\tRMSE Training: [10.660618]\n",
      "\tRMSE Validation: [10.252465]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 13\n",
      "\tRMSE Training: [10.052449]\n",
      "\tRMSE Validation: [9.6820345]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 16\n",
      "\tRMSE Training: [9.772356]\n",
      "\tRMSE Validation: [9.386697]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 19\n",
      "\tRMSE Training: [9.542956]\n",
      "\tRMSE Validation: [9.200353]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 22\n",
      "\tRMSE Training: [9.396561]\n",
      "\tRMSE Validation: [9.100972]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 25\n",
      "\tRMSE Training: [9.330906]\n",
      "\tRMSE Validation: [9.071038]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 28\n",
      "\tRMSE Training: [9.209227]\n",
      "\tRMSE Validation: [8.99472]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 31\n",
      "\tRMSE Training: [9.009544]\n",
      "\tRMSE Validation: [8.874805]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 34\n",
      "\tRMSE Training: [8.922005]\n",
      "\tRMSE Validation: [8.806299]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 37\n",
      "\tRMSE Training: [8.882729]\n",
      "\tRMSE Validation: [8.760379]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 40\n",
      "\tRMSE Training: [8.81289]\n",
      "\tRMSE Validation: [8.655082]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 43\n",
      "\tRMSE Training: [8.718748]\n",
      "\tRMSE Validation: [8.719546]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 46\n",
      "\tRMSE Training: [8.6589575]\n",
      "\tRMSE Validation: [8.5179825]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 49\n",
      "\tRMSE Training: [8.6106415]\n",
      "\tRMSE Validation: [8.5014925]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 52\n",
      "\tRMSE Training: [8.567939]\n",
      "\tRMSE Validation: [8.462554]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 55\n",
      "\tRMSE Training: [8.488003]\n",
      "\tRMSE Validation: [8.385783]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 58\n",
      "\tRMSE Training: [8.445883]\n",
      "\tRMSE Validation: [8.5024185]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 61\n",
      "\tRMSE Training: [8.411686]\n",
      "\tRMSE Validation: [8.226861]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 64\n",
      "\tRMSE Training: [8.321441]\n",
      "\tRMSE Validation: [8.221233]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 67\n",
      "\tRMSE Training: [8.322675]\n",
      "\tRMSE Validation: [8.364351]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 70\n",
      "\tRMSE Training: [8.211171]\n",
      "\tRMSE Validation: [8.074013]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 73\n",
      "\tRMSE Training: [8.170731]\n",
      "\tRMSE Validation: [8.17183]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 76\n",
      "\tRMSE Training: [8.187797]\n",
      "\tRMSE Validation: [8.050008]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 79\n",
      "\tRMSE Training: [8.146056]\n",
      "\tRMSE Validation: [8.014384]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 82\n",
      "\tRMSE Training: [8.222186]\n",
      "\tRMSE Validation: [8.029288]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 85\n",
      "\tRMSE Training: [8.123961]\n",
      "\tRMSE Validation: [8.087509]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 88\n",
      "\tRMSE Training: [8.063706]\n",
      "\tRMSE Validation: [7.9242716]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 91\n",
      "\tRMSE Training: [8.127324]\n",
      "\tRMSE Validation: [7.957433]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 94\n",
      "\tRMSE Training: [8.102113]\n",
      "\tRMSE Validation: [8.124081]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 97\n",
      "\tRMSE Training: [8.037439]\n",
      "\tRMSE Validation: [8.487686]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 100\n",
      "\tRMSE Training: [8.018651]\n",
      "\tRMSE Validation: [7.9141026]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 103\n",
      "\tRMSE Training: [8.10134]\n",
      "\tRMSE Validation: [8.231985]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 106\n",
      "\tRMSE Training: [8.015282]\n",
      "\tRMSE Validation: [7.998142]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 109\n",
      "\tRMSE Training: [8.015309]\n",
      "\tRMSE Validation: [7.9481854]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 112\n",
      "\tRMSE Training: [8.05014]\n",
      "\tRMSE Validation: [7.941263]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 115\n",
      "\tRMSE Training: [8.017381]\n",
      "\tRMSE Validation: [7.9204373]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 118\n",
      "\tRMSE Training: [7.9900827]\n",
      "\tRMSE Validation: [7.9568357]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 121\n",
      "\tRMSE Training: [7.9211082]\n",
      "\tRMSE Validation: [8.076359]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 124\n",
      "\tRMSE Training: [7.9023137]\n",
      "\tRMSE Validation: [7.9114943]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 127\n",
      "\tRMSE Training: [7.978148]\n",
      "\tRMSE Validation: [7.975491]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 130\n",
      "\tRMSE Training: [7.9006777]\n",
      "\tRMSE Validation: [7.840807]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 133\n",
      "\tRMSE Training: [7.9420643]\n",
      "\tRMSE Validation: [7.9728293]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 136\n",
      "\tRMSE Training: [7.911767]\n",
      "\tRMSE Validation: [7.960689]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 139\n",
      "\tRMSE Training: [7.916719]\n",
      "\tRMSE Validation: [7.9667487]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 142\n",
      "\tRMSE Training: [7.951831]\n",
      "\tRMSE Validation: [7.9012527]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 145\n",
      "\tRMSE Training: [7.96149]\n",
      "\tRMSE Validation: [8.266356]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 148\n",
      "\tRMSE Training: [7.9927263]\n",
      "\tRMSE Validation: [8.300432]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 151\n",
      "\tRMSE Training: [7.8479085]\n",
      "\tRMSE Validation: [7.761196]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 154\n",
      "\tRMSE Training: [7.945396]\n",
      "\tRMSE Validation: [7.8655987]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 157\n",
      "\tRMSE Training: [7.875052]\n",
      "\tRMSE Validation: [7.699923]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 160\n",
      "\tRMSE Training: [7.8754697]\n",
      "\tRMSE Validation: [7.8396435]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 163\n",
      "\tRMSE Training: [7.89151]\n",
      "\tRMSE Validation: [7.7783575]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 166\n",
      "\tRMSE Training: [7.8418646]\n",
      "\tRMSE Validation: [8.165254]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 169\n",
      "\tRMSE Training: [7.8251214]\n",
      "\tRMSE Validation: [7.976941]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 172\n",
      "\tRMSE Training: [7.9542766]\n",
      "\tRMSE Validation: [7.899788]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 175\n",
      "\tRMSE Training: [7.828413]\n",
      "\tRMSE Validation: [7.9555697]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 178\n",
      "\tRMSE Training: [7.9469237]\n",
      "\tRMSE Validation: [7.903995]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 181\n",
      "\tRMSE Training: [7.858464]\n",
      "\tRMSE Validation: [9.589686]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 184\n",
      "\tRMSE Training: [7.7305446]\n",
      "\tRMSE Validation: [7.692303]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 187\n",
      "\tRMSE Training: [7.8876925]\n",
      "\tRMSE Validation: [7.760326]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 190\n",
      "\tRMSE Training: [7.8326764]\n",
      "\tRMSE Validation: [7.635787]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 193\n",
      "\tRMSE Training: [7.7974114]\n",
      "\tRMSE Validation: [8.229474]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 196\n",
      "\tRMSE Training: [7.7485504]\n",
      "\tRMSE Validation: [8.084963]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 199\n",
      "\tRMSE Training: [7.859313]\n",
      "\tRMSE Validation: [7.6345196]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 202\n",
      "\tRMSE Training: [7.777076]\n",
      "\tRMSE Validation: [7.702294]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 205\n",
      "\tRMSE Training: [7.8293586]\n",
      "\tRMSE Validation: [7.890835]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 208\n",
      "\tRMSE Training: [7.823549]\n",
      "\tRMSE Validation: [7.8540783]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 211\n",
      "\tRMSE Training: [7.880826]\n",
      "\tRMSE Validation: [7.7994394]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 214\n",
      "\tRMSE Training: [7.7987223]\n",
      "\tRMSE Validation: [7.687534]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 217\n",
      "\tRMSE Training: [7.796707]\n",
      "\tRMSE Validation: [7.756958]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 220\n",
      "\tRMSE Training: [7.7743464]\n",
      "\tRMSE Validation: [7.6896567]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 223\n",
      "\tRMSE Training: [7.8234744]\n",
      "\tRMSE Validation: [7.758965]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 226\n",
      "\tRMSE Training: [7.8527265]\n",
      "\tRMSE Validation: [7.6455703]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 229\n",
      "\tRMSE Training: [7.841109]\n",
      "\tRMSE Validation: [8.055523]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 232\n",
      "\tRMSE Training: [7.774371]\n",
      "\tRMSE Validation: [8.070633]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 235\n",
      "\tRMSE Training: [7.7748575]\n",
      "\tRMSE Validation: [7.775296]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 238\n",
      "\tRMSE Training: [7.7515]\n",
      "\tRMSE Validation: [7.788625]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 241\n",
      "\tRMSE Training: [7.7218623]\n",
      "\tRMSE Validation: [8.206772]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 244\n",
      "\tRMSE Training: [7.7714977]\n",
      "\tRMSE Validation: [7.630397]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 247\n",
      "\tRMSE Training: [7.8672705]\n",
      "\tRMSE Validation: [8.023381]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 250\n",
      "\tRMSE Training: [7.7677937]\n",
      "\tRMSE Validation: [7.8322206]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 253\n",
      "\tRMSE Training: [7.7665405]\n",
      "\tRMSE Validation: [7.6499076]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 256\n",
      "\tRMSE Training: [7.6833353]\n",
      "\tRMSE Validation: [7.76853]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 259\n",
      "\tRMSE Training: [7.820436]\n",
      "\tRMSE Validation: [7.6414695]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 262\n",
      "\tRMSE Training: [7.772383]\n",
      "\tRMSE Validation: [7.7201056]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 265\n",
      "\tRMSE Training: [7.760231]\n",
      "\tRMSE Validation: [8.185892]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 268\n",
      "\tRMSE Training: [7.691002]\n",
      "\tRMSE Validation: [7.5494423]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 271\n",
      "\tRMSE Training: [7.747016]\n",
      "\tRMSE Validation: [7.6631775]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 274\n",
      "\tRMSE Training: [7.799616]\n",
      "\tRMSE Validation: [8.567989]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 277\n",
      "\tRMSE Training: [7.74002]\n",
      "\tRMSE Validation: [7.6592636]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 280\n",
      "\tRMSE Training: [7.7463536]\n",
      "\tRMSE Validation: [7.863754]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 283\n",
      "\tRMSE Training: [7.7565417]\n",
      "\tRMSE Validation: [7.649195]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 286\n",
      "\tRMSE Training: [7.705023]\n",
      "\tRMSE Validation: [8.126752]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 289\n",
      "\tRMSE Training: [7.7504315]\n",
      "\tRMSE Validation: [7.5895267]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 292\n",
      "\tRMSE Training: [7.792789]\n",
      "\tRMSE Validation: [7.763536]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 295\n",
      "\tRMSE Training: [7.7551103]\n",
      "\tRMSE Validation: [7.7689033]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 298\n",
      "\tRMSE Training: [7.714961]\n",
      "\tRMSE Validation: [7.8154774]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 301\n",
      "\tRMSE Training: [7.6677494]\n",
      "\tRMSE Validation: [8.082709]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 304\n",
      "\tRMSE Training: [7.7879]\n",
      "\tRMSE Validation: [7.9084907]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 307\n",
      "\tRMSE Training: [7.6941986]\n",
      "\tRMSE Validation: [7.6773944]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 310\n",
      "\tRMSE Training: [7.6984057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRMSE Validation: [7.6058416]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 313\n",
      "\tRMSE Training: [7.7201157]\n",
      "\tRMSE Validation: [7.7059407]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 316\n",
      "\tRMSE Training: [7.750629]\n",
      "\tRMSE Validation: [7.91846]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 319\n",
      "\tRMSE Training: [7.6882486]\n",
      "\tRMSE Validation: [7.667133]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 322\n",
      "\tRMSE Training: [7.735918]\n",
      "\tRMSE Validation: [7.8455834]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 325\n",
      "\tRMSE Training: [7.7277813]\n",
      "\tRMSE Validation: [7.692596]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 328\n",
      "\tRMSE Training: [7.706473]\n",
      "\tRMSE Validation: [7.841278]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 331\n",
      "\tRMSE Training: [7.693598]\n",
      "\tRMSE Validation: [8.14445]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 334\n",
      "\tRMSE Training: [7.7001433]\n",
      "\tRMSE Validation: [7.5492144]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 337\n",
      "\tRMSE Training: [7.7473264]\n",
      "\tRMSE Validation: [7.752311]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 340\n",
      "\tRMSE Training: [7.622212]\n",
      "\tRMSE Validation: [8.490829]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 343\n",
      "\tRMSE Training: [7.7255483]\n",
      "\tRMSE Validation: [7.71131]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 346\n",
      "\tRMSE Training: [7.7322645]\n",
      "\tRMSE Validation: [7.6216903]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 349\n",
      "\tRMSE Training: [7.6935153]\n",
      "\tRMSE Validation: [7.683495]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 352\n",
      "\tRMSE Training: [7.697453]\n",
      "\tRMSE Validation: [7.6202154]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 355\n",
      "\tRMSE Training: [7.6770616]\n",
      "\tRMSE Validation: [7.813396]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 358\n",
      "\tRMSE Training: [7.8602676]\n",
      "\tRMSE Validation: [7.7553635]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 361\n",
      "\tRMSE Training: [7.632017]\n",
      "\tRMSE Validation: [7.9544263]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 364\n",
      "\tRMSE Training: [7.710128]\n",
      "\tRMSE Validation: [8.0056]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 367\n",
      "\tRMSE Training: [7.8057985]\n",
      "\tRMSE Validation: [7.695961]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 370\n",
      "\tRMSE Training: [7.723705]\n",
      "\tRMSE Validation: [7.762395]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 373\n",
      "\tRMSE Training: [7.7869067]\n",
      "\tRMSE Validation: [7.6974607]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 376\n",
      "\tRMSE Training: [7.6884866]\n",
      "\tRMSE Validation: [7.68766]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 379\n",
      "\tRMSE Training: [7.708599]\n",
      "\tRMSE Validation: [7.6199875]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 382\n",
      "\tRMSE Training: [7.7374926]\n",
      "\tRMSE Validation: [7.6076617]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 385\n",
      "\tRMSE Training: [7.7463527]\n",
      "\tRMSE Validation: [7.7090845]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 388\n",
      "\tRMSE Training: [7.6870713]\n",
      "\tRMSE Validation: [7.8325634]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 391\n",
      "\tRMSE Training: [7.691364]\n",
      "\tRMSE Validation: [7.749257]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 394\n",
      "\tRMSE Training: [7.639874]\n",
      "\tRMSE Validation: [7.684449]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 397\n",
      "\tRMSE Training: [7.6548395]\n",
      "\tRMSE Validation: [7.8573623]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 400\n",
      "\tRMSE Training: [7.61357]\n",
      "\tRMSE Validation: [7.4830923]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 403\n",
      "\tRMSE Training: [7.745317]\n",
      "\tRMSE Validation: [7.8776846]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 406\n",
      "\tRMSE Training: [7.8244195]\n",
      "\tRMSE Validation: [7.7164297]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 409\n",
      "\tRMSE Training: [7.733819]\n",
      "\tRMSE Validation: [8.053468]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 412\n",
      "\tRMSE Training: [7.685901]\n",
      "\tRMSE Validation: [7.671162]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 415\n",
      "\tRMSE Training: [7.7132]\n",
      "\tRMSE Validation: [7.681029]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 418\n",
      "\tRMSE Training: [7.703624]\n",
      "\tRMSE Validation: [7.673404]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 421\n",
      "\tRMSE Training: [7.689023]\n",
      "\tRMSE Validation: [7.596365]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 424\n",
      "\tRMSE Training: [7.761268]\n",
      "\tRMSE Validation: [7.5450034]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 427\n",
      "\tRMSE Training: [7.6205435]\n",
      "\tRMSE Validation: [7.695206]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 430\n",
      "\tRMSE Training: [7.6771894]\n",
      "\tRMSE Validation: [8.291414]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 433\n",
      "\tRMSE Training: [7.698948]\n",
      "\tRMSE Validation: [7.6081376]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 436\n",
      "\tRMSE Training: [7.750674]\n",
      "\tRMSE Validation: [7.910799]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 439\n",
      "\tRMSE Training: [7.78715]\n",
      "\tRMSE Validation: [7.690996]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 442\n",
      "\tRMSE Training: [7.6797023]\n",
      "\tRMSE Validation: [8.107661]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 445\n",
      "\tRMSE Training: [7.80571]\n",
      "\tRMSE Validation: [7.654784]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 448\n",
      "\tRMSE Training: [7.750094]\n",
      "\tRMSE Validation: [7.896882]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 451\n",
      "\tRMSE Training: [7.6392217]\n",
      "\tRMSE Validation: [7.6829824]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 454\n",
      "\tRMSE Training: [7.7552037]\n",
      "\tRMSE Validation: [7.6455145]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 457\n",
      "\tRMSE Training: [7.728624]\n",
      "\tRMSE Validation: [7.8375673]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 460\n",
      "\tRMSE Training: [7.5915866]\n",
      "\tRMSE Validation: [7.790929]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 463\n",
      "\tRMSE Training: [7.702535]\n",
      "\tRMSE Validation: [7.796839]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 466\n",
      "\tRMSE Training: [7.6508365]\n",
      "\tRMSE Validation: [7.641811]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 469\n",
      "\tRMSE Training: [7.644088]\n",
      "\tRMSE Validation: [7.6453953]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 472\n",
      "\tRMSE Training: [7.7753634]\n",
      "\tRMSE Validation: [7.746141]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 475\n",
      "\tRMSE Training: [7.726018]\n",
      "\tRMSE Validation: [7.9567604]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 478\n",
      "\tRMSE Training: [7.730723]\n",
      "\tRMSE Validation: [7.702465]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 481\n",
      "\tRMSE Training: [7.5946827]\n",
      "\tRMSE Validation: [7.7960396]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 484\n",
      "\tRMSE Training: [7.694053]\n",
      "\tRMSE Validation: [7.7992754]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 487\n",
      "\tRMSE Training: [7.673739]\n",
      "\tRMSE Validation: [7.80099]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 490\n",
      "\tRMSE Training: [7.659289]\n",
      "\tRMSE Validation: [8.101015]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 493\n",
      "\tRMSE Training: [7.68136]\n",
      "\tRMSE Validation: [7.686372]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 496\n",
      "\tRMSE Training: [7.6936584]\n",
      "\tRMSE Validation: [7.5420046]\n",
      "145\n",
      "145\n",
      "145\n",
      "epoch: 499\n",
      "\tRMSE Training: [7.74701]\n",
      "\tRMSE Validation: [7.8445077]\n",
      "145\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "train_mse=[]\n",
    "validation_mse=[]\n",
    "test_mse=[]\n",
    "tf.reset_default_graph()   #We didn't have any previous graph objects running, but this would reset the graphs\n",
    "\n",
    "\n",
    "#=============================LSTM part===========================================\n",
    "\n",
    "lstm_graph=tf.Graph()\n",
    "with lstm_graph.as_default():\n",
    "    X = tf.placeholder(tf.float32, [None, num_periods_input, inputs])   #create variable objects\n",
    "    y = tf.placeholder(tf.float32, [None, num_periods_output, output])\n",
    "    learning_rate=tf.placeholder(tf.float32, None)\n",
    "    #batchsize = tf.placeholder(tf.int16)\n",
    "    #dropout = tf.placeholder(tf.float32)\n",
    "    is_train = tf.placeholder(tf.bool)\n",
    "    EventBased_X=tf.placeholder(tf.float32, [None,num_periods_input,Number_of_EventBased])\n",
    "    static_X = tf.placeholder(tf.float32, [None,Number_Of_Static_Features])\n",
    "    keep_prob = tf.placeholder(tf.float32, None)\n",
    "\n",
    "    \n",
    "    #====================================================================================\n",
    "    #=========================Static Features part=======================================\n",
    "\n",
    "    Layer1 = tf.layers.dense(static_X, units=100,activation=tf.nn.relu)  \n",
    "    Static_Output_1 = tf.layers.dense(Layer1,units= 50,activation=tf.nn.relu) \n",
    "    Static_Output = tf.nn.dropout(Static_Output_1,keep_prob=keep_prob_static) # dropout \n",
    "    #===================================== Combine before LSTM ===========================\n",
    "    Static_Output=tf.reshape(Static_Output, [-1, num_periods_input,50])\n",
    "\n",
    "    Combined_output=tf.concat([X,Static_Output],2)\n",
    "    #========================================= LSTM ===========================================\n",
    "    with tf.variable_scope('Time'):\n",
    "        #create our RNN object\n",
    "        cells = []\n",
    "        for i in range(num_layers):\n",
    "            LSTM_cell=tf.contrib.rnn.LSTMCell(num_units=hidden, activation=tf.nn.relu)\n",
    "            #LSTM_cell=tf.contrib.rnn.DropoutWrapper(LSTM_cell, output_keep_prob=keep_prob)\n",
    "            cells.append(LSTM_cell )\n",
    "\n",
    "        cells = tf.contrib.rnn.MultiRNNCell(cells,state_is_tuple=True)\n",
    "        #x_norm = tf.layers.batch_normalization(X, training=is_train)\n",
    "        rnn_output, states = tf.nn.dynamic_rnn(cells, Combined_output, dtype=tf.float32)               #choose dynamic over static\n",
    "\n",
    "        # ======= Fully connected after LSTM part==========\n",
    "        stacked_rnn_output = tf.reshape(rnn_output, [-1,(hidden*num_periods_input)])# to be able to concat. the static features\n",
    "\n",
    "        LSTM_Output_1 = tf.layers.dense(stacked_rnn_output, units=100,activation=tf.nn.relu)  \n",
    "        LSTM_Output = tf.nn.dropout(LSTM_Output_1,keep_prob=keep_prob) # dropout\n",
    "    #========================LSTM Event Based============================================\n",
    "    with tf.variable_scope('Event'):\n",
    "        #====================================================================\n",
    "        cells_event = []\n",
    "        for i in range(num_layers_EventBased):\n",
    "            LSTM_cell_event=tf.contrib.rnn.LSTMCell(num_units=hidden_event, activation=tf.nn.relu)\n",
    "            #LSTM_cell_event=tf.contrib.rnn.DropoutWrapper(LSTM_cell_event, output_keep_prob=keep_prob)\n",
    "            cells_event.append(LSTM_cell_event )\n",
    "\n",
    "        cells_event = tf.contrib.rnn.MultiRNNCell(cells_event,state_is_tuple=True)\n",
    "\n",
    "        rnn_output_event, states_event = tf.nn.dynamic_rnn(cells_event,EventBased_X, dtype=tf.float32)               #choose dynamic over static\n",
    "\n",
    "        # ======= Fully connected after Event Based LSTM part===========================================\n",
    "        #===================================================================================\n",
    "        stacked_rnn_output_event = tf.reshape(rnn_output_event, [-1,(hidden_event*num_periods_input)])# to be able to concat. the static features\n",
    "\n",
    "        LSTM_Output_event_1 = tf.layers.dense(stacked_rnn_output_event, units=100,activation=tf.nn.relu)  \n",
    "        LSTM_Output_event = tf.nn.dropout(LSTM_Output_event_1,keep_prob=keep_prob_event)\n",
    "        #====================================================================================\n",
    "    #=========================Combination part===========================================\n",
    "\n",
    "    Combined_output=tf.concat([LSTM_Output,LSTM_Output_event],1)\n",
    "    stacked_outputs = tf.layers.dense(Combined_output, units=2) #specify the type of layer (dense)\n",
    "    outputs = tf.reshape(stacked_outputs, [-1, num_periods_output, output])          #shape of results\n",
    "    #Regularization part\n",
    "    tv = tf.trainable_variables()\n",
    "    regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
    "    Error=tf.square(outputs - y)\n",
    "    #Total_err=Error+regularization_cost\n",
    "    loss = tf.reduce_mean(tf.square(outputs - y))+ lamda*regularization_cost   #define the cost function which evaluates the quality of our model\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)          #gradient descent method\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "    \n",
    "    #opt to get gradient info:\n",
    "    grads=tf.gradients(loss,tv)\n",
    "    grads=list(zip(grads,tv))\n",
    "    \n",
    "    training_op = optimizer.apply_gradients(capped_gvs)\n",
    "    #training_op = optimizer.minimize(loss)          #train the result of the application of the cost_function                                 \n",
    "    \n",
    "    #Before running session, set variables to track in Tensorboard\n",
    "    #with lstm_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    #Creat Summary to monitor scalar values (loss):\n",
    "    #tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "    # Create a summary to monitor prediction tensor\n",
    "    #tf.summary.histogram(\"Prediction\", predictions)\n",
    "    \n",
    "    # Gradient Info\n",
    "    for var in tv:\n",
    "        tf.summary.histogram(var.name,var)\n",
    "    \n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "#====================================================================================\n",
    "\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    #batch_size=\n",
    "    X_returned=[]\n",
    "    Y_returned=[]\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        if (start + batch_size)>len(features):\n",
    "            break\n",
    "        else:\n",
    "            end = start + batch_size\n",
    "        X_returned.append(features[start:end])\n",
    "        Y_returned.append(labels[start:end])\n",
    "    return X_returned, Y_returned\n",
    "\n",
    "\n",
    "# COMPUTE LEARNING RATE schedule beforehand\n",
    "#LR_schedule = compute_LR(init_epoch,epochs,learning_rate_decay,initial_LR) \n",
    "with tf.Session(graph=lstm_graph) as sess:    \n",
    "    \n",
    "    init = tf.global_variables_initializer()           #initialize all the variables\n",
    "    init.run()\n",
    "    \n",
    "    # creating the writer inside the session\n",
    "    #writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    #### LOOP OVER LOCATIONS ####\n",
    "    data_path=r'D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events'\n",
    "    #r'/content/drive/My Drive/FINAL_DATA_EVENTS'\n",
    "    #r'D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\FINAL_DATA_EVENTS'\n",
    "    data_All=pd.DataFrame()\n",
    "    x_batches_Full=[]\n",
    "    y_batches_Full=[]\n",
    "    X_Valid_Full=[]\n",
    "    Y_Valid_Full=[]\n",
    "    X_Test_Full=[]\n",
    "    Y_Test_Full=[]\n",
    "    range_list=[x for x in range(1,31) if x != 8 and x!=21]\n",
    "    for loc_id in range_list:\n",
    "        #========\n",
    "        data=load_locationfiles(data_path,loc_id)\n",
    "        header=list(data.columns.values)\n",
    "        data=pd.DataFrame(data,columns=header)\n",
    "        x_batches, y_batches, X_Valid, Y_Valid,X_Test,Y_Test=preprocessing(data,(Number_of_TimeFeatures+Number_of_EventBased))\n",
    "        #===============================\n",
    "        for element1 in (x_batches):\n",
    "            x_batches_Full.append(element1)\n",
    "            \n",
    "        for element2 in (y_batches):\n",
    "            y_batches_Full.append(element2)\n",
    "            \n",
    "        for element3 in (X_Valid):\n",
    "            X_Valid_Full.append(element3)\n",
    "            \n",
    "        for element4 in (Y_Valid):\n",
    "            Y_Valid_Full.append(element4)\n",
    "            \n",
    "        for element5 in (X_Test):\n",
    "            X_Test_Full.append(element5)\n",
    "            \n",
    "        for element6 in (Y_Test):\n",
    "            Y_Test_Full.append(element6)            \n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        #CALCULATE LR TO USE!!\n",
    "        #curr_lr=LR_schedule[ep]\n",
    "        Training_Error=[]\n",
    "        #even though NOT SHUFFLED YET\n",
    "        shuffled_batch_features,shuffled_batch_y=batch_features_labels(x_batches_Full,y_batches_Full,batchsize)\n",
    "        #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "        combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
    "        random.shuffle(combined)\n",
    "        shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "        #===========================================================================================\n",
    "        print(len(shuffled_batch_features))\n",
    "        \n",
    "        for i in range(0,len(shuffled_batch_features)): \n",
    "            #print('====================')\n",
    "            batch_features=shuffled_batch_features[i]\n",
    "            #print(batch_features)\n",
    "            batch_y=shuffled_batch_y[i]\n",
    "            static_train=[]\n",
    "            Event_Based_Train=[]\n",
    "            \n",
    "            #print('Before drop',batch_features[0][0][0])\n",
    "            for h in range(0,no_sequences):\n",
    "                Event_window=[]\n",
    "                for k in range(0,num_periods_input):\n",
    "                    loc_id=int(batch_features[h][k][0])\n",
    "                    static_train.append(Static_Features[loc_id-1][:]) # \n",
    "                    Event_window.append(batch_features[h][k][Event_Based_StartIndex:])                    \n",
    "                Event_Based_Train.append(Event_window)\n",
    "                \n",
    "            EventBased_EndIndex=Event_Based_StartIndex+Number_of_EventBased\n",
    "            Event_Based_index=list(range(Event_Based_StartIndex, EventBased_EndIndex))\n",
    "            #print('THE EVENT BASED:  ',Event_Based_index)\n",
    "            batch_features=np.delete(batch_features,Event_Based_index, axis=2) \n",
    "            batch_features=np.delete(batch_features,[0], axis=2) \n",
    "            \n",
    "            #print('X',len(batch_features))\n",
    "            #print('Y',len(batch_y[0]))\n",
    "            _,Train_Batch_error,summary=sess.run([training_op,Error,merged_summary_op],\n",
    "                                                 feed_dict={\n",
    "                                                     keep_prob:keep_probab,\n",
    "                                                     X: batch_features,\n",
    "                                                     y: batch_y,\n",
    "                                                     learning_rate: l_rate,\n",
    "                                                     static_X:static_train,\n",
    "                                                     EventBased_X:Event_Based_Train})  \n",
    "            Training_Error.append(Train_Batch_error)\n",
    "            \n",
    "        \n",
    "        #write logs (per epoch)\n",
    "        #writer.add_summary(summary, ep)\n",
    "        \n",
    "        if ep % 3 == 0:\n",
    "            ################  evaluate training error\n",
    "            #print('Length of whole:',len(Training_Error),'Length of each: ',len(Training_Error[0][0]))\n",
    "            Sum_train=np.sum(Training_Error,axis=2)\n",
    "            Sum_train_1=np.sum(Sum_train,axis=1)\n",
    "            Sum_train_2=np.sum(Sum_train_1,axis=0)\n",
    "            '''print('Sum_train shape:',Sum_train.shape)\n",
    "            print('Sum_train_1 shape:',Sum_train_1.shape)\n",
    "            print('Sum_train_2 shape:',Sum_train_2.shape)'''\n",
    "            Mean_train=Sum_train_2/(len(Training_Error)*batchsize*num_periods_output)\n",
    "            print(\"epoch:\",int(ep+1))\n",
    "            print(\"\\tRMSE Training:\", (Mean_train)**0.5)\n",
    "            #mse = loss.eval(feed_dict={\n",
    "            #                              X: batch_features,\n",
    "            #                             y: batch_y,\n",
    "            #                            static_X:static_train,\n",
    "            #                           is_train:True})\n",
    "            train_mse.append((Mean_train)**0.5)\n",
    "                \n",
    "            \n",
    "            Validation_Error=[]\n",
    "            unshuffled_valid_batch_features,unshuffled_valid_batch_y=batch_features_labels(X_Valid_Full,Y_Valid_Full,batchsize)\n",
    "            \n",
    "            #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "            #combined = list(zip(unshuffled_valid_batch_features, unshuffled_valid_batch_y))\n",
    "            #random.shuffle(combined)\n",
    "            #shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "            #===========================================================================================\n",
    "            #print(len(unshuffled_valid_batch_features))\n",
    "            \n",
    "            for i in range(0,len(unshuffled_valid_batch_features)):\n",
    "                batch_features_valid=unshuffled_valid_batch_features[i]\n",
    "                #print(batch_features)\n",
    "                batch_y_valid=unshuffled_valid_batch_y[i]\n",
    "                static_Valid=[]\n",
    "                Event_Based_Valid=[]\n",
    "                #print('Before drop',batch_features[0][0][0])\n",
    "                for h in range(0,no_sequences):\n",
    "                    Event_window_valid=[]\n",
    "                    for k in range(0,num_periods_input):\n",
    "                        loc_id=int(batch_features_valid[h][k][0])\n",
    "                        static_Valid.append(Static_Features[loc_id-1][:]) # \n",
    "                        Event_window_valid.append(batch_features_valid[h][k][Event_Based_StartIndex:])\n",
    "                    Event_Based_Valid.append(Event_window_valid)\n",
    "                    \n",
    "                EventBased_EndIndex=Event_Based_StartIndex+Number_of_EventBased\n",
    "                Event_Based_index=list(range(Event_Based_StartIndex, EventBased_EndIndex))\n",
    "                batch_features_valid=np.delete(batch_features_valid,Event_Based_index, axis=2)\n",
    "                batch_features_valid=np.delete(batch_features_valid,[0], axis=2)\n",
    "                \n",
    "                \n",
    "                y_predict,Valid_error_batch=sess.run([outputs,Error], \n",
    "                                                     feed_dict={\n",
    "                                                     keep_prob:keep_prob_testval,\n",
    "                                                     X: batch_features_valid, \n",
    "                                                     y: batch_y_valid,\n",
    "                                                     static_X:static_Valid,\n",
    "                                                     EventBased_X:Event_Based_Valid})\n",
    "                #print('Valid_error_batch',Valid_error_batch)\n",
    "                Validation_Error.append(Valid_error_batch)\n",
    "            \n",
    "            Sum_valid=np.sum(Validation_Error,axis=2)\n",
    "            Sum_valid_1=np.sum(Sum_valid,axis=1)\n",
    "            Sum_valid_2=np.sum(Sum_valid_1,axis=0)\n",
    "            '''print('Sum_train shape:',Sum_valid.shape)\n",
    "            print('Sum_train_1 shape:',Sum_valid_1.shape)\n",
    "            print('Sum_train_2 shape:',Sum_valid_2.shape)'''\n",
    "            Mean_valid=Sum_valid_2/(len(Validation_Error)*batchsize*num_periods_output)\n",
    "            print(\"\\tRMSE Validation:\", (Mean_valid)**0.5)\n",
    "            #mse = loss.eval(feed_dict={\n",
    "            #                              X: batch_features,\n",
    "            #                             y: batch_y,\n",
    "            #                            static_X:static_train,\n",
    "            #                           is_train:True})\n",
    "            #train_mse.append((Mean_train)**0.5)\n",
    "            \n",
    "            validation_mse.append((Mean_valid)**0.5)\n",
    "              \n",
    "    # save training session --> TO RESTORE\n",
    "    saver.save(sess,\"checkpoints-conn_beg/har.ckpt\")\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_irySJICsFvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min training RMSE: [7.5915866]\n",
      "min validation RMSE: [7.4830923]\n"
     ]
    }
   ],
   "source": [
    "print('min training RMSE:',min(train_mse))\n",
    "print('min validation RMSE:',min(validation_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeoeBeZxsFvZ"
   },
   "source": [
    "### Plot Training + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgI4Lq9asFva"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train_draw=[]\n",
    "Valid_draw=[]\n",
    "for i in range(0,len(train_mse)):\n",
    "    if i%3==0:\n",
    "        Train_draw.append(train_mse[i])\n",
    "        Valid_draw.append(validation_mse[i])\n",
    "\n",
    "plt.title(\"Training vs. Validation Error\", fontsize=14)\n",
    "#plt.legend(loc=\"lower right\")\n",
    "plt.plot(Train_draw[1:], markersize=10, label=\"Training Error\",color='red')\n",
    "plt.plot(Valid_draw[1:], markersize=10, label=\"Validation Error\",color='blue')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('Training vs Testing Error.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpSktO3hsFvd"
   },
   "source": [
    "### Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MESF4QjsFve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints-conn_beg\\har.ckpt\n",
      "25\n",
      "Sum_test shape: (25, 128, 1)\n",
      "Sum_test_1 shape: (25, 1)\n",
      "Sum_test_2 shape: (1,)\n",
      "\tRMSE Testing: [8.082906]\n"
     ]
    }
   ],
   "source": [
    "Test_Error=[]\n",
    "with tf.Session(graph=lstm_graph) as sess: \n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-conn_beg'))\n",
    "    test_batch_features,test_batch_y=batch_features_labels(X_Test_Full,Y_Test_Full,batchsize)\n",
    "    #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "    #combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
    "    #random.shuffle(combined)\n",
    "    #shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "    #===========================================================================================\n",
    "    print(len(test_batch_features))\n",
    "    \n",
    "    for i in range(0,len(test_batch_features)):\n",
    "        batch_features_test=test_batch_features[i]\n",
    "        #print(batch_features)\n",
    "        batch_y_test=test_batch_y[i]\n",
    "        static_test=[]\n",
    "        Event_Based_Test=[]\n",
    "        #print('Before drop',batch_features[0][0][0])\n",
    "        for h in range(0,no_sequences):\n",
    "            Event_window_Test=[]\n",
    "            for k in range(0,num_periods_input):\n",
    "                loc_id=int(batch_features_test[h][k][0])\n",
    "                static_test.append(Static_Features[loc_id-1][:]) # \n",
    "                Event_window_Test.append(batch_features_test[h][k][Event_Based_StartIndex:])\n",
    "            Event_Based_Test.append(Event_window_Test)\n",
    "            \n",
    "        EventBased_EndIndex=Event_Based_StartIndex+Number_of_EventBased\n",
    "        Event_Based_index=list(range(Event_Based_StartIndex, EventBased_EndIndex))\n",
    "        batch_features_test=np.delete(batch_features_test,Event_Based_index, axis=2)  \n",
    "        batch_features_test=np.delete(batch_features_test, [0], axis=2) \n",
    "        #print('X',len(batch_features[0]))\n",
    "        #print('Y',len(batch_y[0]))\n",
    "        Test_Batch_error,y_predict_test,summary=sess.run([Error,outputs,merged_summary_op],\n",
    "                                             feed_dict={\n",
    "                                                 keep_prob:keep_prob_testval,\n",
    "                                                 X: batch_features_test,\n",
    "                                                 y: batch_y_test,\n",
    "                                                 learning_rate: l_rate,\n",
    "                                                 static_X:static_test,\n",
    "                                                 is_train:False,\n",
    "                                                 EventBased_X:Event_Based_Test})\n",
    "\n",
    "        #print('error:',Train_Batch_error[0])\n",
    "        Test_Error.append(Test_Batch_error)\n",
    "\n",
    "    Sum_test=np.sum(Test_Error,axis=2)\n",
    "    Sum_test_1=np.sum(Sum_test,axis=1)\n",
    "    Sum_test_2=np.sum(Sum_test_1,axis=0)\n",
    "    print('Sum_test shape:',Sum_test.shape)\n",
    "    print('Sum_test_1 shape:',Sum_test_1.shape)\n",
    "    print('Sum_test_2 shape:',Sum_test_2.shape)\n",
    "    Mean_test=Sum_test_2/(len(Test_Error)*batchsize*num_periods_output)\n",
    "    print(\"\\tRMSE Testing:\", (Mean_test)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15SGHOrMsFvg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2211_Conn_Beg_EventLSTM_validation_BIRM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
