{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1574547513068,
     "user": {
      "displayName": "daniela thyssens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAjESWh9r_JpJu7Y-DtgOWeyh4Y6Cw-yuE0sVSv5Q=s64",
      "userId": "06737456205702308294"
     },
     "user_tz": -60
    },
    "id": "PuuRX58dsI_3",
    "outputId": "1a65fb6b-bc9f-4781-ca2f-97b271ef54b6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVbzKDghsFuf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version\n",
    "#Import Libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "from random import shuffle\n",
    "#TF Version\n",
    "tf.__version__\n",
    "\n",
    "#with warnings.catch_warnings():\n",
    "#    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "#    import h5py\n",
    "\n",
    "##### Prediction Params #####\n",
    "num_periods_output = 2    #to predict\n",
    "num_periods_input = 4       #input\n",
    "#num_periods = 4           #number of periods per vector we are using to predict one period ahead\n",
    "\n",
    "\n",
    "ALL_Test_Data=[]\n",
    "ALL_Test_Prediction=[]\n",
    "#Event_Based_StartIndex\n",
    "Number_of_EventBased=0\n",
    "Number_of_TimeFeatures=2\n",
    "\n",
    "\n",
    "No_Of_weeks=1/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VWsYwOysFuq"
   },
   "source": [
    "<h5>Preprocessing data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnP7bj4HsFut"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def preprocessing(df_,num_features):\n",
    "    # get year, month,Day,Hour,Minute\n",
    "    #df_['LastUpdated'] = pd.to_datetime(df_['LastUpdated'])\n",
    "    #df_['Year'] = df_['LastUpdated'].dt.year\n",
    "    #df_['Month'] = df_['LastUpdated'].dt.month\n",
    "    #df_['Day'] = df_['LastUpdated'].dt.day\n",
    "    #df_['Hour'] = df_['LastUpdated'].dt.hour\n",
    "    #df_['Minute'] = df_['LastUpdated'].dt.minute\n",
    "    \n",
    "    #,'Month','Day','Hour','Minute'\n",
    "    # select features\n",
    "    df=df_[['ID','Occ_percent']]\n",
    "    \n",
    "    ################################################encoding########################\n",
    "    df['Occ_percent'] = pd.to_numeric(df['Occ_percent'],errors='coerce')\n",
    "    df['Occ_percent'] = df['Occ_percent'].abs()\n",
    "    \n",
    "    \n",
    "    Number_Of_Features=num_features\n",
    "    df=df.values\n",
    "    df = df.astype('float32')\n",
    "    split=num_periods_output+num_periods_input\n",
    "    \n",
    "    \n",
    "    ##################################SPLIT##############################################\n",
    "    print('LEN DF BEFORE CUTTING ANYTHING',len(df))\n",
    "     ########################## SPLITTING FOR TESTING & VALIDATION ##########################\n",
    "    #test_len=np.floor(len(df)*0.2)\n",
    "    test_val_len=np.floor(len(df)*0.2)\n",
    "    #mod=test_len%(num_periods_input+num_periods_output)\n",
    "    mod=test_val_len%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    test_val_len=int(test_val_len-mod)\n",
    "    Test_Val=df[(len(df)-test_val_len):,:]\n",
    "    \n",
    "    ############################ VALIDATION & TESTING ##################################\n",
    "    valid_len=np.floor(len(Test_Val)*0.5)\n",
    "    Valid=Test_Val[0:(len(Test_Val)-int(valid_len)),:]\n",
    "    Test=Test_Val[(len(Test_Val)-int(valid_len)):,:]\n",
    "    \n",
    "    ########################### SPLITTING FOR TRAIN ###########################\n",
    "    \n",
    "    new_cutted_df=df[:(len(df)-test_val_len),:]\n",
    "    Start_train_index=17*7*No_Of_weeks\n",
    "    #Start_train_index=12*24*1 # 1 day\n",
    "    Start_train_index=np.floor(Start_train_index)\n",
    "    Start_train_index=int(Start_train_index)\n",
    "    print('instances',Start_train_index)\n",
    "    Train=new_cutted_df[len(new_cutted_df)-Start_train_index:,:]\n",
    "    print('len new_cutted - start_train_ind',len(new_cutted_df)-Start_train_index)\n",
    "    train_len=len(Train)\n",
    "    mod=train_len%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    train_len=int(train_len-mod)\n",
    "    Train=Train[0:train_len,:]\n",
    "    print('len Train',len(Train))\n",
    "   \n",
    "\n",
    "    ############################################ TRAIN minibatches ##################################\n",
    "    \n",
    "    end=len(Train)\n",
    "    start=0\n",
    "    next=0\n",
    "    x_batches=[]\n",
    "    y_batches=[]\n",
    "    \n",
    "    count=0\n",
    "    #print('lennnn',len(Train))\n",
    "    while next+(num_periods_input+num_periods_output)<end:\n",
    "        next=start+num_periods_input\n",
    "        x_batches.append(Train[start:next,:])\n",
    "        y_batches.append(Train[next:next+num_periods_output,1])\n",
    "        start=start+1\n",
    "    y_batches=np.asarray(y_batches)\n",
    "    y_batches = y_batches.reshape(-1, num_periods_output, 1)   \n",
    "    x_batches=np.asarray(x_batches)\n",
    "    x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
    "    print('len x_batches ',len(x_batches))\n",
    "    \n",
    "    ############################################ VALID minibatches ##################################\n",
    "    \n",
    "    end_val=len(Valid)\n",
    "    start_val=0\n",
    "    next_val=0\n",
    "    x_validbatches=[]\n",
    "    y_validbatches=[]\n",
    "    \n",
    "    while next_val+(num_periods_input+num_periods_output)<end_val:\n",
    "        next_val=start_val+num_periods_input\n",
    "        x_validbatches.append(Valid[start_val:next_val,:])\n",
    "        y_validbatches.append(Valid[next_val:next_val+num_periods_output,1])\n",
    "        start_val=start_val+1\n",
    "    y_validbatches=np.asarray(y_validbatches)\n",
    "    y_validbatches = y_validbatches.reshape(-1, num_periods_output, 1)   \n",
    "    x_validbatches=np.asarray(x_validbatches)\n",
    "    x_validbatches = x_validbatches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
    "\n",
    "    ###########################################TEST#####################################\n",
    "    \n",
    "    ID_Test=Test[:,0]\n",
    "    Test=np.delete(Test,[0],1)\n",
    "    #X_test=X_test.drop(columns=['ID'], axis=1)\n",
    "    occ_Test=Test[:,0]\n",
    "    Test=np.delete(Test,[0],1)\n",
    "    #X_test=X_test.drop(columns=['Occupancy'], axis=1)\n",
    "    #Test = Test.astype('float32')\n",
    "    #Test=normalizer.transform(Test)\n",
    "    \n",
    "    #------------------\n",
    "    ID_Test=np.reshape(ID_Test,(len(ID_Test),1))\n",
    "    occ_Test=np.reshape(occ_Test,(len(occ_Test),1))\n",
    "    \n",
    "    Test=np.append(occ_Test,Test, axis=1)\n",
    "    Test=np.append(ID_Test, Test, axis=1)\n",
    "    print('final Test shape',Test.shape)\n",
    "    ############################################ TEST minibatches ##################################\n",
    "    end_test=len(Test)\n",
    "    start_test=0\n",
    "    next_test=0\n",
    "    x_testbatches=[]\n",
    "    y_testbatches=[]\n",
    "    \n",
    "    \n",
    "    #print('lennnn',len(Train))\n",
    "    while next_test+(num_periods_input+num_periods_output)<end_test:\n",
    "        next_test=start_test+num_periods_input\n",
    "        x_testbatches.append(Test[start_test:next_test,:])\n",
    "        y_testbatches.append(Test[next_test:next_test+num_periods_output,1])\n",
    "        start_test=start_test+1\n",
    "    y_testbatches=np.asarray(y_testbatches)\n",
    "    y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)   \n",
    "    x_testbatches=np.asarray(x_testbatches)\n",
    "    x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features) \n",
    "    print('len Test',len(Test))\n",
    "    print('len xTestbatches',len(x_testbatches))\n",
    "    ######################## Sampling##########################################\n",
    "    \n",
    "    #x_batches, y_batches, x_validbatches, y_validbatches, x_testbatches, y_testbatches\n",
    "    \n",
    "    return x_batches, y_batches,x_validbatches, y_validbatches, x_testbatches, y_testbatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmhRJEHVsFu1"
   },
   "outputs": [],
   "source": [
    "def load_locationfiles(path,loc_id):\n",
    "    filename=path + '/Birm'+str(loc_id)+'.csv'\n",
    "    print(filename)\n",
    "    data_loc=pd.read_csv(filename)\n",
    "    #mod=len(data_loc)%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    #data_loc=data_loc[:len(data_loc)-mod]\n",
    "    return data_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MYuE1zOsFu8"
   },
   "source": [
    "# Creating Tensorflow Graph + Run Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKje0imlsFu_"
   },
   "source": [
    "##### Training Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nso4-lghsFvB"
   },
   "outputs": [],
   "source": [
    "\n",
    "##### Graph Params #####\n",
    "inputs = Number_of_TimeFeatures-1                #number of vectors submitted\n",
    "hidden = 128               #number of neurons we will recursively work through, can be changed to improve accuracy\n",
    "hidden_event=128\n",
    "output = 1                 #number of output vectors\n",
    "num_layers=1\n",
    "num_layers_EventBased=1\n",
    "\n",
    "##### Static Features #####\n",
    "Number_Of_Static_Features=30\n",
    "no_sequences=128            #re-iterating factor for static features\n",
    "\n",
    "##### Optimization Params #####\n",
    "batchsize=128\n",
    "#init_epoch=3              #number of epochs using the constant init_learning_rate\n",
    "#initial_LR=0.0003\n",
    "#learning_rate_decay=0.95\n",
    "l_rate = 0.00009        #small learning rate so we don't overshoot the minimum\n",
    "keep_prob_static=0.7       #number of epochs using the constant init_learning_rate\n",
    "keep_prob_event=0.7\n",
    "lamda=0.01                #regularization param \n",
    "keep_probab=0.9            #(1-dropout_rate)\n",
    "keep_prob_testval=1.0      #(1-dropout_rate) for testing and validation runs\n",
    "epochs = 400                #number of iterations or training cycles, includes both the FeedFoward and Backpropogation\n",
    "\n",
    "#where to save logs\n",
    "#logs_path = '/tmp/tf_logs_3_LSTM_Fully_0410_ConnEnd_Shift_FSTop3/example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkLBQDYosFvI"
   },
   "outputs": [],
   "source": [
    "# model decaying learning rate, instead of fixed one\n",
    "#def compute_LR(init_epoch,max_epoch,learning_rate_decay,init_learning_rate):\n",
    "#    LR_to_use = [\n",
    "#        init_learning_rate * (\n",
    "#            learning_rate_decay ** max(float(i+1-init_epoch),0.0)\n",
    "#        ) for i in range(max_epoch)\n",
    "#    ]\n",
    "#    print(\"Middle LR:\", LR_to_use[len(LR_to_use) // 2])\n",
    "#    return LR_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdKqxvb4Vcbl"
   },
   "outputs": [],
   "source": [
    "#IDs=np.arange(30)\n",
    "#Static_Features=np.zeros((30,30))\n",
    "#Static_Features[np.arange(30),IDs]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IWGs1v9usFvO",
    "outputId": "0a6f4366-991c-46ea-e184-db7d219846c4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-5db538c49bb6>:25: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-5db538c49bb6>:29: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-5db538c49bb6>:31: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-8-5db538c49bb6>:36: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-5db538c49bb6>:37: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Summary name Time/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0 is illegal; using Time/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Time/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0 is illegal; using Time/rnn/multi_rnn_cell/cell_0/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Time/dense/kernel:0 is illegal; using Time/dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Time/dense/bias:0 is illegal; using Time/dense/bias_0 instead.\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm1.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm2.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1276\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 976\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (126, 2)\n",
      "len Test 126\n",
      "len xTestbatches 117\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm3.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1294\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 988\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm4.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm5.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 904\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (117, 2)\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm6.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 904\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (117, 2)\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm7.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 904\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (117, 2)\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm9.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm10.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1276\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 976\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (126, 2)\n",
      "len Test 126\n",
      "len xTestbatches 117\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm11.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm12.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm13.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1292\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 986\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm14.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1038\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 786\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (102, 2)\n",
      "len Test 102\n",
      "len xTestbatches 93\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm15.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm16.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1291\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 985\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm17.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 904\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (117, 2)\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm18.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm19.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 904\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (117, 2)\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm20.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1204\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 916\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (120, 2)\n",
      "len Test 120\n",
      "len xTestbatches 111\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm22.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1204\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 916\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (120, 2)\n",
      "len Test 120\n",
      "len xTestbatches 111\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm23.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm24.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm25.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1294\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 988\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm26.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm27.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm28.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm29.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm30.csv\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 48\n",
      "len new_cutted - start_train_ind 1006\n",
      "len Train 48\n",
      "len x_batches  39\n",
      "final Test shape (129, 2)\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "8\n",
      "epoch: 1\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 4\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 7\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 10\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 13\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 16\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 19\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 22\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 25\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 28\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 31\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 34\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 37\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 40\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 43\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 46\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 49\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 52\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 55\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 58\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 61\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 64\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 67\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 70\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 73\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 76\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 79\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 82\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 85\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 88\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 91\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.342323]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 94\n",
      "\tRMSE Training: [62.70889]\n",
      "\tRMSE Validation: [59.34232]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 97\n",
      "\tRMSE Training: [62.708782]\n",
      "\tRMSE Validation: [59.326355]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 100\n",
      "\tRMSE Training: [61.22874]\n",
      "\tRMSE Validation: [57.24973]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 103\n",
      "\tRMSE Training: [53.297215]\n",
      "\tRMSE Validation: [48.57095]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 106\n",
      "\tRMSE Training: [49.838764]\n",
      "\tRMSE Validation: [46.154953]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 109\n",
      "\tRMSE Training: [49.606106]\n",
      "\tRMSE Validation: [45.95118]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 112\n",
      "\tRMSE Training: [49.376144]\n",
      "\tRMSE Validation: [45.79559]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 115\n",
      "\tRMSE Training: [49.082115]\n",
      "\tRMSE Validation: [45.604343]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 118\n",
      "\tRMSE Training: [48.8486]\n",
      "\tRMSE Validation: [45.473175]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 121\n",
      "\tRMSE Training: [49.08706]\n",
      "\tRMSE Validation: [45.23604]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 124\n",
      "\tRMSE Training: [48.611473]\n",
      "\tRMSE Validation: [45.0878]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 127\n",
      "\tRMSE Training: [48.70208]\n",
      "\tRMSE Validation: [44.938896]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 130\n",
      "\tRMSE Training: [48.62064]\n",
      "\tRMSE Validation: [44.834614]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 133\n",
      "\tRMSE Training: [47.924862]\n",
      "\tRMSE Validation: [44.770008]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 136\n",
      "\tRMSE Training: [48.408146]\n",
      "\tRMSE Validation: [44.78925]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 139\n",
      "\tRMSE Training: [48.15194]\n",
      "\tRMSE Validation: [44.551636]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 142\n",
      "\tRMSE Training: [48.203762]\n",
      "\tRMSE Validation: [44.450035]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 145\n",
      "\tRMSE Training: [48.38443]\n",
      "\tRMSE Validation: [44.227863]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 148\n",
      "\tRMSE Training: [48.03715]\n",
      "\tRMSE Validation: [44.078796]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 151\n",
      "\tRMSE Training: [47.80822]\n",
      "\tRMSE Validation: [44.199745]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 154\n",
      "\tRMSE Training: [47.82769]\n",
      "\tRMSE Validation: [43.991226]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 157\n",
      "\tRMSE Training: [48.330353]\n",
      "\tRMSE Validation: [43.9131]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 160\n",
      "\tRMSE Training: [48.062252]\n",
      "\tRMSE Validation: [43.89373]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 163\n",
      "\tRMSE Training: [47.622723]\n",
      "\tRMSE Validation: [43.810505]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 166\n",
      "\tRMSE Training: [48.277832]\n",
      "\tRMSE Validation: [43.826176]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 169\n",
      "\tRMSE Training: [48.01612]\n",
      "\tRMSE Validation: [43.816685]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 172\n",
      "\tRMSE Training: [44.96106]\n",
      "\tRMSE Validation: [35.87362]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 175\n",
      "\tRMSE Training: [26.620134]\n",
      "\tRMSE Validation: [19.248634]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 178\n",
      "\tRMSE Training: [26.298012]\n",
      "\tRMSE Validation: [18.859676]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 181\n",
      "\tRMSE Training: [25.399014]\n",
      "\tRMSE Validation: [18.04765]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 184\n",
      "\tRMSE Training: [26.433752]\n",
      "\tRMSE Validation: [17.771336]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 187\n",
      "\tRMSE Training: [25.085924]\n",
      "\tRMSE Validation: [16.820377]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 190\n",
      "\tRMSE Training: [24.810575]\n",
      "\tRMSE Validation: [17.228144]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 193\n",
      "\tRMSE Training: [25.18969]\n",
      "\tRMSE Validation: [17.083057]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 196\n",
      "\tRMSE Training: [25.096811]\n",
      "\tRMSE Validation: [18.569664]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 199\n",
      "\tRMSE Training: [25.048998]\n",
      "\tRMSE Validation: [16.284351]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 202\n",
      "\tRMSE Training: [22.940044]\n",
      "\tRMSE Validation: [15.944617]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 205\n",
      "\tRMSE Training: [24.083683]\n",
      "\tRMSE Validation: [17.140718]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 208\n",
      "\tRMSE Training: [24.214556]\n",
      "\tRMSE Validation: [15.435237]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 211\n",
      "\tRMSE Training: [23.52538]\n",
      "\tRMSE Validation: [15.314234]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 214\n",
      "\tRMSE Training: [23.836504]\n",
      "\tRMSE Validation: [14.960354]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 217\n",
      "\tRMSE Training: [23.861923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRMSE Validation: [14.5517845]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 220\n",
      "\tRMSE Training: [23.065968]\n",
      "\tRMSE Validation: [15.263887]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 223\n",
      "\tRMSE Training: [23.496998]\n",
      "\tRMSE Validation: [15.355959]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 226\n",
      "\tRMSE Training: [22.804604]\n",
      "\tRMSE Validation: [14.827239]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 229\n",
      "\tRMSE Training: [24.36143]\n",
      "\tRMSE Validation: [14.142823]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 232\n",
      "\tRMSE Training: [23.867771]\n",
      "\tRMSE Validation: [15.070563]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 235\n",
      "\tRMSE Training: [23.845304]\n",
      "\tRMSE Validation: [14.190379]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 238\n",
      "\tRMSE Training: [24.114754]\n",
      "\tRMSE Validation: [14.396442]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 241\n",
      "\tRMSE Training: [23.521477]\n",
      "\tRMSE Validation: [15.130989]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 244\n",
      "\tRMSE Training: [24.000296]\n",
      "\tRMSE Validation: [13.92785]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 247\n",
      "\tRMSE Training: [22.521109]\n",
      "\tRMSE Validation: [14.24249]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 250\n",
      "\tRMSE Training: [23.867823]\n",
      "\tRMSE Validation: [13.551932]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 253\n",
      "\tRMSE Training: [22.34888]\n",
      "\tRMSE Validation: [14.337426]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 256\n",
      "\tRMSE Training: [23.750116]\n",
      "\tRMSE Validation: [13.40963]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 259\n",
      "\tRMSE Training: [22.475529]\n",
      "\tRMSE Validation: [13.162684]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 262\n",
      "\tRMSE Training: [21.608637]\n",
      "\tRMSE Validation: [14.113585]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 265\n",
      "\tRMSE Training: [22.8795]\n",
      "\tRMSE Validation: [14.305266]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 268\n",
      "\tRMSE Training: [22.487194]\n",
      "\tRMSE Validation: [13.889895]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 271\n",
      "\tRMSE Training: [23.230354]\n",
      "\tRMSE Validation: [13.967816]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 274\n",
      "\tRMSE Training: [22.403725]\n",
      "\tRMSE Validation: [13.825054]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 277\n",
      "\tRMSE Training: [22.901312]\n",
      "\tRMSE Validation: [13.64091]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 280\n",
      "\tRMSE Training: [21.833342]\n",
      "\tRMSE Validation: [14.149902]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 283\n",
      "\tRMSE Training: [21.822392]\n",
      "\tRMSE Validation: [13.638169]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 286\n",
      "\tRMSE Training: [23.399534]\n",
      "\tRMSE Validation: [12.940834]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 289\n",
      "\tRMSE Training: [21.79033]\n",
      "\tRMSE Validation: [12.875108]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 292\n",
      "\tRMSE Training: [22.496416]\n",
      "\tRMSE Validation: [13.160743]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 295\n",
      "\tRMSE Training: [22.390072]\n",
      "\tRMSE Validation: [12.86134]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 298\n",
      "\tRMSE Training: [22.655928]\n",
      "\tRMSE Validation: [12.435698]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 301\n",
      "\tRMSE Training: [23.15561]\n",
      "\tRMSE Validation: [13.683615]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 304\n",
      "\tRMSE Training: [22.365849]\n",
      "\tRMSE Validation: [14.059831]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 307\n",
      "\tRMSE Training: [22.358147]\n",
      "\tRMSE Validation: [12.958341]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 310\n",
      "\tRMSE Training: [21.971104]\n",
      "\tRMSE Validation: [12.542349]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 313\n",
      "\tRMSE Training: [21.655756]\n",
      "\tRMSE Validation: [12.598148]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 316\n",
      "\tRMSE Training: [21.996275]\n",
      "\tRMSE Validation: [15.937315]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 319\n",
      "\tRMSE Training: [23.051445]\n",
      "\tRMSE Validation: [12.384793]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 322\n",
      "\tRMSE Training: [21.88575]\n",
      "\tRMSE Validation: [13.49101]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 325\n",
      "\tRMSE Training: [22.728815]\n",
      "\tRMSE Validation: [13.939894]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 328\n",
      "\tRMSE Training: [22.689924]\n",
      "\tRMSE Validation: [12.110302]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 331\n",
      "\tRMSE Training: [23.403605]\n",
      "\tRMSE Validation: [14.057605]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 334\n",
      "\tRMSE Training: [21.462599]\n",
      "\tRMSE Validation: [13.136947]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 337\n",
      "\tRMSE Training: [21.16718]\n",
      "\tRMSE Validation: [12.0683775]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 340\n",
      "\tRMSE Training: [23.160635]\n",
      "\tRMSE Validation: [12.071325]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 343\n",
      "\tRMSE Training: [23.22608]\n",
      "\tRMSE Validation: [12.010951]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 346\n",
      "\tRMSE Training: [22.228794]\n",
      "\tRMSE Validation: [12.724835]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 349\n",
      "\tRMSE Training: [21.835379]\n",
      "\tRMSE Validation: [12.049994]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 352\n",
      "\tRMSE Training: [23.11781]\n",
      "\tRMSE Validation: [12.240298]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 355\n",
      "\tRMSE Training: [22.970255]\n",
      "\tRMSE Validation: [13.566694]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 358\n",
      "\tRMSE Training: [22.191172]\n",
      "\tRMSE Validation: [13.870931]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 361\n",
      "\tRMSE Training: [22.32791]\n",
      "\tRMSE Validation: [12.652217]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 364\n",
      "\tRMSE Training: [21.666992]\n",
      "\tRMSE Validation: [12.783003]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 367\n",
      "\tRMSE Training: [22.519678]\n",
      "\tRMSE Validation: [13.237539]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 370\n",
      "\tRMSE Training: [23.06191]\n",
      "\tRMSE Validation: [12.773193]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 373\n",
      "\tRMSE Training: [23.478209]\n",
      "\tRMSE Validation: [12.047293]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 376\n",
      "\tRMSE Training: [22.003508]\n",
      "\tRMSE Validation: [12.262581]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 379\n",
      "\tRMSE Training: [21.578758]\n",
      "\tRMSE Validation: [11.9033165]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 382\n",
      "\tRMSE Training: [22.493885]\n",
      "\tRMSE Validation: [15.295312]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 385\n",
      "\tRMSE Training: [22.818441]\n",
      "\tRMSE Validation: [12.061402]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 388\n",
      "\tRMSE Training: [23.384468]\n",
      "\tRMSE Validation: [12.159802]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 391\n",
      "\tRMSE Training: [21.252485]\n",
      "\tRMSE Validation: [13.209066]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 394\n",
      "\tRMSE Training: [23.235691]\n",
      "\tRMSE Validation: [11.765841]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 397\n",
      "\tRMSE Training: [21.990673]\n",
      "\tRMSE Validation: [12.492823]\n",
      "8\n",
      "8\n",
      "8\n",
      "epoch: 400\n",
      "\tRMSE Training: [23.3998]\n",
      "\tRMSE Validation: [12.45561]\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "train_mse=[]\n",
    "validation_mse=[]\n",
    "test_mse=[]\n",
    "tf.reset_default_graph()   #We didn't have any previous graph objects running, but this would reset the graphs\n",
    "\n",
    "\n",
    "#=============================LSTM part===========================================\n",
    "\n",
    "lstm_graph=tf.Graph()\n",
    "with lstm_graph.as_default():\n",
    "    X = tf.placeholder(tf.float32, [None, num_periods_input, inputs])   #create variable objects\n",
    "    y = tf.placeholder(tf.float32, [None, num_periods_output, output])\n",
    "    learning_rate=tf.placeholder(tf.float32, None)\n",
    "    #batchsize = tf.placeholder(tf.int16)\n",
    "    #dropout = tf.placeholder(tf.float32)\n",
    "    is_train = tf.placeholder(tf.bool)\n",
    "    EventBased_X=tf.placeholder(tf.float32, [None,num_periods_input,Number_of_EventBased])\n",
    "    static_X = tf.placeholder(tf.float32, [None,Number_Of_Static_Features])\n",
    "    keep_prob = tf.placeholder(tf.float32, None)\n",
    "    #========================================= LSTM ===========================================\n",
    "    with tf.variable_scope('Time'):\n",
    "        #create our RNN object\n",
    "        cells = []\n",
    "        for i in range(num_layers):\n",
    "            LSTM_cell=tf.contrib.rnn.LSTMCell(num_units=hidden, activation=tf.nn.relu)\n",
    "            #LSTM_cell=tf.contrib.rnn.DropoutWrapper(LSTM_cell, output_keep_prob=keep_prob)\n",
    "            cells.append(LSTM_cell )\n",
    "\n",
    "        cells = tf.contrib.rnn.MultiRNNCell(cells,state_is_tuple=True)\n",
    "        #x_norm = tf.layers.batch_normalization(X, training=is_train)\n",
    "        rnn_output, states = tf.nn.dynamic_rnn(cells, X, dtype=tf.float32)               #choose dynamic over static\n",
    "\n",
    "        # ======= Fully connected after LSTM part==========\n",
    "        stacked_rnn_output = tf.reshape(rnn_output, [-1,(hidden*num_periods_input)])# to be able to concat. the static features\n",
    "\n",
    "        LSTM_Output_1 = tf.layers.dense(stacked_rnn_output, units=num_periods_output,activation=tf.nn.relu)  \n",
    "        LSTM_Output = tf.nn.dropout(LSTM_Output_1,keep_prob=keep_prob) # dropout\n",
    "    #====================================================================================\n",
    "    \n",
    "    \n",
    "    outputs = tf.reshape(LSTM_Output, [-1, num_periods_output, output])          #shape of results\n",
    "    #Regularization part\n",
    "    tv = tf.trainable_variables()\n",
    "    regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
    "    Error=tf.square(outputs - y)\n",
    "    #Total_err=Error+regularization_cost\n",
    "    loss = tf.reduce_mean(tf.square(outputs - y))+ lamda*regularization_cost   #define the cost function which evaluates the quality of our model\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)          #gradient descent method\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "    \n",
    "    #opt to get gradient info:\n",
    "    grads=tf.gradients(loss,tv)\n",
    "    grads=list(zip(grads,tv))\n",
    "    \n",
    "    training_op = optimizer.apply_gradients(capped_gvs)\n",
    "    #training_op = optimizer.minimize(loss)          #train the result of the application of the cost_function                                 \n",
    "    \n",
    "    #Before running session, set variables to track in Tensorboard\n",
    "    #with lstm_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    #Creat Summary to monitor scalar values (loss):\n",
    "    #tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "    # Create a summary to monitor prediction tensor\n",
    "    #tf.summary.histogram(\"Prediction\", predictions)\n",
    "    \n",
    "    # Gradient Info\n",
    "    for var in tv:\n",
    "        tf.summary.histogram(var.name,var)\n",
    "    \n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "#====================================================================================\n",
    "\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    #batch_size=\n",
    "    X_returned=[]\n",
    "    Y_returned=[]\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        if (start + batch_size)>len(features):\n",
    "            break\n",
    "        else:\n",
    "            end = start + batch_size\n",
    "        X_returned.append(features[start:end])\n",
    "        Y_returned.append(labels[start:end])\n",
    "    return X_returned, Y_returned\n",
    "\n",
    "\n",
    "# COMPUTE LEARNING RATE schedule beforehand\n",
    "#LR_schedule = compute_LR(init_epoch,epochs,learning_rate_decay,initial_LR) \n",
    "with tf.Session(graph=lstm_graph) as sess:    \n",
    "    \n",
    "    init = tf.global_variables_initializer()           #initialize all the variables\n",
    "    init.run()\n",
    "    \n",
    "    # creating the writer inside the session\n",
    "    #writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    #### LOOP OVER LOCATIONS ####\n",
    "    data_path=r'D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events'\n",
    "    #r'/content/drive/My Drive/FINAL_DATA_EVENTS'\n",
    "    #r'D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\FINAL_DATA_EVENTS'\n",
    "    data_All=pd.DataFrame()\n",
    "    x_batches_Full=[]\n",
    "    y_batches_Full=[]\n",
    "    X_Valid_Full=[]\n",
    "    Y_Valid_Full=[]\n",
    "    X_Test_Full=[]\n",
    "    Y_Test_Full=[]\n",
    "    range_list=[x for x in range(1,31) if x != 8 and x!=21]\n",
    "    for loc_id in range_list:\n",
    "        #========\n",
    "        data=load_locationfiles(data_path,loc_id)\n",
    "        header=list(data.columns.values)\n",
    "        data=pd.DataFrame(data,columns=header)\n",
    "        x_batches, y_batches, X_Valid, Y_Valid,X_Test,Y_Test=preprocessing(data,(Number_of_TimeFeatures+Number_of_EventBased))\n",
    "        #===============================\n",
    "        for element1 in (x_batches):\n",
    "            x_batches_Full.append(element1)\n",
    "            \n",
    "        for element2 in (y_batches):\n",
    "            y_batches_Full.append(element2)\n",
    "            \n",
    "        for element3 in (X_Valid):\n",
    "            X_Valid_Full.append(element3)\n",
    "            \n",
    "        for element4 in (Y_Valid):\n",
    "            Y_Valid_Full.append(element4)\n",
    "            \n",
    "        for element5 in (X_Test):\n",
    "            X_Test_Full.append(element5)\n",
    "            \n",
    "        for element6 in (Y_Test):\n",
    "            Y_Test_Full.append(element6)            \n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        #CALCULATE LR TO USE!!\n",
    "        #curr_lr=LR_schedule[ep]\n",
    "        Training_Error=[]\n",
    "        #even though NOT SHUFFLED YET\n",
    "        shuffled_batch_features,shuffled_batch_y=batch_features_labels(x_batches_Full,y_batches_Full,batchsize)\n",
    "        #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "        combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
    "        random.shuffle(combined)\n",
    "        shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "        #===========================================================================================\n",
    "        print(len(shuffled_batch_features))\n",
    "        \n",
    "        for i in range(0,len(shuffled_batch_features)): \n",
    "            #print('====================')\n",
    "            batch_features=shuffled_batch_features[i]\n",
    "            #print(batch_features)\n",
    "            batch_y=shuffled_batch_y[i]\n",
    "            batch_features=np.delete(batch_features,[0], axis=2) \n",
    "            \n",
    "            #print('X',len(batch_features))\n",
    "            #print('Y',len(batch_y[0]))\n",
    "            _,Train_Batch_error,summary=sess.run([training_op,Error,merged_summary_op],\n",
    "                                                 feed_dict={\n",
    "                                                     keep_prob:keep_probab,\n",
    "                                                     X: batch_features,\n",
    "                                                     y: batch_y,\n",
    "                                                     learning_rate: l_rate})  \n",
    "            Training_Error.append(Train_Batch_error)\n",
    "            \n",
    "        \n",
    "        #write logs (per epoch)\n",
    "        #writer.add_summary(summary, ep)\n",
    "        \n",
    "        if ep % 3 == 0:\n",
    "            ################  evaluate training error\n",
    "            #print('Length of whole:',len(Training_Error),'Length of each: ',len(Training_Error[0][0]))\n",
    "            Sum_train=np.sum(Training_Error,axis=2)\n",
    "            Sum_train_1=np.sum(Sum_train,axis=1)\n",
    "            Sum_train_2=np.sum(Sum_train_1,axis=0)\n",
    "            '''print('Sum_train shape:',Sum_train.shape)\n",
    "            print('Sum_train_1 shape:',Sum_train_1.shape)\n",
    "            print('Sum_train_2 shape:',Sum_train_2.shape)'''\n",
    "            Mean_train=Sum_train_2/(len(Training_Error)*batchsize*num_periods_output)\n",
    "            print(\"epoch:\",int(ep+1))\n",
    "            print(\"\\tRMSE Training:\", (Mean_train)**0.5)\n",
    "            #mse = loss.eval(feed_dict={\n",
    "            #                              X: batch_features,\n",
    "            #                             y: batch_y,\n",
    "            #                            static_X:static_train,\n",
    "            #                           is_train:True})\n",
    "            train_mse.append((Mean_train)**0.5)\n",
    "                \n",
    "            \n",
    "            Validation_Error=[]\n",
    "            unshuffled_valid_batch_features,unshuffled_valid_batch_y=batch_features_labels(X_Valid_Full,Y_Valid_Full,batchsize)\n",
    "            \n",
    "            #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "            #combined = list(zip(unshuffled_valid_batch_features, unshuffled_valid_batch_y))\n",
    "            #random.shuffle(combined)\n",
    "            #shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "            #===========================================================================================\n",
    "            #print(len(unshuffled_valid_batch_features))\n",
    "            \n",
    "            for i in range(0,len(unshuffled_valid_batch_features)):\n",
    "                batch_features_valid=unshuffled_valid_batch_features[i]\n",
    "                #print(batch_features)\n",
    "                batch_y_valid=unshuffled_valid_batch_y[i]\n",
    "                batch_features_valid=np.delete(batch_features_valid,[0], axis=2)\n",
    "                \n",
    "                \n",
    "                y_predict,Valid_error_batch=sess.run([outputs,Error], \n",
    "                                                     feed_dict={\n",
    "                                                     keep_prob:keep_prob_testval,\n",
    "                                                     X: batch_features_valid, \n",
    "                                                     y: batch_y_valid})\n",
    "                #print('Valid_error_batch',Valid_error_batch)\n",
    "                Validation_Error.append(Valid_error_batch)\n",
    "            \n",
    "            Sum_valid=np.sum(Validation_Error,axis=2)\n",
    "            Sum_valid_1=np.sum(Sum_valid,axis=1)\n",
    "            Sum_valid_2=np.sum(Sum_valid_1,axis=0)\n",
    "            Mean_valid=Sum_valid_2/(len(Validation_Error)*batchsize*num_periods_output)\n",
    "            print(\"\\tRMSE Validation:\", (Mean_valid)**0.5)\n",
    "            #mse = loss.eval(feed_dict={\n",
    "            #                              X: batch_features,\n",
    "            #                             y: batch_y,\n",
    "            #                            static_X:static_train,\n",
    "            #                           is_train:True})\n",
    "            #train_mse.append((Mean_train)**0.5)\n",
    "            \n",
    "            validation_mse.append((Mean_valid)**0.5)\n",
    "              \n",
    "    # save training session --> TO RESTORE\n",
    "    saver.save(sess,\"checkpoints-conn_beg/har.ckpt\")\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_irySJICsFvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min training RMSE: [21.16718]\n",
      "min validation RMSE: [11.765841]\n"
     ]
    }
   ],
   "source": [
    "print('min training RMSE:',min(train_mse))\n",
    "print('min validation RMSE:',min(validation_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeoeBeZxsFvZ"
   },
   "source": [
    "### Plot Training + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgI4Lq9asFva"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEJCAYAAACNNHw2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xUVfrH8c+TAIZqCIQSUAKCEDohsjQLFmwgirrAiguWxb7WVWR1baur/lxR1HVVFHVRwLXhWnBdRLEBhiIqEUF6TUAQpCc8vz/OTTKZTJJJnfa8X6/7mtyZW87cJN85c+6554qqYowxJvLEhboAxhhjKsYC3BhjIpQFuDHGRCgLcGOMiVAW4MYYE6EswI0xJkJZgEc5EZkuIq+Xc515IvJIdZUpEonI6yIyvaT5Etb5RESerOp9G5PPAjzERETLmF6s5C6uAC4v5zpnAfdUcr8hJSL1RGSniNxSwus3icguEalfwV1cjju2VUZEhni/84Tq3lcJ+88s4W9wcnXv21RMrVAXwNDS5+chwHN+z+0LtJKI1FbVQ2VtXFV/KW+BVPXn8q4TblR1r4hMAy4FAn2buBSYrqp7Krj9nZUpX7juC3gSuN/vub0lLRzo71BE4gFV1cPl3Xmwf9fGsRp4iKnqlvwJ2On/nKr+IiKdvJrQhSLyqYjsB8aISHMRmSEiG0Vkr4h8JyIX+W7fvwnFax6ZKCL/JyI/i8gWEXlARMRvmUd85reIyG0i8oKI7BaR9SLyR7/9dBaRL0Rkv4gsE5HTRCRXREYGet8iMswrcyO/5x8Vkfnez01E5FURyfG2u1JErirH4Z0MpIlIP799/Abo4r2OiLQUkdd8juO3IjKqtA0HaFJp5JV1j4hsEpEbA6xzuYgsEpFfvWP6iog0817rCvzHW3Sf9/t+soR91RORp32Oy+cicpzP6/k1+RO8/e0Vka9EpEsQx2yP39/fFlXdlV9Gb7vni8hn3t/hRSJyrfd+hotIFnAAOFpE4kXkr95xPSAii0XkDJ9yBtxeEGU0HgvwyPIgMBFIA94H6gLzgLOBrsDTwEsiMrCM7VwK/AL8BrgZuA04t4x1bgEWAL2Ax4HHRSQdQERqATOB3UAfYBzwAKX/fb2Pq9kNz39CROKAkcBUn/fbATgT6ORtd2sZ5SygqguBJbj36+sy4DtVXeDN1wO+xB3HbsCzwL9EpG+w+8LVXPsBQ4HTgZOBdL9lagG3A92B84C2wEveaz8AF3s/p+K+hd1ewr6e8Mp6EdAbWA18KCJJfsvdD1wPZACHgJfL8X5K8xDuW00a8KH3XCJwI3AJ7m8xG5gAXA3cgHvPs4F3ROTYILZngqGqNoXJBFzgfiXFnu8EKHBNENt4G3jSZ3468LrP/Dxgjt86n/mtMw94xGd+CzDFb531wC3ez8OAg0Azn9dP9so8spSyPg185DN/Ki5omnnz/wWeruQxvRbYBdT35ut589eXsd67wGM+86/jmlyKzQPJQC4wzOf1JNwH1JOl7CPDO0aJ3vwQbz7BbznffTUF8oDhPq/XATYB4/22M8BnmdN991VCeTK93+OvftMY7/Wu3jauCHCMFejo85zgvlHeFGAf/yxtezYFP1kNPLJk+s6ISC0Rucv7yv+ziPyKq5kdXcZ2lvrNbwKaVWKdTsAaVc32eX1+GdsDV9M+WUTy2/wvAv7rs52ngLHeV++Hg/hmEcgrQG3gQm/+Qlzg5dfyEZHaInKP33E8nbKPY75jgXjgq/wn1J1HWO67kIj0FZH3RGSdiOwGPvVeCnY/+fuKA77w2ddB3Lejzn7L+v7ONnmPZf2eXwB6+k1v+S2T6b8S8Kuq+r7flsCRvuX0fB6gnIG2Z4JgAR5Z/E+4/Rm4BvgbMAj3z/Y+LqBK43+SSCn7b6G0dcSbLxdV/QJYA4wU1/NiOD7BqqozgTa4JpuWuGaCp8u5jx3AmxQ2o1wGvK2q230W+wtwJa7ZJ/84fkjZxzGflLmAa96YhWta+B2u9n2e93Kw+/HdV6Dj7f/coQCvlfV73qmqK/2mXX7LBDrx6/9cecpZoRPJxgI80g0E3lLVV1X1G2AVroZW07KAVBFJ9nmuT5DrvoqreQ/F/T3O9H1RVbNV9UVVvRjXnnq511ZeHpOB40XkbOB4b97XQFwz0zTvOK6mfMdxOXAYKGgzF5HGftvohquR3qqqn3u11RZ+2znoPcaXsa88r8z5+6oDHAcsK0eZq9sm3HkW/29NAwmvckY060YY2X4EzvZ6WewEbgJSgLU1XI73gHW4E6jjgYa4E5BK2TXzfwF3eNObqlrQZU1EHsC1xy8DjsCdaF2uXvc0r2fGblX9Qxn7+AT4ydvXGtzJNF8/Amd4Jy134U7YNveeL5Oq5ojIq8BEEdkFbMPV5n270a3GtZP/UUReAHp479nXGu9xiIh8DOxVv26OqrpN3LUBE71mmI24k531cF1QK6u+iPh/sBzwvskETVVVXE+mO0RkHfAtrj97d9w3EFMFrAYe2e7CtXN+hAupbNwJrxqlqrm4E5mJwNe4Gu693sv7y1j3R2+d7vg0n3gO4XooLAXm4mqmw31eTwWOCqJ8imvbbQy84M37uhP3IfE/4GNgA+5kcHlc672P973tfAos9CnDOlyAXYz7xvInXA8g33L+iPvgm4TrbfNQCfu63tvPNGARrjfLYK2a/vvXApv9pmkV3NbfcCeqJ+EC/FTgHO99miogxf+Wjak8r6/1PKCrqn4f6vIYE40swE2VEJELgR3ASuAY4DFcE8BvQlowY6KYtYGbqnIk7itza2A7rp355lLXMMZUitXAjTEmQtlJTGOMiVA12oTStGlTTU1NrcldGmNMxFu4cOE2VU32f75GAzw1NZXMTLtq1hhjykNEAl7bYU0oxhgToSzAjTEmQlmAG2NMhLJ+4MZEiUOHDrFhwwb27y919AITxhISEmjdujW1a9cOankLcGOixIYNG2jYsCGpqamIlDnCrQkzqsr27dvZsGEDbdu2DWoda0IxJkrs37+fJk2aWHhHKBGhSZMm5foGZQFuTBSx8I5s5f39RUYTytSp8GMMj0AZFwcjR0KnTqEuiTEmjERGgE+fDu+/H+pShI4q/P3v8MorcM45oS6NMcVs376dU045BYAtW7YQHx9PcrK7cHDBggXUqVP2XeMuueQSxo8fT8eOHUtc5qmnniIxMZGLLrqo0mUeOHAgOTk51K1bF4COHTsyY8aMSm+3JkVGgL/7bqhLEFobNsB558GwYXDfffDnP4N9VTZhpEmTJixZsgSAu+++mwYNGnDLLbcUWabgTupxgVtup0yZUuZ+rrnmmsoX1seMGTPo2bNnia/n5uZSq1atEueDXa+6WBt4JGjdGubOhdGj4c47YcQI2GP3gTXhb+XKlXTt2pUrr7yS9PR0Nm/ezLhx48jIyKBLly7ce++9BcsOHDiQJUuWkJubS2JiIuPHj6dHjx7069eP7OxsAO644w4ee+yxguXHjx9Pnz596NixI19++SUAe/bs4fzzz6dHjx6MGjWKjIyMgg+XYIwePZqbb76ZQYMGMWHCBO644w6uuOIKTjvtNC655BL27dvHmDFj6NatG+np6cydOxeAyZMnM3LkSIYMGcKZZ55ZVYewVJFRAzdQty68/DL07Am33grLl8PMmWCDg5lAbrgByhFaQenZE7zwLI9ly5YxZcoU/vnPfwLw4IMPkpSURG5uLoMGDeKCCy6gc+fORdb55ZdfOPHEE3nwwQe56aabeOGFFxg/fnyxbasqCxYs4J133uHee+9l1qxZPPHEE7Ro0YI33niDb775hvT09BLLNmLEiIImlDPOOIMHH3wQgJ9++onZs2cTFxfHHXfcweLFi5k7dy4JCQk89NBD1KlTh2+//Zbvv/+es846ixUrVgDw1VdfsWTJEho3blzu41QRVgOPJCJw883ufMDatXDccfDpp6EulTGlOuaYYzjuuOMK5qdNm0Z6ejrp6elkZWWxbFnxm9TXrVu3oBbbu3dv1qxZE3Dbw4cPL7bM559/zsiRIwHo0aMHXbp0KbFsM2bMYMmSJSxZsqQgvAEuvPDCIk09w4YNIyEhoWD7F198MQBdunQhJSWFlStXAjB48OAaC2+wGnhkOv10WLDAtYmfeiq88Yad3DRFVaCmXF3q169f8POKFSt4/PHHWbBgAYmJiYwePTpgv2ffk57x8fHk5uYG3PYRRxxRbJmquEmNb5n950vbvv961c1q4JHq2GNh/nxo3tz1TjEmAuzatYuGDRvSqFEjNm/ezIcffljl+xg4cCCvvfYaAN9++23AGn5lnHDCCbzi/c9lZWWxefNm2rdvX6X7CJbVwCNZo0auXfKHH0JdEmOCkp6eTufOnenatSvt2rVjwIABVb6P6667jt///vd0796d9PR0unbtypFHHhlwWd828ObNmwf1gXLddddxxRVX0K1bN2rXrs3LL78cVDfJ6hDUPTFFJBGYDHQFFLgUWA7MAFKBNcBvVXVHadvJyMhQu6FDFfvTn+DJJ+HXXyE+PtSlMSGUlZVFWlpaqIsRcrm5ueTm5pKQkMCKFSsYPHgwK1asqJFufVUh0O9RRBaqaob/ssG+o8eBWap6gYjUAeoBE4DZqvqgiIwHxgO3Va7optw6dYL9+2HdOghyABxjotmvv/7KKaecQm5uLqrKM888EzHhXV5lvisRaQScAIwFUNWDwEERGQac5C32EvAJFuA1L//y+h9+sAA3BkhMTGThwoWhLkaNCOYkZjsgB5giIotFZLKI1Aeaq+pmAO+xWaCVRWSciGSKSGZOTk6VFdx4fAPcGBNTgvleUQtIB65T1fki8jiuuSQoqvos8Cy4NvCKFPL9910LQayKj4dzz4XkYvekBpo0gaZNLcCNiUHBBPgGYIOqzvfmX8cF+FYRaamqm0WkJZBdXYV86qnYHssKYNIk+PxzCHgyvVMnyMqq8TIZY0KrzABX1S0isl5EOqrqcuAUYJk3jQEe9B5nVlchp06FAweqa+vhLzPTjWV14YXw3ntQ7G5LnTq5y+qNMbElf4Sw0iagJ5AJLAXeBhoDTYDZwArvMams7fTu3VtNxUyZogqql16qeviw34uPPOJe3LYtFEUzYWLZsmUh2/eJJ56os2bNKvLcxIkT9aqrrip1vfr166uq6saNG/X8888vcdtff/11qduZOHGi7tmzp2D+zDPP1B07dgRT9FLdddddmpKSoj169CiYqmK7pQn0ewQyNUCmBnUlpqouUdUMVe2uqueq6g5V3a6qp6hqB+/x5+r4gDHO2LHwl7/ACy/A/ff7vZh/InP58pouljEAjBo1iunTpxd5bvr06YwaNSqo9VNSUnj99dcrvP/HHnuMvXv3Fsy///77JCYmVnh7vm688caC8VKWLFlSbLv+l/nn5eUFtV1V5fDhw5Uqm11KH0HuvhsuvtiNKDt1qs8L1hPFhNgFF1zAu+++ywGvrXPNmjVs2rSJgQMHFvTLTk9Pp1u3bswM0Ny3Zs0aunbtCsC+ffsYOXIk3bt3Z8SIEezbt69guauuuqpgKNq77roLgEmTJrFp0yYGDRrEoEGDAEhNTWXbtm0APProo3Tt2pWuXbsWDEW7Zs0a0tLS+MMf/kCXLl0YPHhwkf2U5cUXX+TCCy9k6NChDB48mE8++YRBgwbxu9/9jm7dupW536uvvpr09HTWr19fruPsLzp7t0cpEZg8Gdavh0svdcOEn3QSbkjZOnUswE2Bmh5NtkmTJvTp04dZs2YxbNgwpk+fzogRIxAREhISeOutt2jUqBHbtm2jb9++nHPOOSXe//Hpp5+mXr16LF26lKVLlxYZDvb+++8nKSmJvLw8TjnlFJYuXcof//hHHn30UebMmUPTpk2LbGvhwoVMmTKF+fPno6r85je/4cQTT6Rx48asWLGCadOm8dxzz/Hb3/6WN954g9GjRxcrz8SJE5nq1ZgaN27MnDlzADd07NKlS0lKSuKTTz5hwYIFfPfdd7Rt27bU/S5fvpwpU6bwj3/8oyK/hiKsBh5h6tSBN9+E9u3dic2sLFw/w2OPtQA3IeXbjOLbfKKqTJgwge7du3PqqaeyceNGtm7dWuJ25s6dWxCk3bt3p3v37gWvvfbaa6Snp9OrVy++//77Mgeq+vzzzznvvPOoX78+DRo0YPjw4Xz22WcAtG3btuBuPKUNWevbhJIf3gCnnXYaSUlJBfN9+vShrXcxXWn7bdOmDX379i213MGyGngEatzYdavs2xfOPBPmzYMWnTrBN9+EumgmTIRiNNlzzz2Xm266iUWLFrFv376CmvMrr7xCTk4OCxcupHbt2qSmpgYcQtZXoNr56tWreeSRR/j6669p3LgxY8eOLXM7WspYT/lD0YIbjrY8TSgQHkPOWg08QqWmuluFbtkCDzwApKXBqlWx3d/ShFSDBg046aSTuPTSS4ucvPzll19o1qwZtWvXZs6cOaxdu7bU7fgO1/rdd9+xdOlSwA1FW79+fY488ki2bt3KBx98ULBOw4YN2b17d8Btvf322+zdu5c9e/bw1ltvcfzxx1fF2y3zPdTEfq0GHsEyMqBXL1i6FBjXCfLy4KefwO/2VMbUlFGjRjF8+PAiPVIuuugihg4dSkZGBj179qRT/kn3Elx11VVccskldO/enZ49e9KnTx/A3V2nV69edOnSpdhQtOPGjePMM8+kZcuWRZo50tPTGTt2bME2Lr/8cnr16lVic0kgvm3gAG+//XaZ61TFfoMR1HCyVcWGk616l13mauJbP1gEvXu7u/N4t5kyscWGk40O5RlO1ppQIlxaGmRnw89Nj3VP2IlMY2KGBXiEy/+gzlrfAI46ygLcmBhiAR7h8gN82TLcBT0W4DGtJptETdUr7+/PAjzCtWkDCQlef/D8ALd/4piUkJDA9u3bLcQjlKqyfft2EhISgl7HeqFEuPh4n9Fkh3aC3bth82ZISQl10UwNa926NRs2bMBunBK5EhISaN26ddDLW4BHgbQ0+PJL4E9e96ysLAvwGFS7du2CKwFNbLAmlCiQlgZr18Keo70GcWsHNyYmWIBHgfwTmT/sbAENG1qAGxMjLMCjQP6Fl1k/iPVEMSaGWIBHgfbt3cnMIj1RjDFRzwI8CtSp40I8KwvXnrJhg+uNYoyJahbgUSItzediHoAffwxpeYwx1c8CPEp07gwrV8LBdnZ7NWNihQV4lEhLc6PJruQY1yBuAW5M1LMAjxIFg1qtrAPHHGMBbkwMsACPEp18LsK0nijGxAYL8ChRv74b2KrgROaPP7o2FWNM1LIAjyJpaT418IMHoYpv32SMCS8W4FEkLQ2WL4fDx1pPFGNigQV4FElLg337YG09G9TKmFhgAR5FCsZE2ZwIzZpZgBsT5SzAo0ix26tlZYW0PMaY6mUBHkWSklzF27oSGhMbggpwEVkjIt+KyBIRyfSeSxKRj0RkhffYuHqLaoJR0BMlLQ22b4dt20JdJGNMNSlPDXyQqvZU1QxvfjwwW1U7ALO9eRNi+QGuHa0nijHRrjJNKMOAl7yfXwLOrXxxTGV17gw7d8KWJl3cExbgxkStYANcgf+KyEIRGec911xVNwN4j80CrSgi40QkU0Qy7W7Z1a9gTJRdrSAhAT791F3UY4yJOsEG+ABVTQfOBK4RkROC3YGqPquqGaqakZycXKFCmuAVBPjyOBgyBKZOhaOPhjvvdDd6MMZEjaACXFU3eY/ZwFtAH2CriLQE8B6zq6uQJngpKe6+xllZwIwZ8MEHcNxxcP/9kJoK558Ps2eDaqiLaoyppFplLSAi9YE4Vd3t/TwYuBd4BxgDPOg9zqzOgprgiLh28KwsIC4OzjjDTWvWwD//CZMnw5tvum6GZ5/t+h02bQrJyW7K/7lRI7cxY0zYEi2jJiYi7XC1bnCB/6qq3i8iTYDXgKOBdcCFqvpzadvKyMjQzMzMypfalOqSS2DWLNi8OcCL+/fDv/8NTz8Nixe7+UAaNnQh37mza5dJS3M/t23rbhhhjKkxIrLQpwdg4fNlBXhVsgCvGQ8/DLfdBjt2QGJiKQuqwt69kJPj+ovn5BROa9e6avyyZbBpU+E6Rxzh2mlq1XJTfHzhVKuWq8GfdRYMHera3o0xlVZSgJfZhGIiT8GJzCzo16+UBUXcQOL167v28ZL88ovbWP60aZMbazx/ys0tfFyxAq691k29esE558CwYdCzpzXJGFPFLMCjUMGgVmUFeLCOPBL69nVTMH74Ad55x0333gv33AOtW8Ppp7smmKOOKpxat3bdHY0x5WYBHoVSU11LR8jGsurUyU233grZ2fD++zBzppsCXdqfnAw9esC0aa4JxhgTFAvwKBQfDx07eqMShlqzZjB2rJvADVi+YQOsX184rVsHL74IV1/tuj5aU4sxQbEAj1JpabBgQahLEUDdutChg5t8tW0LEybAeefBqFGhKZsxEcaGk41SnTu7rt/79oW6JEH6059cG/s11xTt9WKMKZEFeJRKS3O9BJcvD3VJglSrFrz8suuXftlldqWoMUGwAI9SRe7OEyk6dHCd2GfNgueeC3VpjAl7FuBRqkMHdyV9ZmaEVWavvhpOOQVuuglWrQp1aYwJaxbgUeqII6BrV5g4EVq0cOcFn3/etYuHtbg4mDLFdaUZO9ZdIGSMCcgCPIp99JHLwsGD4ZNP4PLLXWePY46BcePg9ddh165QlzKAo46CSZPgs8/gscdCXRpjwpaNhRIjVN2FPbNnw//+5wJ91y537vD4493AhGef7fqPh0U3bFXXpXDWLFi0qPDyUmNikA1mZYrIzYWvvoL33nPTd9+559u1c/eB6NcPmjcvHGW2SRMX9jUqOxu6dIE2bWDevBAUwJjwYAFuSrV2bWGYf/xx8VFmRaBxYxfmHTq4kD/nHGjZspoLNmUKXHqp+7QJdiwWY6KMjUZoStWmjesAcvXVboTZVauKji6bP2VnuxaNd9+FK6+EPn3cYIPDhrlWjipvfunZ0z0GHNzcmNhmAW6KqVfP9WApiSp8/33h+FR//rObjjnGnTDt0MGdLM2fGjWqRGFatHCPW7ZUYiPGRCcLcFNuIi7gu3Z1wb1xI/znPy7Mp06F3buLLt+kiQvy1FR3L4iWLYs/Nm5cQu09Odm9YAFuTDEW4KbSWrVyzSlXXulq5z//DKtXu2nVqsKfly6FDz8sHvDgTpguWwZJSX4v5N/lZ+vWGnkvxkQSC3BTpURcjbtJE8godsrF2bPHNWlv2uQeFy+Ghx5y3b6HDQuwQosWVgM3JgC7kMfUuPr1oX17OOEEGDEC7r4b6tSBL74oYQULcGMCsgA3IZeQAL17W4AbU14W4CYs9O/vBt46cCDAi82buwCPqFG5jKl+FuAmLAwYAAcPwsKFAV5s0cIle1gO3GJM6FiAm7DQv797DNiMYn3BjQnIAtyEhebN3YVAX34Z4EULcGMCsgA3YWPAAFcDL9bUbQFuTEAW4CZsDBjgxltZudLvhebN3aMFuDFFWICbsJHfDl6sGSUpyV2RaVdjGlOEBbgJG507Q2JigBOZcXGFXQmNMQWCDnARiReRxSLyrjffVkTmi8gKEZkhInWqr5gmFsTFuRtJlNgTxQLcmCLKUwO/HsjymX8ImKiqHYAdwGVVWTATm/r3d4Na/fyz3wsW4MYUE1SAi0hr4GxgsjcvwMnA694iLwHnVkcBTWwZMMA9zpvn94I1oRhTTLA18MeAW4HD3nwTYKeq5nrzG4BWVVw2E4P69IH4+ADNKC1auNsBHT4ccD1jYlGZAS4iQ4BsVfW9yDnQ0PsBB6oQkXEikikimTk5ORUspokV9etDr14lBHheHmzfHpJyGROOgqmBDwDOEZE1wHRc08ljQKKI5I8n3hrYFGhlVX1WVTNUNSM5ObkKimyiXf/+sGABHDrk86RdzGNMMWUGuKrerqqtVTUVGAl8rKoXAXOAC7zFxgAzq62UJqYMGAD79sGSJT5PWoAbU0xl+oHfBtwkIitxbeLPV02RTKwLOLCVXY1pTDHlCnBV/URVh3g/r1LVPqraXlUvVNVAIzkbU26tW8PRR/tdkZlfA7erMY0pYFdimrBUbGCrhg2hbl2rgRvjwwLchKUBA9xNj9eu9Z4QsYt5jPFjAW7CUsCBrSzAjSnCAtyEpW7doEGDACcyLcCNKWABbsJSrVrQt69fgLdoYScxjfFhAW7CVv/+8O23PvcybtECtm3zu8LHmNhlAW7C1oABbuiT+fO9J/K7EmZnh6xMxoQTC3ATtvr2dWOEFzSj2NWYxhRhAW7CVqNG7mRmQU8UuxrTmCIswE1Y69/fjQ2el4ddjWmMHwtwE9b694fdu91deqwGbkxRFuAmrLVv7x7XrcNdSn/kkRbgxngswE1YS0lxj5vyR5u3qzGNKWABbsJay5busSDA7WpMYwpYgJuwVrs2NGvmVwO3k5jGABbgJgKkpFgTijGBWICbsFcswHftgr17Q1omY8KBBbgJe8UCHKwZxRgswE0ESElxeZ2bi/UFN8aHBbgJeykp7tZqW7ZgNXBjfFiAm7BXpC+4DWhlTAELcBP2WrVyj5s2AcnJ7v6YFuDGWICb8FekBl67NjRtagFuDBbgJgIkJ0N8vPUFN8afBbgJe/HxLrOLXE5vJzGNsQA3kcGuxjSmOAtwExECBrhqSMtkTKhZgJuIUCzA9+/3uV29MbHJAtxEhFatYPt2l9vWF9wYxwLcRIT8roSbN1N4Ob2dyDQxrswAF5EEEVkgIt+IyPcico/3fFsRmS8iK0RkhojUqf7imlhlV2MaU1wwNfADwMmq2gPoCZwhIn2Bh4CJqtoB2AFcVn3FNLHOAtyY4soMcHV+9WZre5MCJwOve8+/BJxbLSU0Br8AT0qCWrUswE3MC6oNXETiRWQJkA18BPwE7FTVXG+RDUCr6imiMS6z69TxAjwuzu6NaQxBBriq5qlqT6A10AdIC7RYoHVFZJyIZIpIZk5OTsVLamKaiF9XQrsa05jy9UJR1Z3AJ0BfIFFEankvtQY2lbDOs6qaoaoZycnJlSmriXF2NaYxRQXTCyVZRBK9n+sCpwJZwBzgAm+xMcDM6nJbwtMAABQvSURBVCqkMeD6gm/c6M1YgBsTVA28JTBHRJYCXwMfqeq7wG3ATSKyEmgCPF99xTQmQA1861Y4fDikZTImlGqVtYCqLgV6BXh+Fa493JgakZICu3e7qWGLFpCX5y7PtKY5E6PsSkwTMexqTGOKsgA3EcMu5jGmKAtwEzEswI0pygLcRAwLcGOKsgA3EaNhQ6hf3wvwhg2hbl0LcBPTLMBNxBBxfcE3bfJm7HJ6E+MswE1ESUnxu5jHeqGYGGYBbiKKXU5vTCELcBNR8gNcFQtwE/MswE1ESUlx98XcuRMX4Nu2waFDoS6WMSFhAW4iSpGuhPlXY2Znh6w8xoSSBbiJKAH7gq9eHbLyGBNKFuAmohQJ8Pbt3cyJJ8KgQfDkkz5dVIyJfmWORmhMOCkS4GO6wtKl8Npr8MYbcN11burbF84/H4YOhQMHYNUqV0vPf1y9GjZscKF/663Qv39I35MxFSWqAe+EVi0yMjI0MzOzxvZnolNSElx0ETzxhN8LWVnw5psuzBcvLr5iw4bQrh20bQtNmrhld+xwAX7rrS7w4+xLqQk/IrJQVTOKPW8BbiJN165w7LEuf0u0ejV89BEkJrrAbtfOJb9I4TJ79sALL8Df/w5r10LHjnDLLTB6NCQkVPv7MCZYFuAmagweDLt2wbx5VbTB3Fx4/XV4+GFXc2/eHIYMgfR0N3XvDvXqVdHOjCm/kgLc2sBNxElJgR9+qMIN1qoFI0fCiBHw8ccwaRK8/TY8790lMC4OOnVyYd6rF5x3nqvVl8eqVbBggevy6Dvl5LjHLl3gxRfdNwZjgmQBbiJOSoq7K8/hw1XcZC0Cp5ziJlVYvx4WLXK18kWLXLhPnQoTJsDNN8Ptt0ODBqVvc8cOuPde10MmN9c9FxfnbgPXrJmbevaEmTNdb5pZs6Blyyp8Uyaa2RkbE3FSUlwWbttWjTsRgaOPhnPPhXvugf/8x3VRXL0aLrgAHnjAtZm/8op3Xb+f3Fz4xz+gQwd4/HG45BL45htX4z50yA0BsHQp/O9/8O9/w7vvwk8/uROqK1ZU4xsz1WLDBnj2WTh4sEZ3awFuIk6rVu6xYFCrmpSa6mrhX3zhasqjR8PAgbBwYeEyH33katXXXAPdurna+7PPurb0pk0Df20YPBjmzIFff4UBA6Cy54omTYKMDJg/v3LbCVd79rgmr/btoXdv961p+HD3QXnDDXD33fDWW4XfeoL188/lH+FyzRo4/ni44go44QRYt65861eGqtbY1Lt3bzWmsubNUwXV994LcUHy8lSff161WTNVEdVLL1UdMsQVrl071TffVD18uHzbXL5ctU0b1QYNVP/734qV6aabXBkSElRr11adNKn85Qhnu3apnnCCalyc6vnnq559tuqAAapdu6oedZRqo0bu/YPq0UerPvSQ6vbtJW/v8GHVzz5THT1a9Ygj3DGbPDm4sqxa5X5fjRurPvywasOGqk2aqM6aVSVvNR+QqQEy1QLcRJx169xf7nPPhboknp07VW++WbVWLfcP/NBDqvv3V3x7GzeqduvmgmTatODX279fdeRId3CuuUY1J8eFG7jnd++ueJkOH1adPdt9SI0fr/ryy6qZmaq//lrxba5fr3rXXappaaqXXab6yy9lr7Njh2rfvqrx8aUfm0OHVN9+W3XQIPf+69VTvfJK1WXLim5r0iTVzp3dMo0aqV59teppp7n5665TPXiw5H389JP7gEhKUl20yD23fLn73Ymo/uUvqrm5QR2KsliAm6hx8KD7y73nnlCXxM/mzao//1w129qxQ/X4490bvf/+ssN3587CsHrwwcIad16e6gMPuNpqp06q339fvnLk5anOnKn6m98UhlytWoU1XFBNTVU96yzVW25RnTpVNSvLrRdIbq7qu++qDh3qyiSi2q+f+zk1VXXu3JLLsn27au/e7oPtzTeDfw/ffOM+eI44wpV38GDVMWNU69Z188cd52rc+R9Ghw4Vfos5+WTVbduKb3PlStXWrV14L15c9LU9e1THjnXrn3aaanZ28GUtgQW4iSrNmqmOGxfqUlSzvXtVhw93/6YNG7ra4dKlxZfbuFG1e3cXrC+/HHhbH3/sDlq9eqqvvFL2vg8dcst17VoY0k8/rbpvn/sEXbZM9fXXVe+7T3XUKNUePQoDElwT0PHHq95wg+q//qX69deq997raqyg2ry56u23uyYIVdXPP3fNTiKqt91W/BtMdrZ7j0cc4T4AKiI7W/Wvf1VNSXHlGzdOdeHCkpd/6SW3v7Ztix73FStUW7VyTSVLlpS8/vPPu2asVq1Uv/iiYmX2WICbqNKzp2tujnqHD6t++aXqxRcXBmT//i4U9+1zNeqjjw6uzXzjRtWBA902fv971b//XfWJJ1SfeUZ1yhQX2P/+t3uuXTu3XJcurlZ96FDZZT10yAXdlCmq117ratb5tdz86dRT3T4OHCi+/q5dqpdf7pbr0UP122/d85s2uWaOunVVP/ywvEewuNzcwPsPZN481ZYtVevXd7X+H390HwBNm7qafVkWL1Y95hj34Tp/foWLbAFuospZZ6mmp4e6FDVs2zYXuh06uH/dpCTVxERXm81vgy3LwYOuqSMurmiw+k99+rg25JKaQoJ16JAL4mnTXM01GDNnqiYnuw+s++5z77d+fdU5cypXlorauNEdD3DHu2nTwN+ESrJjh2vGqsSxLCnA7VJ6E5H+8AfXdXrz5lCXJAQOH3ZdDp9+2vVNf/XV8l8ZeuCAmw4eLHzMn2rVclee+o4bU9Oys90v+Z13oFEj+OCD0I4auX8/XH2167f//vtuQJ4aZJfSm6jSqpXrrpub6/ImpsTFFV4xWlFHHOGmcNWsmRvO4K233MhlNRyYxSQkuIHPVEP7weYn1v70TZRISXH/S1u3Fl7YY6KMiLs4J5yEUXhDEFdiishRIjJHRLJE5HsRud57PklEPhKRFd5j4+ovrjFOkRs7GBOjgrmUPhe4WVXTgL7ANSLSGRgPzFbVDsBsb96YGmEBbkwQAa6qm1V1kffzbiALaAUMA17yFnsJOLe6CmmMv/wAt1tgmlhWrsGsRCQV6AXMB5qr6mZwIQ80K2GdcSKSKSKZOTk5lSutMZ7kZIiPtxq4iW1BB7iINADeAG5Q1V3Brqeqz6pqhqpmJCcnV6SMxhQTHw8tWliAm9gWVICLSG1ceL+iqvl3ItwqIi2911sC2dVTRGMCS0mxADexLZheKAI8D2Sp6qM+L70DjPF+HgPMrPriGVOyVq0swE1sC6YGPgC4GDhZRJZ401nAg8BpIrICOM2bN6bGWA3cxLoyL+RR1c+BknqvV+JSMGMqJyUFtm93V4KH80WFxlQXu6WaiVj5XQljcjwUY7AANxEsP8BnzHC1cGNijQW4iVj9+rn72Y4f7+41/MAD7p60xsQKC3ATsRo1gq+/hv/+193w/c9/hqOOguuug59+CnXpjKl+FuAmoonAaafBhx/C0qXw29/CM89Ahw5w/vmweHGoS2hM9bEAN1GjWzeYMgXWrHHNKh9/DOnpcOGFkJUV6tIZU/UswE3USUlx7eGrV8Odd8KsWe5+AGPGwKpVoS6dMVXHAtxErcREuPdeF9o33QSvvQYdO8JVV9kohiY6WICbqJecDP/3f+7E5rhx8PzzcMwxcO21rpZuTKSyADcxIyUFnnoKfvwRRo+GZ591JzsvusidADXVQxVefNGdmzBVywLcxJzUVJg82dW+b7zR3fi8Rw846yz49FMXOKbqTJ8Ol1wCJ51kY9dUNQtwE7NatXJNK+vWwf33Q2amC5l+/VyoW5BX3i+/uPMPaWlu3JozzoCdO0NdquhhAW5iXuPGMGECrF0L//gHZGfDsGHQsyf8+9+QlxfqEkauO++ErVvhX/+Ct96CH36AoUNh375Qlyw6WIAb46lb1/VQ+fFHePllN77Kb3/ruiBOnQq5uSWve/CgCye7lL/QokXunMPVV7shD0491R3HL76AkSNLP54mOKI1+D0xIyNDMzMza2x/xlRGXh688Qb89a/w7bfQrh3cfju0bw/Ll7vpxx/d4+rVbvlateD002HUKFeLb9Ag1O8iNPLyoH9/963mhx9cl858Tz3legBdeqk7FyElDVZtCojIQlXN8H++zPHAjYlV8fGuBn7BBfDuu3DfffCHPxS+XrcuHHss9OrlapQdOsD338O0afDee+71c86B3/3Otf3WqVO+/eflwbJlrgmiTRs4+ujIGfd88mRYsMDVuH3DG+Caa9x7uu8+aNYM/va30JQxGlgN3JggqcLnn8P+/e6CoNatIS5AI+Thw66ZYNo0d/HQ9u0uxE4+2QV+hw6FU/PmhTXQnTth/nz48kv46iuYNw927y667ZYtXZi3aeN60xx1lOvn3rRp4WPTplC7dmFZcnJc74/Nm93jpk3u+T/+EZKSqv44ZWdDp06uZ8/HHweuYau65qpnnoGJE+GGG6q+HNGkpBq4Bbgx1ejQIfjoIxfmCxa4q0J9234bNnRNMgcPutq2qvtQ6NbNNUH06+c+KNavd80Ra9YUPq5b57YfSGKi+waQkxO4rVnEfRi89JJrm65KY8fCq6/CN9+43iclycuDESNcM9Vtt8H117symeIswI0JA7m5LoBXrCg6xcW5sO7XD/r0ccFelvza9bZt7tH3523bYO9eaNHChWJKiptatnTPffedu5gpK8sF59/+5gK/subOhRNPdOcKHnig7OX373dt4dOnu/MHo0a5vvk9e1a+LNHEAtwYU8S+fa7m+8QT0KULvPKKa/aoqEOH3PmAX3913ybq1Qt+3RUrYNIkN5rknj2uP/6NN8KQIYGbqWJNSQFuh8aYGFW3rgvNWbNc98fjjnMXNlW03/tjj7mTuJMmlS+8wZ0PeOIJ2LABHn7YjVszbJg71/Dyy3ZRVUkswI2Jcaef7rpJDh0Kt97qar/PP+9qxWUFZ06O62nyu9+5i3aGDnU9byoqMRH+9Cd3rmDGDDc/ZgwMGuS6I1YHVfetYf16dxzWraue/VQHa0IxxgAuyF56ybVfb9ninmveHE44oXDq3NldoPP++/DBB+6WdqquO+BZZ7m29BYtqq5Mhw+7D5Nbb3VNK7fd5q6aLW97fV6ea/f/8ks3rVgBO3a4aefOoieDRdzdnCZMcE1ClZWb6/bXsWPFm4OsDdwYExRVd4HS3Llu+vRTVzsF1zc+L8+FXN++cOaZLrh79aretursbLjlFndJfrt2bsiD008vufw5ObBkSWFg+3bJbN7c9fJJSnLDKPhPixfDk0/Crl3u/U2YAAMHBlfOnTtd75v8aelS98Gxf787ph06VOz9W4AbYyps7VoX5t98425TN3iw629e0z7+uHC4gxEjYPhwV7bVq13Xyvwpf6yVuDh3w+v+/Qun1NSyr/785Rd3xejEia5HzwknuCAfPNgNsbB6NaxcWXT64YeizS9Nm7qTwj16uDKcc477gKgIC3BjTFQ4cAAeesh1UzxwwD3XuDG0bevCOTXV/ZyWFnyXzJLs3QvPPedO7m7cCE2auBO+vrF55JGFF2Z1714Y2i1bVt0wARbgxpiosmmTaypJTXUhWp0OHHDNN1984fbXvn3hlJRU/eO5WIAbY0yEsn7gxhgTZSzAjTEmQpUZ4CLygohki8h3Ps8lichHIrLCe6zguVVjjDEVFUwN/EXgDL/nxgOzVbUDMNubN8YYU4PKDHBVnQv43yhqGPCS9/NLwLlVXC5jjDFlqGgbeHNV3QzgPTYraUERGScimSKSmZOTU8HdGWOM8VftJzFV9VlVzVDVjOTk5OrenTHGxIyKBvhWEWkJ4D1mV12RjDHGBKOiNzV+BxgDPOg9zgxmpYULF24TkbUV3GdTYFsF1412dmxKZscmMDsuJQvHY9Mm0JNlXokpItOAk3BvaitwF/A28BpwNLAOuFBV/U90VikRyQx0JZKxY1MaOzaB2XEpWSQdmzJr4Ko6qoSXTqnishhjjCkHuxLTGGMiVCQF+LOhLkAYs2NTMjs2gdlxKVnEHJsaHY3QGGNM1YmkGrgxxhgfFuDGGBOhIiLAReQMEVkuIitFJKYHzrLRIQMTkaNEZI6IZInI9yJyvfe8HRuRBBFZICLfeMfmHu/5tiIy3zs2M0SkTqjLGgoiEi8ii0XkXW8+Yo5L2Ae4iMQDTwFnAp2BUSLSObSlCqkXsdEhA8kFblbVNKAvcI33d2LHBg4AJ6tqD6AncIaI9AUeAiZ6x2YHcFkIyxhK1wNZPvMRc1zCPsCBPsBKVV2lqgeB6bjREGOSjQ4ZmKpuVtVF3s+7cf+QrbBjgzq/erO1vUmBk4HXvedj8tiISGvgbGCyNy9E0HGJhABvBaz3md/gPWcKBT06ZCwQkVSgFzAfOzZAQTPBEty4RR8BPwE7VTXXWyRW/68eA24FDnvzTYig4xIJAR7ofs/W99EEJCINgDeAG1R1V6jLEy5UNU9VewKtcd9q0wItVrOlCi0RGQJkq+pC36cDLBq2x6Wig1nVpA3AUT7zrYFNISpLuNoqIi1VdXMsjw4pIrVx4f2Kqr7pPW3Hxoeq7hSRT3DnCRJFpJZX24zF/6sBwDkichaQADTC1cgj5rhEQg38a6CDd2a4DjASNxqiKZQ/OiSUY3TIaOK1XT4PZKnqoz4v2bERSRaRRO/nusCpuHMEc4ALvMVi7tio6u2q2lpVU3G58rGqXkQEHZeIuBLT+4R8DIgHXlDV+0NcpJAJl9Ehw42IDAQ+A76lsD1zAq4dPNaPTXfcybh4XKXtNVW9V0Ta4ToFJAGLgdGqeiB0JQ0dETkJuEVVh0TScYmIADfGGFNcJDShGGOMCcAC3BhjIpQFuDHGRCgLcGOMiVAW4MYYE6EswI0xJkJZgBtjTIT6f5BrbwakjZq9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train_draw=[]\n",
    "Valid_draw=[]\n",
    "for i in range(0,len(train_mse)):\n",
    "    if i%3==0:\n",
    "        Train_draw.append(train_mse[i])\n",
    "        Valid_draw.append(validation_mse[i])\n",
    "\n",
    "plt.title(\"Training vs. Validation Error\", fontsize=14)\n",
    "#plt.legend(loc=\"lower right\")\n",
    "plt.plot(Train_draw[1:], markersize=10, label=\"Training Error\",color='red')\n",
    "plt.plot(Valid_draw[1:], markersize=10, label=\"Validation Error\",color='blue')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('Training vs Testing Error.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpSktO3hsFvd"
   },
   "source": [
    "### Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MESF4QjsFve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints-conn_beg\\har.ckpt\n",
      "25\n",
      "Sum_test shape: (25, 128, 1)\n",
      "Sum_test_1 shape: (25, 1)\n",
      "Sum_test_2 shape: (1,)\n",
      "\tRMSE Testing: [12.546811]\n"
     ]
    }
   ],
   "source": [
    "Test_Error=[]\n",
    "with tf.Session(graph=lstm_graph) as sess: \n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-conn_beg'))\n",
    "    test_batch_features,test_batch_y=batch_features_labels(X_Test_Full,Y_Test_Full,batchsize)\n",
    "    #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "    #combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
    "    #random.shuffle(combined)\n",
    "    #shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "    #===========================================================================================\n",
    "    print(len(test_batch_features))\n",
    "    \n",
    "    for i in range(0,len(test_batch_features)):\n",
    "        batch_features_test=test_batch_features[i]\n",
    "        #print(batch_features)\n",
    "        batch_y_test=test_batch_y[i]\n",
    "        batch_features_test=np.delete(batch_features_test, [0], axis=2) \n",
    "        #print('X',len(batch_features[0]))\n",
    "        #print('Y',len(batch_y[0]))\n",
    "        Test_Batch_error,y_predict_test,summary=sess.run([Error,outputs,merged_summary_op],\n",
    "                                             feed_dict={\n",
    "                                                 keep_prob:keep_prob_testval,\n",
    "                                                 X: batch_features_test,\n",
    "                                                 y: batch_y_test,\n",
    "                                                 learning_rate: l_rate,\n",
    "                                                 is_train:False})\n",
    "\n",
    "        #print('error:',Train_Batch_error[0])\n",
    "        Test_Error.append(Test_Batch_error)\n",
    "\n",
    "    Sum_test=np.sum(Test_Error,axis=2)\n",
    "    Sum_test_1=np.sum(Sum_test,axis=1)\n",
    "    Sum_test_2=np.sum(Sum_test_1,axis=0)\n",
    "    print('Sum_test shape:',Sum_test.shape)\n",
    "    print('Sum_test_1 shape:',Sum_test_1.shape)\n",
    "    print('Sum_test_2 shape:',Sum_test_2.shape)\n",
    "    Mean_test=Sum_test_2/(len(Test_Error)*batchsize*num_periods_output)\n",
    "    print(\"\\tRMSE Testing:\", (Mean_test)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15SGHOrMsFvg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2211_Conn_Beg_EventLSTM_validation_BIRM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
