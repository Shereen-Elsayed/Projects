{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1574420305497,
     "user": {
      "displayName": "daniela thyssens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAjESWh9r_JpJu7Y-DtgOWeyh4Y6Cw-yuE0sVSv5Q=s64",
      "userId": "06737456205702308294"
     },
     "user_tz": -60
    },
    "id": "PuuRX58dsI_3",
    "outputId": "dfed3b53-8889-455d-e431-2ea00ac8e090"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVbzKDghsFuf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version\n",
    "#Import Libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "from random import shuffle\n",
    "#TF Version\n",
    "tf.__version__\n",
    "\n",
    "#np.random.seed(1)\n",
    "#tf.random.set_random_seed(1)\n",
    "#with warnings.catch_warnings():\n",
    "#    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "#    import h5py\n",
    "\n",
    "#num_periods_output = 4 #to predict\n",
    "#num_periods_input=8 #input\n",
    "\n",
    "ALL_Test_Data=[]\n",
    "ALL_Test_Prediction=[]\n",
    "Event_Based_StartIndex=0\n",
    "Number_of_EventBased=0\n",
    "Number_of_TimeFeatures=15\n",
    "\n",
    "\n",
    "No_Of_weeks=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VWsYwOysFuq"
   },
   "source": [
    "<h5>Preprocessing data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnP7bj4HsFut"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def preprocessing(df_,num_features):\n",
    "    \n",
    "    #cols=df.columns\n",
    "    #df_part=df[['Occupancy_m5', 'Occupancy_m6', 'Occupancy_m7']]\n",
    "    #print(cols[20:])\n",
    "    \n",
    "    # get year, month,Day,Hour,Minute\n",
    "    df_['LastUpdated'] = pd.to_datetime(df_['LastUpdated'])\n",
    "    df_['Year'] = df_['LastUpdated'].dt.year\n",
    "    df_['Month'] = df_['LastUpdated'].dt.month\n",
    "    df_['Day'] = df_['LastUpdated'].dt.day\n",
    "    df_['Hour'] = df_['LastUpdated'].dt.hour\n",
    "    df_['Minute'] = df_['LastUpdated'].dt.minute\n",
    "    \n",
    "    #,'Month','Day','Hour','Minute'\n",
    "    # select features\n",
    "    df=df_[['ID','Occ_percent','Month','Day','Hour','Minute',\n",
    "           'temperature','dew_point','humidity','wind_speed',\n",
    "           'feels_like','Events_Football_City','Events_Football_Derby',\n",
    "           'Events_Football_Aston','Events_Rugby']]\n",
    "    \n",
    "    cols=df.columns\n",
    "    print(cols[20:]) \n",
    "    \n",
    "    ################################################encoding########################\n",
    "    df['Occ_percent'] = pd.to_numeric(df['Occ_percent'],errors='coerce')\n",
    "    df['Occ_percent'] = df['Occ_percent'].abs()\n",
    "    \n",
    "    \n",
    "    \n",
    "    Number_Of_Features=num_features\n",
    "    df=df.values\n",
    "    df = df.astype('float32')\n",
    "    split=num_periods_output+num_periods_input\n",
    "    \n",
    "    \n",
    "    ##################################SPLIT##############################################\n",
    "    print('LEN DF BEFORE CUTTING ANYTHING',len(df))\n",
    "     ########################## SPLITTING FOR TESTING & VALIDATION ##########################\n",
    "    #test_len=np.floor(len(df)*0.2)\n",
    "    test_val_len=np.floor(len(df)*0.2)\n",
    "    #mod=test_len%(num_periods_input+num_periods_output)\n",
    "    mod=test_val_len%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    test_val_len=int(test_val_len-mod)\n",
    "    Test_Val=df[(len(df)-test_val_len):,:]\n",
    "    \n",
    "    ############################ VALIDATION & TESTING ##################################\n",
    "    valid_len=np.floor(len(Test_Val)*0.5)\n",
    "    Valid=Test_Val[0:(len(Test_Val)-int(valid_len)),:]\n",
    "    Test=Test_Val[(len(Test_Val)-int(valid_len)):,:]\n",
    "    #Valid=Test[0:(len(Test)-int(valid_len)),:]\n",
    "    \n",
    "    \n",
    "    ########################### SPLITTING FOR TRAIN ###########################\n",
    "    \n",
    "    new_cutted_df=df[:(len(df)-test_val_len),:]\n",
    "    Start_train_index=17*7*No_Of_weeks\n",
    "    #Start_train_index=12*24*1 # 1 day\n",
    "    Start_train_index=np.floor(Start_train_index)\n",
    "    Start_train_index=int(Start_train_index)\n",
    "    print('instances',Start_train_index)\n",
    "    Train=new_cutted_df[len(new_cutted_df)-Start_train_index:,:]\n",
    "    print('len new_cutted - start_train_ind',len(new_cutted_df)-Start_train_index)\n",
    "    train_len=len(Train)\n",
    "    mod=train_len%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    train_len=int(train_len-mod)\n",
    "    Train=Train[0:train_len,:]\n",
    "    print('len Train',len(Train))\n",
    "   \n",
    "        \n",
    "    #############################  Normalization on train and validation separatly  #############\n",
    "     \n",
    "    ID_Train=Train[:,0]\n",
    "    Train=np.delete(Train,[0],1)\n",
    "    #x_batches=x_batches.drop(columns=['ID'], axis=1)\n",
    "    occ_Train=Train[:,0]\n",
    "    Train=np.delete(Train,[0],1)\n",
    "    #x_batches=x_batches.drop(columns=['Occupancy'], axis=1)\n",
    "    #normalizing data\n",
    "    Train = Train.astype('float32')\n",
    "    normalizer = Normalizer().fit(Train)\n",
    "    Train=normalizer.transform(Train)\n",
    "    \n",
    "    ID_Valid=Valid[:,0]\n",
    "    Valid=np.delete(Valid,[0],1)\n",
    "    #X_test=X_test.drop(columns=['ID'], axis=1)\n",
    "    occ_Valid=Valid[:,0]\n",
    "    Valid=np.delete(Valid,[0],1)\n",
    "    #X_test=X_test.drop(columns=['Occupancy'], axis=1)\n",
    "    Valid = Valid.astype('float32')\n",
    "    Valid=normalizer.transform(Valid)\n",
    "    #------------------\n",
    "    ID_Train=np.reshape(ID_Train,(len(ID_Train),1))\n",
    "    occ_Train=np.reshape(occ_Train,(len(occ_Train),1))\n",
    "    \n",
    "    Train=np.append(occ_Train, Train, axis=1)\n",
    "    Train=np.append(ID_Train, Train, axis=1)\n",
    "    #------------------\n",
    "    ID_Valid=np.reshape(ID_Valid,(len(ID_Valid),1))\n",
    "    occ_Valid=np.reshape(occ_Valid,(len(occ_Valid),1))\n",
    "    \n",
    "    Valid=np.append(occ_Valid,Valid, axis=1)\n",
    "    Valid=np.append(ID_Valid, Valid, axis=1)\n",
    "\n",
    "    ############################################ TRAIN minibatches ##################################\n",
    "    \n",
    "    end=len(Train)\n",
    "    start=0\n",
    "    next=0\n",
    "    x_batches=[]\n",
    "    y_batches=[]\n",
    "    \n",
    "    count=0\n",
    "    #print('lennnn',len(Train))\n",
    "    while next+(num_periods_input+num_periods_output)<end:\n",
    "        next=start+num_periods_input\n",
    "        x_batches.append(Train[start:next,:])\n",
    "        y_batches.append(Train[next:next+num_periods_output,1])\n",
    "        start=start+1\n",
    "    y_batches=np.asarray(y_batches)\n",
    "    y_batches = y_batches.reshape(-1, num_periods_output, 1)   \n",
    "    x_batches=np.asarray(x_batches)\n",
    "    x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
    "    print('len x_batches ',len(x_batches))\n",
    "    \n",
    "    ############################################ VALID minibatches ##################################\n",
    "    \n",
    "    end_val=len(Valid)\n",
    "    start_val=0\n",
    "    next_val=0\n",
    "    x_validbatches=[]\n",
    "    y_validbatches=[]\n",
    "    \n",
    "    while next_val+(num_periods_input+num_periods_output)<end_val:\n",
    "        next_val=start_val+num_periods_input\n",
    "        x_validbatches.append(Valid[start_val:next_val,:])\n",
    "        y_validbatches.append(Valid[next_val:next_val+num_periods_output,1])\n",
    "        start_val=start_val+1\n",
    "    y_validbatches=np.asarray(y_validbatches)\n",
    "    y_validbatches = y_validbatches.reshape(-1, num_periods_output, 1)   \n",
    "    x_validbatches=np.asarray(x_validbatches)\n",
    "    x_validbatches = x_validbatches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
    "\n",
    "    ###########################################TEST#####################################\n",
    "    \n",
    "    ID_Test=Test[:,0]\n",
    "    Test=np.delete(Test,[0],1)\n",
    "    #X_test=X_test.drop(columns=['ID'], axis=1)\n",
    "    occ_Test=Test[:,0]\n",
    "    Test=np.delete(Test,[0],1)\n",
    "    #X_test=X_test.drop(columns=['Occupancy'], axis=1)\n",
    "    Test = Test.astype('float32')\n",
    "    Test=normalizer.transform(Test)\n",
    "    \n",
    "    #------------------\n",
    "    ID_Test=np.reshape(ID_Test,(len(ID_Test),1))\n",
    "    occ_Test=np.reshape(occ_Test,(len(occ_Test),1))\n",
    "    \n",
    "    Test=np.append(occ_Test,Test, axis=1)\n",
    "    Test=np.append(ID_Test, Test, axis=1)\n",
    "    \n",
    "    ############################################ TEST minibatches ##################################\n",
    "    end_test=len(Test)\n",
    "    start_test=0\n",
    "    next_test=0\n",
    "    x_testbatches=[]\n",
    "    y_testbatches=[]\n",
    "    \n",
    "    \n",
    "    #print('lennnn',len(Train))\n",
    "    while next_test+(num_periods_input+num_periods_output)<end_test:\n",
    "        next_test=start_test+num_periods_input\n",
    "        x_testbatches.append(Test[start_test:next_test,:])\n",
    "        y_testbatches.append(Test[next_test:next_test+num_periods_output,1])\n",
    "        start_test=start_test+1\n",
    "    y_testbatches=np.asarray(y_testbatches)\n",
    "    y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)   \n",
    "    x_testbatches=np.asarray(x_testbatches)\n",
    "    x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features) \n",
    "    print('len Test',len(Test))\n",
    "    print('len xTestbatches',len(x_testbatches))\n",
    "    ######################## Sampling##########################################\n",
    "    \n",
    "    #x_batches, y_batches, x_validbatches, y_validbatches, x_testbatches, y_testbatches\n",
    "    \n",
    "    return x_batches, y_batches,x_validbatches, y_validbatches, x_testbatches, y_testbatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmhRJEHVsFu1"
   },
   "outputs": [],
   "source": [
    "def load_locationfiles(path,loc_id):\n",
    "    filename=path + '/Birm'+str(loc_id)+'.csv'\n",
    "    print(filename)\n",
    "    data_loc=pd.read_csv(filename)\n",
    "    #mod=len(data_loc)%(num_periods_input+num_periods_output)\n",
    "    #let thelength be divisable by 12\n",
    "    #data_loc=data_loc[:len(data_loc)-mod]\n",
    "    return data_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MYuE1zOsFu8"
   },
   "source": [
    "# Creating Tensorflow Graph + Run Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKje0imlsFu_"
   },
   "source": [
    "##### Training Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nso4-lghsFvB"
   },
   "outputs": [],
   "source": [
    "##### Prediction Params #####\n",
    "num_periods_output = 2    #to predict (1h)\n",
    "#12\n",
    "num_periods_input= 4      #input (2h)\n",
    "#24\n",
    "#num_periods = 4           #number of periods per vector we are using to predict one period ahead\n",
    "\n",
    "##### Graph Params #####\n",
    "inputs = Number_of_TimeFeatures-1                #number of vectors submitted\n",
    "hidden = 128               #number of neurons we will recursively work through, can be changed to improve accuracy\n",
    "hidden_event=128\n",
    "output = 1                 #number of output vectors\n",
    "num_layers=1\n",
    "num_layers_EventBased=1\n",
    "\n",
    "##### Static Features #####\n",
    "Number_Of_Static_Features=30\n",
    "no_sequences=128            #re-iterating factor for static features\n",
    "\n",
    "##### Optimization Params #####\n",
    "batchsize=128\n",
    "#init_epoch=3              #number of epochs using the constant init_learning_rate\n",
    "#initial_LR=0.0003\n",
    "#learning_rate_decay=0.95\n",
    "l_rate = 0.00005         #small learning rate so we don't overshoot the minimum\n",
    "keep_prob_static=0.7       #number of epochs using the constant init_learning_rate\n",
    "keep_prob_event=0.7\n",
    "lamda=0.01                #regularization param \n",
    "keep_probab=0.9            #(1-dropout_rate)\n",
    "keep_prob_testval=1.0      #(1-dropout_rate) for testing and validation runs\n",
    "epochs = 600               #number of iterations or training cycles, includes both the FeedFoward and Backpropogation\n",
    "#250                \n",
    "\n",
    "\n",
    "#where to save logs\n",
    "#logs_path = '/tmp/tf_logs_3_LSTM_Fully_0410_ConnEnd_Shift_FSTop3/example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkLBQDYosFvI"
   },
   "outputs": [],
   "source": [
    "# model decaying learning rate, instead of fixed one\n",
    "#def compute_LR(init_epoch,max_epoch,learning_rate_decay,init_learning_rate):\n",
    "#    LR_to_use = [\n",
    "#        init_learning_rate * (\n",
    "#            learning_rate_decay ** max(float(i+1-init_epoch),0.0)\n",
    "#        ) for i in range(max_epoch)\n",
    "#    ]\n",
    "#    print(\"Middle LR:\", LR_to_use[len(LR_to_use) // 2])\n",
    "#    return LR_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPKeQOzb2ocE"
   },
   "outputs": [],
   "source": [
    "IDs=np.arange(30)\n",
    "Static_Features=np.zeros((30,30))\n",
    "Static_Features[np.arange(30),IDs]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 110170,
     "status": "ok",
     "timestamp": 1574374903683,
     "user": {
      "displayName": "daniela thyssens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAjESWh9r_JpJu7Y-DtgOWeyh4Y6Cw-yuE0sVSv5Q=s64",
      "userId": "06737456205702308294"
     },
     "user_tz": -60
    },
    "id": "IWGs1v9usFvO",
    "outputId": "81814401-7d6c-4c75-8595-93bd98bdf8c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-c13be2575426>:37: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-8-c13be2575426>:39: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling1D instead.\n",
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-c13be2575426>:44: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-c13be2575426>:45: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Summary name Time/conv1d/kernel:0 is illegal; using Time/conv1d/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Time/conv1d/bias:0 is illegal; using Time/conv1d/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Time/conv1d_1/kernel:0 is illegal; using Time/conv1d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Time/conv1d_1/bias:0 is illegal; using Time/conv1d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Time/dense/kernel:0 is illegal; using Time/dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Time/dense/bias:0 is illegal; using Time/dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm1.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm2.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1276\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 688\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 126\n",
      "len xTestbatches 117\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm3.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1294\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 700\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm4.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm5.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 616\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm6.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 616\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm7.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 616\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm9.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm10.csv\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN DF BEFORE CUTTING ANYTHING 1276\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 688\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 126\n",
      "len xTestbatches 117\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm11.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm12.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm13.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1292\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 698\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm14.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1038\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 498\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 102\n",
      "len xTestbatches 93\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm15.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm16.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1291\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 697\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm17.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 616\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm18.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm19.csv\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN DF BEFORE CUTTING ANYTHING 1186\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 616\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 117\n",
      "len xTestbatches 108\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm20.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1204\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 628\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 120\n",
      "len xTestbatches 111\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm22.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1204\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 628\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 120\n",
      "len xTestbatches 111\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm23.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm24.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm25.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1294\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 700\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm26.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm27.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm28.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm29.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events/Birm30.csv\n",
      "Index([], dtype='object')\n",
      "LEN DF BEFORE CUTTING ANYTHING 1312\n",
      "instances 336\n",
      "len new_cutted - start_train_ind 718\n",
      "len Train 336\n",
      "len x_batches  327\n",
      "len Test 129\n",
      "len xTestbatches 120\n",
      "71\n",
      "epoch: 1\n",
      "\tRMSE Training: [48.158527]\n",
      "\tRMSE Validation: [35.417545]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 4\n",
      "\tRMSE Training: [14.959077]\n",
      "\tRMSE Validation: [14.391857]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 7\n",
      "\tRMSE Training: [12.272125]\n",
      "\tRMSE Validation: [11.861398]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 10\n",
      "\tRMSE Training: [11.525753]\n",
      "\tRMSE Validation: [11.359893]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 13\n",
      "\tRMSE Training: [11.105846]\n",
      "\tRMSE Validation: [11.024208]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 16\n",
      "\tRMSE Training: [10.931732]\n",
      "\tRMSE Validation: [10.955901]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 19\n",
      "\tRMSE Training: [10.655383]\n",
      "\tRMSE Validation: [10.439729]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 22\n",
      "\tRMSE Training: [10.467691]\n",
      "\tRMSE Validation: [10.528772]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 25\n",
      "\tRMSE Training: [10.283734]\n",
      "\tRMSE Validation: [10.098607]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 28\n",
      "\tRMSE Training: [10.071498]\n",
      "\tRMSE Validation: [10.043342]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 31\n",
      "\tRMSE Training: [9.970438]\n",
      "\tRMSE Validation: [9.868307]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 34\n",
      "\tRMSE Training: [9.789105]\n",
      "\tRMSE Validation: [9.717277]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 37\n",
      "\tRMSE Training: [9.698383]\n",
      "\tRMSE Validation: [9.6350565]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 40\n",
      "\tRMSE Training: [9.63032]\n",
      "\tRMSE Validation: [9.494787]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 43\n",
      "\tRMSE Training: [9.510397]\n",
      "\tRMSE Validation: [9.625882]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 46\n",
      "\tRMSE Training: [9.34311]\n",
      "\tRMSE Validation: [9.5210495]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 49\n",
      "\tRMSE Training: [9.291422]\n",
      "\tRMSE Validation: [9.466312]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 52\n",
      "\tRMSE Training: [9.292567]\n",
      "\tRMSE Validation: [9.540469]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 55\n",
      "\tRMSE Training: [9.214695]\n",
      "\tRMSE Validation: [9.347954]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 58\n",
      "\tRMSE Training: [9.279499]\n",
      "\tRMSE Validation: [9.403747]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 61\n",
      "\tRMSE Training: [9.196298]\n",
      "\tRMSE Validation: [9.378575]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 64\n",
      "\tRMSE Training: [9.095437]\n",
      "\tRMSE Validation: [9.209477]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 67\n",
      "\tRMSE Training: [9.027855]\n",
      "\tRMSE Validation: [9.119045]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 70\n",
      "\tRMSE Training: [9.139187]\n",
      "\tRMSE Validation: [9.27299]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 73\n",
      "\tRMSE Training: [8.975099]\n",
      "\tRMSE Validation: [9.051985]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 76\n",
      "\tRMSE Training: [8.957303]\n",
      "\tRMSE Validation: [9.157948]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 79\n",
      "\tRMSE Training: [8.868468]\n",
      "\tRMSE Validation: [8.944727]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 82\n",
      "\tRMSE Training: [8.939012]\n",
      "\tRMSE Validation: [9.07926]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 85\n",
      "\tRMSE Training: [8.858172]\n",
      "\tRMSE Validation: [9.053281]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 88\n",
      "\tRMSE Training: [8.912304]\n",
      "\tRMSE Validation: [9.139623]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 91\n",
      "\tRMSE Training: [8.750154]\n",
      "\tRMSE Validation: [8.918496]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 94\n",
      "\tRMSE Training: [8.837369]\n",
      "\tRMSE Validation: [9.209469]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 97\n",
      "\tRMSE Training: [8.740367]\n",
      "\tRMSE Validation: [8.912456]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 100\n",
      "\tRMSE Training: [8.764831]\n",
      "\tRMSE Validation: [8.822273]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 103\n",
      "\tRMSE Training: [8.682915]\n",
      "\tRMSE Validation: [8.908631]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 106\n",
      "\tRMSE Training: [8.70178]\n",
      "\tRMSE Validation: [8.801156]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 109\n",
      "\tRMSE Training: [8.6833]\n",
      "\tRMSE Validation: [8.791759]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 112\n",
      "\tRMSE Training: [8.643486]\n",
      "\tRMSE Validation: [8.750842]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 115\n",
      "\tRMSE Training: [8.5670805]\n",
      "\tRMSE Validation: [8.713793]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 118\n",
      "\tRMSE Training: [8.58438]\n",
      "\tRMSE Validation: [8.731335]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 121\n",
      "\tRMSE Training: [8.595895]\n",
      "\tRMSE Validation: [8.629493]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 124\n",
      "\tRMSE Training: [8.601746]\n",
      "\tRMSE Validation: [8.624856]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 127\n",
      "\tRMSE Training: [8.638963]\n",
      "\tRMSE Validation: [9.02365]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 130\n",
      "\tRMSE Training: [8.506074]\n",
      "\tRMSE Validation: [8.754206]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 133\n",
      "\tRMSE Training: [8.53154]\n",
      "\tRMSE Validation: [8.758896]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 136\n",
      "\tRMSE Training: [8.554856]\n",
      "\tRMSE Validation: [8.890166]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 139\n",
      "\tRMSE Training: [8.452288]\n",
      "\tRMSE Validation: [8.681884]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 142\n",
      "\tRMSE Training: [8.4877615]\n",
      "\tRMSE Validation: [8.591275]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 145\n",
      "\tRMSE Training: [8.479928]\n",
      "\tRMSE Validation: [8.53014]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 148\n",
      "\tRMSE Training: [8.381128]\n",
      "\tRMSE Validation: [8.7830105]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 151\n",
      "\tRMSE Training: [8.419819]\n",
      "\tRMSE Validation: [8.572108]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 154\n",
      "\tRMSE Training: [8.454795]\n",
      "\tRMSE Validation: [8.459301]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 157\n",
      "\tRMSE Training: [8.379607]\n",
      "\tRMSE Validation: [8.727052]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 160\n",
      "\tRMSE Training: [8.3361225]\n",
      "\tRMSE Validation: [8.554708]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 163\n",
      "\tRMSE Training: [8.415242]\n",
      "\tRMSE Validation: [8.473041]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 166\n",
      "\tRMSE Training: [8.44201]\n",
      "\tRMSE Validation: [8.494828]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 169\n",
      "\tRMSE Training: [8.337888]\n",
      "\tRMSE Validation: [8.606186]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 172\n",
      "\tRMSE Training: [8.391241]\n",
      "\tRMSE Validation: [8.504542]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 175\n",
      "\tRMSE Training: [8.294518]\n",
      "\tRMSE Validation: [8.509374]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 178\n",
      "\tRMSE Training: [8.326744]\n",
      "\tRMSE Validation: [8.453433]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 181\n",
      "\tRMSE Training: [8.281403]\n",
      "\tRMSE Validation: [8.494551]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 184\n",
      "\tRMSE Training: [8.288337]\n",
      "\tRMSE Validation: [8.502851]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 187\n",
      "\tRMSE Training: [8.276691]\n",
      "\tRMSE Validation: [8.409826]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 190\n",
      "\tRMSE Training: [8.200957]\n",
      "\tRMSE Validation: [8.75656]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 193\n",
      "\tRMSE Training: [8.302662]\n",
      "\tRMSE Validation: [8.366865]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 196\n",
      "\tRMSE Training: [8.274861]\n",
      "\tRMSE Validation: [8.345328]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 199\n",
      "\tRMSE Training: [8.2560625]\n",
      "\tRMSE Validation: [8.309559]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 202\n",
      "\tRMSE Training: [8.2371235]\n",
      "\tRMSE Validation: [8.520235]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 205\n",
      "\tRMSE Training: [8.251461]\n",
      "\tRMSE Validation: [8.397644]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 208\n",
      "\tRMSE Training: [8.125178]\n",
      "\tRMSE Validation: [8.369057]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 211\n",
      "\tRMSE Training: [8.268046]\n",
      "\tRMSE Validation: [8.327525]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 214\n",
      "\tRMSE Training: [8.170576]\n",
      "\tRMSE Validation: [8.431641]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 217\n",
      "\tRMSE Training: [8.149697]\n",
      "\tRMSE Validation: [8.360871]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 220\n",
      "\tRMSE Training: [8.14277]\n",
      "\tRMSE Validation: [8.412188]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 223\n",
      "\tRMSE Training: [8.1067705]\n",
      "\tRMSE Validation: [8.246847]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 226\n",
      "\tRMSE Training: [8.094347]\n",
      "\tRMSE Validation: [8.331201]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 229\n",
      "\tRMSE Training: [8.184567]\n",
      "\tRMSE Validation: [8.782617]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 232\n",
      "\tRMSE Training: [7.991146]\n",
      "\tRMSE Validation: [8.52866]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 235\n",
      "\tRMSE Training: [8.137414]\n",
      "\tRMSE Validation: [8.4298115]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 238\n",
      "\tRMSE Training: [8.040907]\n",
      "\tRMSE Validation: [8.536897]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 241\n",
      "\tRMSE Training: [8.066253]\n",
      "\tRMSE Validation: [8.406034]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 244\n",
      "\tRMSE Training: [8.149331]\n",
      "\tRMSE Validation: [8.411559]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 247\n",
      "\tRMSE Training: [8.051675]\n",
      "\tRMSE Validation: [8.3936]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 250\n",
      "\tRMSE Training: [8.072167]\n",
      "\tRMSE Validation: [8.266183]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 253\n",
      "\tRMSE Training: [8.041267]\n",
      "\tRMSE Validation: [8.342998]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 256\n",
      "\tRMSE Training: [7.9695325]\n",
      "\tRMSE Validation: [8.249412]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 259\n",
      "\tRMSE Training: [7.9427176]\n",
      "\tRMSE Validation: [8.2843275]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 262\n",
      "\tRMSE Training: [7.9874825]\n",
      "\tRMSE Validation: [8.428763]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 265\n",
      "\tRMSE Training: [7.9801555]\n",
      "\tRMSE Validation: [8.208867]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 268\n",
      "\tRMSE Training: [8.003452]\n",
      "\tRMSE Validation: [8.265697]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 271\n",
      "\tRMSE Training: [7.960658]\n",
      "\tRMSE Validation: [8.290763]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 274\n",
      "\tRMSE Training: [7.9680314]\n",
      "\tRMSE Validation: [8.369716]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 277\n",
      "\tRMSE Training: [8.018858]\n",
      "\tRMSE Validation: [8.466551]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 280\n",
      "\tRMSE Training: [7.9977665]\n",
      "\tRMSE Validation: [8.433844]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 283\n",
      "\tRMSE Training: [7.9906125]\n",
      "\tRMSE Validation: [8.246524]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 286\n",
      "\tRMSE Training: [7.9737444]\n",
      "\tRMSE Validation: [8.118452]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 289\n",
      "\tRMSE Training: [7.813869]\n",
      "\tRMSE Validation: [8.1795025]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 292\n",
      "\tRMSE Training: [7.918918]\n",
      "\tRMSE Validation: [8.618935]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 295\n",
      "\tRMSE Training: [7.946102]\n",
      "\tRMSE Validation: [8.169416]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 298\n",
      "\tRMSE Training: [7.9365373]\n",
      "\tRMSE Validation: [8.182273]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 301\n",
      "\tRMSE Training: [7.9010725]\n",
      "\tRMSE Validation: [8.308068]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 304\n",
      "\tRMSE Training: [7.8562016]\n",
      "\tRMSE Validation: [8.165676]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 307\n",
      "\tRMSE Training: [7.8882976]\n",
      "\tRMSE Validation: [8.273861]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 310\n",
      "\tRMSE Training: [7.923029]\n",
      "\tRMSE Validation: [8.113345]\n",
      "71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "71\n",
      "epoch: 313\n",
      "\tRMSE Training: [7.838568]\n",
      "\tRMSE Validation: [8.154632]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 316\n",
      "\tRMSE Training: [7.8222623]\n",
      "\tRMSE Validation: [8.2239]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 319\n",
      "\tRMSE Training: [7.8299613]\n",
      "\tRMSE Validation: [8.225499]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 322\n",
      "\tRMSE Training: [7.910803]\n",
      "\tRMSE Validation: [7.9952807]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 325\n",
      "\tRMSE Training: [7.846493]\n",
      "\tRMSE Validation: [8.656743]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 328\n",
      "\tRMSE Training: [7.7930984]\n",
      "\tRMSE Validation: [8.266333]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 331\n",
      "\tRMSE Training: [7.78491]\n",
      "\tRMSE Validation: [8.098727]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 334\n",
      "\tRMSE Training: [7.7667375]\n",
      "\tRMSE Validation: [8.0861]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 337\n",
      "\tRMSE Training: [7.7369814]\n",
      "\tRMSE Validation: [8.495846]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 340\n",
      "\tRMSE Training: [7.8678384]\n",
      "\tRMSE Validation: [8.1615]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 343\n",
      "\tRMSE Training: [7.761395]\n",
      "\tRMSE Validation: [8.252743]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 346\n",
      "\tRMSE Training: [7.859812]\n",
      "\tRMSE Validation: [8.119978]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 349\n",
      "\tRMSE Training: [7.7416253]\n",
      "\tRMSE Validation: [8.171604]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 352\n",
      "\tRMSE Training: [7.714577]\n",
      "\tRMSE Validation: [8.187633]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 355\n",
      "\tRMSE Training: [7.6304536]\n",
      "\tRMSE Validation: [8.671602]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 358\n",
      "\tRMSE Training: [7.743832]\n",
      "\tRMSE Validation: [8.276207]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 361\n",
      "\tRMSE Training: [7.7002544]\n",
      "\tRMSE Validation: [8.210284]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 364\n",
      "\tRMSE Training: [7.660365]\n",
      "\tRMSE Validation: [8.262085]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 367\n",
      "\tRMSE Training: [7.645363]\n",
      "\tRMSE Validation: [8.097301]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 370\n",
      "\tRMSE Training: [7.691056]\n",
      "\tRMSE Validation: [8.490634]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 373\n",
      "\tRMSE Training: [7.626104]\n",
      "\tRMSE Validation: [8.227287]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 376\n",
      "\tRMSE Training: [7.658399]\n",
      "\tRMSE Validation: [8.082819]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 379\n",
      "\tRMSE Training: [7.69334]\n",
      "\tRMSE Validation: [8.285575]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 382\n",
      "\tRMSE Training: [7.6660495]\n",
      "\tRMSE Validation: [8.052522]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 385\n",
      "\tRMSE Training: [7.663735]\n",
      "\tRMSE Validation: [8.065442]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 388\n",
      "\tRMSE Training: [7.5881333]\n",
      "\tRMSE Validation: [8.331707]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 391\n",
      "\tRMSE Training: [7.651169]\n",
      "\tRMSE Validation: [7.95729]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 394\n",
      "\tRMSE Training: [7.6447477]\n",
      "\tRMSE Validation: [8.086297]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 397\n",
      "\tRMSE Training: [7.4541364]\n",
      "\tRMSE Validation: [8.243687]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 400\n",
      "\tRMSE Training: [7.463825]\n",
      "\tRMSE Validation: [8.090325]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 403\n",
      "\tRMSE Training: [7.6555815]\n",
      "\tRMSE Validation: [8.49583]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 406\n",
      "\tRMSE Training: [7.4615707]\n",
      "\tRMSE Validation: [8.094426]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 409\n",
      "\tRMSE Training: [7.5086646]\n",
      "\tRMSE Validation: [7.9729285]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 412\n",
      "\tRMSE Training: [7.487892]\n",
      "\tRMSE Validation: [8.07276]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 415\n",
      "\tRMSE Training: [7.541324]\n",
      "\tRMSE Validation: [7.985885]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 418\n",
      "\tRMSE Training: [7.551591]\n",
      "\tRMSE Validation: [7.943277]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 421\n",
      "\tRMSE Training: [7.5343013]\n",
      "\tRMSE Validation: [8.266412]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 424\n",
      "\tRMSE Training: [7.529945]\n",
      "\tRMSE Validation: [8.065166]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 427\n",
      "\tRMSE Training: [7.5418973]\n",
      "\tRMSE Validation: [8.219443]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 430\n",
      "\tRMSE Training: [7.45996]\n",
      "\tRMSE Validation: [7.978786]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 433\n",
      "\tRMSE Training: [7.4046593]\n",
      "\tRMSE Validation: [7.9711614]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 436\n",
      "\tRMSE Training: [7.509682]\n",
      "\tRMSE Validation: [8.080587]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 439\n",
      "\tRMSE Training: [7.4502196]\n",
      "\tRMSE Validation: [7.957424]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 442\n",
      "\tRMSE Training: [7.376036]\n",
      "\tRMSE Validation: [8.0897045]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 445\n",
      "\tRMSE Training: [7.4470363]\n",
      "\tRMSE Validation: [8.48901]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 448\n",
      "\tRMSE Training: [7.482054]\n",
      "\tRMSE Validation: [8.1283865]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 451\n",
      "\tRMSE Training: [7.446024]\n",
      "\tRMSE Validation: [8.179088]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 454\n",
      "\tRMSE Training: [7.4474406]\n",
      "\tRMSE Validation: [8.018527]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 457\n",
      "\tRMSE Training: [7.300811]\n",
      "\tRMSE Validation: [8.386565]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 460\n",
      "\tRMSE Training: [7.5418215]\n",
      "\tRMSE Validation: [9.3968935]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 463\n",
      "\tRMSE Training: [7.531001]\n",
      "\tRMSE Validation: [8.297787]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 466\n",
      "\tRMSE Training: [7.3416567]\n",
      "\tRMSE Validation: [8.212163]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 469\n",
      "\tRMSE Training: [7.3746667]\n",
      "\tRMSE Validation: [7.9103584]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 472\n",
      "\tRMSE Training: [7.3887815]\n",
      "\tRMSE Validation: [7.855033]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 475\n",
      "\tRMSE Training: [7.3531485]\n",
      "\tRMSE Validation: [8.322954]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 478\n",
      "\tRMSE Training: [7.2732863]\n",
      "\tRMSE Validation: [7.915808]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 481\n",
      "\tRMSE Training: [7.257413]\n",
      "\tRMSE Validation: [7.9016056]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 484\n",
      "\tRMSE Training: [7.5059233]\n",
      "\tRMSE Validation: [7.965191]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 487\n",
      "\tRMSE Training: [7.263276]\n",
      "\tRMSE Validation: [7.9935513]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 490\n",
      "\tRMSE Training: [7.2532234]\n",
      "\tRMSE Validation: [7.978065]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 493\n",
      "\tRMSE Training: [7.274592]\n",
      "\tRMSE Validation: [7.9742656]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 496\n",
      "\tRMSE Training: [7.4181905]\n",
      "\tRMSE Validation: [7.8734174]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 499\n",
      "\tRMSE Training: [7.287884]\n",
      "\tRMSE Validation: [7.9740596]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 502\n",
      "\tRMSE Training: [7.238992]\n",
      "\tRMSE Validation: [7.8835287]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 505\n",
      "\tRMSE Training: [7.364581]\n",
      "\tRMSE Validation: [8.777658]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 508\n",
      "\tRMSE Training: [7.204334]\n",
      "\tRMSE Validation: [7.9778914]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 511\n",
      "\tRMSE Training: [7.2451677]\n",
      "\tRMSE Validation: [7.913861]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 514\n",
      "\tRMSE Training: [7.2464623]\n",
      "\tRMSE Validation: [7.8665195]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 517\n",
      "\tRMSE Training: [7.212655]\n",
      "\tRMSE Validation: [8.037384]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 520\n",
      "\tRMSE Training: [7.1365957]\n",
      "\tRMSE Validation: [8.009882]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 523\n",
      "\tRMSE Training: [7.215732]\n",
      "\tRMSE Validation: [7.819247]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 526\n",
      "\tRMSE Training: [7.2418413]\n",
      "\tRMSE Validation: [8.08747]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 529\n",
      "\tRMSE Training: [7.232567]\n",
      "\tRMSE Validation: [7.996375]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 532\n",
      "\tRMSE Training: [7.3672643]\n",
      "\tRMSE Validation: [7.8094583]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 535\n",
      "\tRMSE Training: [7.187985]\n",
      "\tRMSE Validation: [7.814995]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 538\n",
      "\tRMSE Training: [7.16505]\n",
      "\tRMSE Validation: [8.267275]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 541\n",
      "\tRMSE Training: [7.269288]\n",
      "\tRMSE Validation: [7.8117642]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 544\n",
      "\tRMSE Training: [7.122781]\n",
      "\tRMSE Validation: [8.222733]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 547\n",
      "\tRMSE Training: [7.2240753]\n",
      "\tRMSE Validation: [7.750486]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 550\n",
      "\tRMSE Training: [7.241683]\n",
      "\tRMSE Validation: [7.7773166]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 553\n",
      "\tRMSE Training: [7.032892]\n",
      "\tRMSE Validation: [7.704432]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 556\n",
      "\tRMSE Training: [7.0170574]\n",
      "\tRMSE Validation: [7.786063]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 559\n",
      "\tRMSE Training: [7.1613846]\n",
      "\tRMSE Validation: [7.8338118]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 562\n",
      "\tRMSE Training: [7.280814]\n",
      "\tRMSE Validation: [7.8304176]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 565\n",
      "\tRMSE Training: [7.112812]\n",
      "\tRMSE Validation: [7.804735]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 568\n",
      "\tRMSE Training: [7.163609]\n",
      "\tRMSE Validation: [7.726198]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 571\n",
      "\tRMSE Training: [7.096086]\n",
      "\tRMSE Validation: [7.7720184]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 574\n",
      "\tRMSE Training: [7.237641]\n",
      "\tRMSE Validation: [7.8512]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 577\n",
      "\tRMSE Training: [7.0651193]\n",
      "\tRMSE Validation: [7.8675203]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 580\n",
      "\tRMSE Training: [7.112998]\n",
      "\tRMSE Validation: [7.973316]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 583\n",
      "\tRMSE Training: [7.0349293]\n",
      "\tRMSE Validation: [7.9513245]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 586\n",
      "\tRMSE Training: [7.083427]\n",
      "\tRMSE Validation: [7.7742076]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 589\n",
      "\tRMSE Training: [6.996079]\n",
      "\tRMSE Validation: [7.722698]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 592\n",
      "\tRMSE Training: [7.1206317]\n",
      "\tRMSE Validation: [7.7888803]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 595\n",
      "\tRMSE Training: [7.0846524]\n",
      "\tRMSE Validation: [8.043245]\n",
      "71\n",
      "71\n",
      "71\n",
      "epoch: 598\n",
      "\tRMSE Training: [7.0275426]\n",
      "\tRMSE Validation: [7.7371016]\n",
      "71\n",
      "71\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "train_mse=[]\n",
    "validation_mse=[]\n",
    "test_mse=[]\n",
    "tf.reset_default_graph()   #We didn't have any previous graph objects running, but this would reset the graphs\n",
    "\n",
    "\n",
    "#=============================LSTM part===========================================\n",
    "\n",
    "lstm_graph=tf.Graph()\n",
    "with lstm_graph.as_default():\n",
    "    X = tf.placeholder(tf.float32, [None, num_periods_input, inputs])   #create variable objects\n",
    "    y = tf.placeholder(tf.float32, [None, num_periods_output, output])\n",
    "    learning_rate=tf.placeholder(tf.float32, None)\n",
    "    #batchsize = tf.placeholder(tf.int16)\n",
    "    #dropout = tf.placeholder(tf.float32)\n",
    "    is_train = tf.placeholder(tf.bool)\n",
    "    #EventBased_X=tf.placeholder(tf.float32, [None,num_periods_input,Number_of_EventBased])\n",
    "    static_X = tf.placeholder(tf.float32, [None,Number_Of_Static_Features])\n",
    "    keep_prob = tf.placeholder(tf.float32, None)\n",
    "\n",
    "    \n",
    "    #====================================================================================\n",
    "    #=========================Static Features part=======================================\n",
    "    '''\n",
    "    Layer1 = tf.layers.dense(static_X, units=100,activation=tf.nn.relu)  \n",
    "    Static_Output_1 = tf.layers.dense(Layer1,units= 50,activation=tf.nn.relu) \n",
    "    Static_Output = tf.nn.dropout(Static_Output_1,keep_prob=keep_prob_static) # dropout \n",
    "    #===================================== Combine before LSTM ===========================\n",
    "    Static_Output=tf.reshape(Static_Output, [-1, num_periods_input,50])\n",
    "\n",
    "    Combined_output=tf.concat([X,Static_Output],2)\n",
    "    '''\n",
    "    Static_Output=tf.reshape(static_X, [-1, num_periods_input,Number_Of_Static_Features])\n",
    "    Combined_output=tf.concat([X,Static_Output],2)\n",
    "    #========================================= **Time CNN** ===================================\n",
    "    with tf.variable_scope('Time'):\n",
    "        conv1 = tf.layers.conv1d(inputs=Combined_output, filters=128, kernel_size=8, padding=\"same\", activation=tf.nn.relu)\n",
    "        # Pooling Layer #1\n",
    "        pool1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=1)\n",
    "        conv2 = tf.layers.conv1d(inputs=pool1, filters=128, kernel_size=8, padding=\"same\", activation=tf.nn.relu)\n",
    "        flat=tf.contrib.layers.flatten(conv2)\n",
    "        ####################  Fully connected after CNN #################################\n",
    "        #flat = tf.reshape(flat, [-1,(hidden_event*num_periods_input)])# to be able to concat. the static features\n",
    "        CNN_Output_1= tf.layers.dense(flat, units=100,activation=tf.nn.relu)  \n",
    "        CNN_Output = tf.nn.dropout(CNN_Output_1,keep_prob=keep_probab)\n",
    "    #========================CNN Event Based============================================\n",
    "    '''with tf.variable_scope('Event'):\n",
    "        conv1_event = tf.layers.conv1d(inputs=EventBased_X, filters=128, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n",
    "        # Pooling Layer #1\n",
    "        pool1_event = tf.layers.max_pooling1d(inputs=conv1_event, pool_size=2, strides=1)\n",
    "        conv2_event = tf.layers.conv1d(inputs=pool1_event, filters=64, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n",
    "        flat=tf.contrib.layers.flatten(conv2_event)\n",
    "        ####################  Fully connected after CNN #################################\n",
    "        #flat = tf.reshape(flat, [-1,(hidden_event*num_periods_input)])# to be able to concat. the static features\n",
    "        CNN_Output_event_1= tf.layers.dense(flat, units=100,activation=tf.nn.relu)  \n",
    "        CNN_Output_event = tf.nn.dropout(CNN_Output_event_1,keep_prob=keep_prob_event)\n",
    "    '''\n",
    "        #====================================================================================\n",
    "    #=========================Combination part===========================================\n",
    "\n",
    "    #Combined_output=tf.concat([CNN_Output,CNN_Output_event],1)\n",
    "    #Combined_output=tf.multiply(LSTM_Output,LSTM_Output_event)\n",
    "    stacked_outputs = tf.layers.dense(CNN_Output, units=num_periods_output) #specify the type of layer (dense)\n",
    "    outputs = tf.reshape(stacked_outputs, [-1, num_periods_output, output])          #shape of results\n",
    "    #Regularization part\n",
    "    tv = tf.trainable_variables()\n",
    "    regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
    "    Error=tf.square(outputs - y)\n",
    "    #Total_err=Error+regularization_cost\n",
    "    loss = tf.reduce_mean(tf.square(outputs - y))+ lamda*regularization_cost   #define the cost function which evaluates the quality of our model\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)          #gradient descent method\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "    \n",
    "    #opt to get gradient info:\n",
    "    grads=tf.gradients(loss,tv)\n",
    "    grads=list(zip(grads,tv))\n",
    "    \n",
    "    training_op = optimizer.apply_gradients(capped_gvs)\n",
    "    #training_op = optimizer.minimize(loss)          #train the result of the application of the cost_function                                 \n",
    "    \n",
    "    #Before running session, set variables to track in Tensorboard\n",
    "    #with lstm_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    #Creat Summary to monitor scalar values (loss):\n",
    "    #tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "    # Create a summary to monitor prediction tensor\n",
    "    #tf.summary.histogram(\"Prediction\", predictions)\n",
    "    \n",
    "    # Gradient Info\n",
    "    for var in tv:\n",
    "        tf.summary.histogram(var.name,var)\n",
    "    \n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "#====================================================================================\n",
    "\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    #batch_size=\n",
    "    X_returned=[]\n",
    "    Y_returned=[]\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        if (start + batch_size)>len(features):\n",
    "            break\n",
    "        else:\n",
    "            end = start + batch_size\n",
    "        X_returned.append(features[start:end])\n",
    "        Y_returned.append(labels[start:end])\n",
    "    return X_returned, Y_returned\n",
    "\n",
    "\n",
    "# COMPUTE LEARNING RATE schedule beforehand\n",
    "#LR_schedule = compute_LR(init_epoch,epochs,learning_rate_decay,initial_LR) \n",
    "with tf.Session(graph=lstm_graph) as sess:    \n",
    "    \n",
    "    init = tf.global_variables_initializer()           #initialize all the variables\n",
    "    init.run()\n",
    "    \n",
    "    # creating the writer inside the session\n",
    "    #writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    #### LOOP OVER LOCATIONS ####\n",
    "    data_path=r'D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data_Events'\n",
    "    #r'D:\\Users\\danie\\Desktop\\jupyter_notebooks\\Project\\Birm_Data'\n",
    "    #r'/content/drive/My Drive/With_historical'\n",
    "    #r'/home/shero/Desktop/OurProject/BanesData/Model/occupation_loc/'\n",
    "    data_All=pd.DataFrame()\n",
    "    x_batches_Full=[]\n",
    "    y_batches_Full=[]\n",
    "    X_Valid_Full=[]\n",
    "    Y_Valid_Full=[]\n",
    "    X_Test_Full=[]\n",
    "    Y_Test_Full=[]\n",
    "    range_list=[x for x in range(1,31) if x != 8 and x!=21]\n",
    "    for loc_id in range_list:\n",
    "        #========\n",
    "        data=load_locationfiles(data_path,loc_id)\n",
    "        header=list(data.columns.values)\n",
    "        data=pd.DataFrame(data,columns=header)\n",
    "        x_batches, y_batches, X_Valid, Y_Valid,X_Test,Y_Test=preprocessing(data,(Number_of_TimeFeatures+Number_of_EventBased))\n",
    "        #===============================\n",
    "        for element1 in (x_batches):\n",
    "            x_batches_Full.append(element1)\n",
    "            \n",
    "        for element2 in (y_batches):\n",
    "            y_batches_Full.append(element2)\n",
    "            \n",
    "        for element3 in (X_Valid):\n",
    "            X_Valid_Full.append(element3)\n",
    "            \n",
    "        for element4 in (Y_Valid):\n",
    "            Y_Valid_Full.append(element4)\n",
    "            \n",
    "        for element5 in (X_Test):\n",
    "            X_Test_Full.append(element5)\n",
    "            \n",
    "        for element6 in (Y_Test):\n",
    "            Y_Test_Full.append(element6)            \n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        #CALCULATE LR TO USE!!\n",
    "        #curr_lr=LR_schedule[ep]\n",
    "        Training_Error=[]\n",
    "        #even though NOT SHUFFLED YET\n",
    "        shuffled_batch_features,shuffled_batch_y=batch_features_labels(x_batches_Full,y_batches_Full,batchsize)\n",
    "        #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "        combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
    "        random.shuffle(combined)\n",
    "        shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "        #===========================================================================================\n",
    "        print(len(shuffled_batch_features))\n",
    "        \n",
    "        for i in range(0,len(shuffled_batch_features)): \n",
    "            #print('====================')\n",
    "            batch_features=shuffled_batch_features[i]\n",
    "            #print(batch_features)\n",
    "            batch_y=shuffled_batch_y[i]\n",
    "            static=[]\n",
    "            Event_Based=[]\n",
    "            #print('Before drop',batch_features[0][0][0])\n",
    "            for h in range(0,no_sequences):\n",
    "                Event_window=[]\n",
    "                for k in range(0,num_periods_input):\n",
    "                    loc_id=int(batch_features[h][k][0])\n",
    "                    static.append(Static_Features[loc_id-1][:]) # \n",
    "                    #Event_window.append(batch_features[h][k][Event_Based_StartIndex:])\n",
    "                #Event_Based.append(Event_window)\n",
    "                \n",
    "            #EventBased_EndIndex=Event_Based_StartIndex+Number_of_EventBased\n",
    "            #Event_Based_index=list(range(Event_Based_StartIndex, EventBased_EndIndex))\n",
    "            #batch_features=np.delete(batch_features,Event_Based_index, axis=2)\n",
    "            batch_features=np.delete(batch_features,[0], axis=2) \n",
    "            \n",
    "            #print('X',len(batch_features))\n",
    "            #print('Y',len(batch_y[0]))\n",
    "            _,Train_Batch_error,summary=sess.run([training_op,Error,merged_summary_op],\n",
    "                                                 feed_dict={\n",
    "                                                     keep_prob:keep_probab,\n",
    "                                                     X: batch_features,\n",
    "                                                     y: batch_y,\n",
    "                                                     learning_rate: l_rate,\n",
    "                                                     static_X:static}) \n",
    "            Training_Error.append(Train_Batch_error)\n",
    "            \n",
    "        \n",
    "        #write logs (per epoch)\n",
    "        #writer.add_summary(summary, ep)\n",
    "        \n",
    "        if ep % 3 == 0:\n",
    "            ################  evaluate training error\n",
    "            #print('Length of whole:',len(Training_Error),'Length of each: ',len(Training_Error[0][0]))\n",
    "            Sum_train=np.sum(Training_Error,axis=2)\n",
    "            Sum_train_1=np.sum(Sum_train,axis=1)\n",
    "            Sum_train_2=np.sum(Sum_train_1,axis=0)\n",
    "            Mean_train=Sum_train_2/(len(Training_Error)*batchsize*num_periods_output)\n",
    "            print(\"epoch:\",int(ep+1))\n",
    "            print(\"\\tRMSE Training:\", (Mean_train)**0.5)\n",
    "            #mse = loss.eval(feed_dict={\n",
    "            #                              X: batch_features,\n",
    "            #                             y: batch_y,\n",
    "            #                            static_X:static_train,\n",
    "            #                           is_train:True})\n",
    "            train_mse.append((Mean_train)**0.5)\n",
    "                \n",
    "            \n",
    "            Validation_Error=[]\n",
    "            unshuffled_valid_batch_features,unshuffled_valid_batch_y=batch_features_labels(X_Valid_Full,Y_Valid_Full,batchsize)\n",
    "\n",
    "            for i in range(0,len(unshuffled_valid_batch_features)):\n",
    "                batch_features_valid=unshuffled_valid_batch_features[i]\n",
    "                #print(batch_features)\n",
    "                batch_y_valid=unshuffled_valid_batch_y[i]\n",
    "                static_Valid=[]\n",
    "                Event_Based_Valid=[]\n",
    "                #print('Before drop',batch_features[0][0][0])\n",
    "                for h in range(0,no_sequences):\n",
    "                    Event_window_valid=[]\n",
    "                    for k in range(0,num_periods_input):\n",
    "                        loc_id=int(batch_features_valid[h][k][0])\n",
    "                        static_Valid.append(Static_Features[loc_id-1][:]) # \n",
    "                        #Event_window_valid.append(batch_features_valid[h][k][Event_Based_StartIndex:])\n",
    "                    #Event_Based_Valid.append(Event_window_valid)\n",
    "                    \n",
    "                #EventBased_EndIndex=Event_Based_StartIndex+Number_of_EventBased\n",
    "                #Event_Based_index=list(range(Event_Based_StartIndex, EventBased_EndIndex))\n",
    "                #batch_features_valid=np.delete(batch_features_valid,Event_Based_index, axis=2)\n",
    "                batch_features_valid=np.delete(batch_features_valid,[0], axis=2)\n",
    "                \n",
    "                \n",
    "                y_predict,Valid_error_batch=sess.run([outputs,Error], \n",
    "                                                     feed_dict={\n",
    "                                                     keep_prob:keep_prob_testval,\n",
    "                                                     X: batch_features_valid, \n",
    "                                                     y: batch_y_valid,\n",
    "                                                     static_X:static_Valid\n",
    "                                                     })\n",
    "                #static_X:static_Valid\n",
    "                #print('Valid_error_batch',Valid_error_batch)\n",
    "                Validation_Error.append(Valid_error_batch)\n",
    "            \n",
    "            Sum_valid=np.sum(Validation_Error,axis=2)\n",
    "            Sum_valid_1=np.sum(Sum_valid,axis=1)\n",
    "            Sum_valid_2=np.sum(Sum_valid_1,axis=0)\n",
    "            '''print('Sum_train shape:',Sum_valid.shape)\n",
    "            print('Sum_train_1 shape:',Sum_valid_1.shape)\n",
    "            print('Sum_train_2 shape:',Sum_valid_2.shape)'''\n",
    "            Mean_valid=Sum_valid_2/(len(Validation_Error)*batchsize*num_periods_output)\n",
    "            print(\"\\tRMSE Validation:\", (Mean_valid)**0.5)\n",
    "            #mse = loss.eval(feed_dict={\n",
    "            #                              X: batch_features,\n",
    "            #                             y: batch_y,\n",
    "            #                            static_X:static_train,\n",
    "            #                           is_train:True})\n",
    "            #train_mse.append((Mean_train)**0.5)\n",
    "            \n",
    "            validation_mse.append((Mean_valid)**0.5)\n",
    "              \n",
    "    # save training session --> TO RESTORE\n",
    "    saver.save(sess,\"checkpoints-conn_beg/har.ckpt\")\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_irySJICsFvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min training RMSE: [6.996079]\n",
      "min validation RMSE: [7.704432]\n"
     ]
    }
   ],
   "source": [
    "print('min training RMSE:',min(train_mse))\n",
    "print('min validation RMSE:',min(validation_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeoeBeZxsFvZ"
   },
   "source": [
    "### Plot Training + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c004fa3148>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgI4Lq9asFva"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train_draw=[]\n",
    "Valid_draw=[]\n",
    "for i in range(0,len(train_mse)):\n",
    "  if i%3==0:\n",
    "    Train_draw.append(train_mse[i])\n",
    "    Valid_draw.append(validation_mse[i])\n",
    "\n",
    "plt.title(\"Training vs. Validation Error\", fontsize=14)\n",
    "#plt.legend(loc=\"lower right\")\n",
    "plt.plot(Train_draw[1:], markersize=10, label=\"Training Error\",color='red')\n",
    "plt.plot(Valid_draw[1:], markersize=10, label=\"Validation Error\",color='blue')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('Training vs Testing Error.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpSktO3hsFvd"
   },
   "source": [
    "### Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MESF4QjsFve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\danie\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints-conn_beg\\har.ckpt\n",
      "25\n",
      "Sum_test shape: (25, 128, 1)\n",
      "Sum_test_1 shape: (25, 1)\n",
      "Sum_test_2 shape: (1,)\n",
      "\tRMSE Testing: [8.744044]\n"
     ]
    }
   ],
   "source": [
    "Test_Error=[]\n",
    "with tf.Session(graph=lstm_graph) as sess: \n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-conn_beg'))\n",
    "    test_batch_features,test_batch_y=batch_features_labels(X_Test_Full,Y_Test_Full,batchsize)\n",
    "    #---------------------shuffle minibatches X and Y together-------------------------------------\n",
    "    #combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
    "    #random.shuffle(combined)\n",
    "    #shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
    "    #===========================================================================================\n",
    "    print(len(test_batch_features))\n",
    "    \n",
    "    for i in range(0,len(test_batch_features)):\n",
    "        batch_features_test=test_batch_features[i]\n",
    "        #print(batch_features)\n",
    "        batch_y_test=test_batch_y[i]\n",
    "        static_test=[]\n",
    "        Event_Based_Test=[]\n",
    "        #print('Before drop',batch_features[0][0][0])\n",
    "        for h in range(0,no_sequences):\n",
    "            Event_window_Test=[]\n",
    "            for k in range(0,num_periods_input):\n",
    "                loc_id=int(batch_features_test[h][k][0])\n",
    "                static_test.append(Static_Features[loc_id-1][:]) # \n",
    "                #Event_window_Test.append(batch_features_test[h][k][Event_Based_StartIndex:])\n",
    "            #Event_Based_Test.append(Event_window_Test)\n",
    "            \n",
    "        #EventBased_EndIndex=Event_Based_StartIndex+Number_of_EventBased\n",
    "        #Event_Based_index=list(range(Event_Based_StartIndex, EventBased_EndIndex))\n",
    "        #batch_features_test=np.delete(batch_features_test,Event_Based_index, axis=2)  \n",
    "        batch_features_test=np.delete(batch_features_test, [0], axis=2) \n",
    "        #print('X',len(batch_features[0]))\n",
    "        #print('Y',len(batch_y[0]))\n",
    "        Test_Batch_error,y_predict_test,summary=sess.run([Error,outputs,merged_summary_op],\n",
    "                                             feed_dict={\n",
    "                                                 keep_prob:keep_prob_testval,\n",
    "                                                 X: batch_features_test,\n",
    "                                                 y: batch_y_test,\n",
    "                                                 static_X:static_test,\n",
    "                                                 is_train:False\n",
    "                                                 })\n",
    "        #static_X:static_test,\n",
    "        #print('error:',Train_Batch_error[0])\n",
    "        Test_Error.append(Test_Batch_error)\n",
    "\n",
    "    Sum_test=np.sum(Test_Error,axis=2)\n",
    "    Sum_test_1=np.sum(Sum_test,axis=1)\n",
    "    Sum_test_2=np.sum(Sum_test_1,axis=0)\n",
    "    print('Sum_test shape:',Sum_test.shape)\n",
    "    print('Sum_test_1 shape:',Sum_test_1.shape)\n",
    "    print('Sum_test_2 shape:',Sum_test_2.shape)\n",
    "    Mean_test=Sum_test_2/(len(Test_Error)*batchsize*num_periods_output)\n",
    "    print(\"\\tRMSE Testing:\", (Mean_test)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15SGHOrMsFvg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1111_Conn_Beg_TimeCNN_validation_BIRM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
