{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Birm_MLP2011_WithFeatures_2311.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC_aVTChKIx3",
        "colab_type": "code",
        "outputId": "c6b83f85-e6e8-4aeb-9d65-229b56cda38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkZGl_g0KFc-",
        "colab_type": "code",
        "outputId": "ea31e52f-a428-4a57-c1f5-d62fe9d055e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "import sys\n",
        "sys.version\n",
        "#Import Libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline\n",
        "import shutil\n",
        "import tensorflow.contrib.learn as tflearn\n",
        "import tensorflow.contrib.layers as tflayers\n",
        "from tensorflow.contrib.learn.python.learn import learn_runner\n",
        "import tensorflow.contrib.metrics as metrics\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "from random import shuffle\n",
        "\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import xgboost as xgb\n",
        "#TF Version\n",
        "tf.__version__\n",
        "\n",
        "#with warnings.catch_warnings():\n",
        "#    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "#    import h5py\n",
        "\n",
        "num_periods_output = 2 #to predict\n",
        "num_periods_input=4 #input\n",
        "l_rate = 0.0001   \n",
        "MiniBatches_size=128\n",
        "keep_probab=0.8            #(1-dropout_rate)\n",
        "keep_prob_testval=1.0  \n",
        "epochs = 400   \n",
        "Number_of_TimeFeatures=30+15\n",
        "inputs = Number_of_TimeFeatures-1 \n",
        "lamda=0.4 \n",
        "\n",
        "\n",
        "No_Of_weeks=0.5\n",
        "\n",
        "ALL_Test_Data=[]\n",
        "ALL_Test_Prediction=[]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4odAQaTMKFdB",
        "colab_type": "text"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpCUqQK9KFdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "def preprocessing(df_,num_features):\n",
        "    \n",
        "\n",
        "   # get year, month,Day,Hour,Minute\n",
        "    df_['LastUpdated'] = pd.to_datetime(df_['LastUpdated'])\n",
        "    df_['Year'] = df_['LastUpdated'].dt.year\n",
        "    df_['Month'] = df_['LastUpdated'].dt.month\n",
        "    df_['Day'] = df_['LastUpdated'].dt.day\n",
        "    df_['Hour'] = df_['LastUpdated'].dt.hour\n",
        "    df_['Minute'] = df_['LastUpdated'].dt.minute\n",
        "    \n",
        "    #,'Month','Day','Hour','Minute'\n",
        "    # select features\n",
        "    df=df_[['ID','Occ_percent','Month','Day','Hour','Minute',\n",
        "           'temperature','dew_point','humidity','wind_speed',\n",
        "           'feels_like','Events_Football_City','Events_Football_Derby',\n",
        "           'Events_Football_Aston','Events_Rugby']]\n",
        "    \n",
        "    cols=df.columns\n",
        "    print(cols[20:]) \n",
        "    \n",
        "    ################################################encoding########################\n",
        "    df['Occ_percent'] = pd.to_numeric(df['Occ_percent'],errors='coerce')\n",
        "    df['Occ_percent'] = df['Occ_percent'].abs()\n",
        "    \n",
        "\n",
        "    Number_Of_Features=num_features\n",
        "    df=df.values\n",
        "    df = df.astype('float32')\n",
        "    split=num_periods_output+num_periods_input\n",
        "    \n",
        "    ##################################SPLIT##############################################\n",
        "\n",
        "    ########################## SPLITTING FOR TESTING & VALIDATION ##########################\n",
        "    #test_len=np.floor(len(df)*0.2)\n",
        "    test_val_len=np.floor(len(df)*0.2)\n",
        "    #mod=test_len%(num_periods_input+num_periods_output)\n",
        "    mod=test_val_len%(num_periods_input+num_periods_output)\n",
        "    #let thelength be divisable by 12\n",
        "    test_val_len=int(test_val_len-mod)\n",
        "    Test_Val=df[(len(df)-test_val_len):,:]\n",
        "    \n",
        "    ############################ VALIDATION & TESTING ##################################\n",
        "    valid_len=np.floor(len(Test_Val)*0.5)\n",
        "    Valid=Test_Val[0:(len(Test_Val)-int(valid_len)),:]\n",
        "    Test=Test_Val[(len(Test_Val)-int(valid_len)):,:]\n",
        "    \n",
        "    ########################### SPLITTING FOR TRAIN ###########################\n",
        "    \n",
        "    new_cutted_df=df[:(len(df)-test_val_len),:]\n",
        "    Start_train_index=17*7*No_Of_weeks\n",
        "    Start_train_index=np.floor(Start_train_index)\n",
        "    Start_train_index=int(Start_train_index)\n",
        "    print('instances',Start_train_index)\n",
        "    Train=new_cutted_df[len(new_cutted_df)-Start_train_index:,:]\n",
        "    train_len=len(Train)\n",
        "    mod=train_len%(num_periods_input+num_periods_output)\n",
        "    #let thelength be divisable by 12\n",
        "    train_len=int(train_len-mod)\n",
        "    Train=Train[0:train_len,:]\n",
        "    print('len Train',len(Train))\n",
        "   \n",
        "        \n",
        "     ############################################ Valid minibatches ##################################\n",
        "    \n",
        "    end_valid=len(Valid)\n",
        "    start=0\n",
        "    next=0\n",
        "    x_validbatches=[]\n",
        "    y_validbatches=[]\n",
        "    \n",
        "    count=0\n",
        "    #print('lennnn',len(Train))\n",
        "    while next+(num_periods_input+num_periods_output)<end_valid:\n",
        "        next=start+num_periods_input\n",
        "        x_validbatches.append(Valid[start:next,:])\n",
        "        y_validbatches.append(Valid[next:next+num_periods_output,1])\n",
        "        start=start+1\n",
        "    y_validbatches=np.asarray(y_validbatches)\n",
        "    y_validbatches = y_validbatches.reshape(-1, num_periods_output, 1)   \n",
        "    x_validbatches=np.asarray(x_validbatches)\n",
        "    x_validbatches = x_validbatches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
        "    print('len x_validbatches ',len(x_validbatches))\n",
        "    ############################################ TRAIN minibatches ##################################\n",
        "    \n",
        "    end=len(Train)\n",
        "    start=0\n",
        "    next=0\n",
        "    x_batches=[]\n",
        "    y_batches=[]\n",
        "    \n",
        "    count=0\n",
        "    #print('lennnn',len(Train))\n",
        "    while next+(num_periods_input+num_periods_output)<end:\n",
        "        next=start+num_periods_input\n",
        "        x_batches.append(Train[start:next,:])\n",
        "        y_batches.append(Train[next:next+num_periods_output,1])\n",
        "        start=start+1\n",
        "    y_batches=np.asarray(y_batches)\n",
        "    y_batches = y_batches.reshape(-1, num_periods_output, 1)   \n",
        "    x_batches=np.asarray(x_batches)\n",
        "    x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
        "    print('len x_batches ',len(x_batches))\n",
        "    \n",
        "    ###########################################TEST#####################################\n",
        "    ############################################ TEST minibatches ##################################\n",
        "    end_test=len(Test)\n",
        "    start_test=0\n",
        "    next_test=0\n",
        "    x_testbatches=[]\n",
        "    y_testbatches=[]\n",
        "    \n",
        "    \n",
        "    #print('lennnn',len(Train))\n",
        "    while next_test+(num_periods_input+num_periods_output)<end_test:\n",
        "        next_test=start_test+num_periods_input\n",
        "        x_testbatches.append(Test[start_test:next_test,:])\n",
        "        y_testbatches.append(Test[next_test:next_test+num_periods_output,1])\n",
        "        start_test=start_test+1\n",
        "    y_testbatches=np.asarray(y_testbatches)\n",
        "    y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)   \n",
        "    x_testbatches=np.asarray(x_testbatches)\n",
        "    x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features) \n",
        "    print('len Test',len(Test))\n",
        "    print('len xTestbatches',len(x_testbatches))\n",
        "    ######################## Sampling##########################################\n",
        "    \n",
        "    #x_batches, y_batches, x_validbatches, y_validbatches, x_testbatches, y_testbatches\n",
        "    \n",
        "    return x_batches, y_batches, x_validbatches, y_validbatches, x_testbatches, y_testbatches\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GeTnVETKFdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_locationfiles(path,loc_id):\n",
        "    filename=path + '/Birm'+str(loc_id)+'.csv'\n",
        "    print(filename)\n",
        "    data_loc=pd.read_csv(filename)\n",
        "    #print(data_loc.head())\n",
        "    #mod=len(data_loc)%(num_periods_input+num_periods_output)\n",
        "    #let thelength be divisable by 12\n",
        "    #data_loc=data_loc[:len(data_loc)-mod]\n",
        "    return data_loc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBMD4AcXKFdI",
        "colab_type": "code",
        "outputId": "2521d445-6f65-482b-c48b-4026b6c2d66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    data_path=r'/content/drive/My Drive/Birm_Data_Events'\n",
        "    #r'/home/shero/Desktop/OurProject/BanesData/Model/occupation_loc/'\n",
        "    data_All=pd.DataFrame()\n",
        "    x_batches_Full=[]\n",
        "    y_batches_Full=[]\n",
        "    X_Valid_Full=[]\n",
        "    Y_Valid_Full=[]\n",
        "    X_Test_Full=[]\n",
        "    Y_Test_Full=[]\n",
        "\n",
        "    range_list = [x for x in range(1,31) if x != 8 and x != 21]\n",
        "\n",
        "    for loc_id in range_list:\n",
        "        #========\n",
        "        data=load_locationfiles(data_path,loc_id)\n",
        "        header=list(data.columns.values)\n",
        "        data=pd.DataFrame(data,columns=header)\n",
        "        x_batches, y_batches,x_valid,y_valid,X_Test,Y_Test=preprocessing(data,Number_of_TimeFeatures)\n",
        "        #===============================\n",
        "        for element1 in (x_batches):\n",
        "            x_batches_Full.append(element1)\n",
        "            \n",
        "        for element2 in (y_batches):\n",
        "            y_batches_Full.append(element2)\n",
        "\n",
        "        for element3 in (x_valid):\n",
        "            X_Valid_Full.append(element3)\n",
        "            \n",
        "        for element4 in (y_valid):\n",
        "            Y_Valid_Full.append(element4)\n",
        "                        \n",
        "        for element5 in (X_Test):\n",
        "            X_Test_Full.append(element5)\n",
        "            \n",
        "        for element6 in (Y_Test):\n",
        "            Y_Test_Full.append(element6)\n",
        "    #---------------------shuffle minibatches X and Y together-------------------------------------\n",
        "    print(len(x_batches_Full),'     length of all file : ',len(y_batches_Full))\n",
        "    combined = list(zip(x_batches_Full, y_batches_Full))\n",
        "    random.shuffle(combined)\n",
        "    shuffled_batch_features, shuffled_batch_y = zip(*combined)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Birm_Data_Events/Birm1.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm2.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  39\n",
            "len x_batches  15\n",
            "len Test 126\n",
            "len xTestbatches 39\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm3.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm4.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm5.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  36\n",
            "len x_batches  15\n",
            "len Test 117\n",
            "len xTestbatches 36\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm6.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  36\n",
            "len x_batches  15\n",
            "len Test 117\n",
            "len xTestbatches 36\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm7.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  36\n",
            "len x_batches  15\n",
            "len Test 117\n",
            "len xTestbatches 36\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm9.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm10.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  39\n",
            "len x_batches  15\n",
            "len Test 126\n",
            "len xTestbatches 39\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm11.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm12.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm13.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm14.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  31\n",
            "len x_batches  15\n",
            "len Test 102\n",
            "len xTestbatches 31\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm15.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm16.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm17.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  36\n",
            "len x_batches  15\n",
            "len Test 117\n",
            "len xTestbatches 36\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm18.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm19.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  36\n",
            "len x_batches  15\n",
            "len Test 117\n",
            "len xTestbatches 36\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm20.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  37\n",
            "len x_batches  15\n",
            "len Test 120\n",
            "len xTestbatches 37\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm22.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  37\n",
            "len x_batches  15\n",
            "len Test 120\n",
            "len xTestbatches 37\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm23.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm24.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm25.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm26.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm27.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm28.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm29.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "/content/drive/My Drive/Birm_Data_Events/Birm30.csv\n",
            "Index([], dtype='object')\n",
            "instances 59\n",
            "len Train 54\n",
            "len x_validbatches  40\n",
            "len x_batches  15\n",
            "len Test 129\n",
            "len xTestbatches 40\n",
            "420      length of all file :  1260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toQ2LajOKFdL",
        "colab_type": "code",
        "outputId": "386a6e3d-6209-4051-f90c-93f5905e0c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "#xgboost part\n",
        "print(len(x_batches_Full))\n",
        "All_Training_Instances=[]\n",
        "\n",
        "IDs=np.arange(30)\n",
        "Static_Features=np.zeros((30,30))\n",
        "Static_Features[np.arange(30),IDs]=1\n",
        "\n",
        "#=============== change each window into Instance =================================\n",
        "for i in range(0,len(shuffled_batch_features)):\n",
        "    hold=[]\n",
        "    temp=[]\n",
        "    for j in range(0,len(shuffled_batch_features[i])):\n",
        "      #print(len(hold))\n",
        "      \n",
        "      if j==(len(shuffled_batch_features[i])-1):\n",
        "          index=int(shuffled_batch_features[i][j][0])\n",
        "          hold=np.concatenate((hold, Static_Features[index-1]), axis=None)\n",
        "          temp=np.delete(shuffled_batch_features[i][j], [0], axis=0) \n",
        "          hold=np.concatenate((hold, temp), axis=None)\n",
        "          \n",
        "      else:\n",
        "          hold=np.concatenate((hold, shuffled_batch_features[i][j][1]), axis=None)\n",
        "          \n",
        "    #print(len(hold))\n",
        "    All_Training_Instances.append(hold)\n",
        "    \n",
        "\n",
        "print(len(All_Training_Instances[0]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "420\n",
            "77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5zKLm39w34R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_features_labels(features, labels, batch_size):\n",
        "    \"\"\"\n",
        "    Split features and labels into batches\n",
        "    \"\"\"\n",
        "    #batch_size=\n",
        "    X_returned=[]\n",
        "    Y_returned=[]\n",
        "    for start in range(0, len(features), batch_size):\n",
        "        if (start + batch_size)>len(features):\n",
        "            break\n",
        "        else:\n",
        "            end = start + batch_size\n",
        "        X_returned.append(features[start:end])\n",
        "        Y_returned.append(labels[start:end])\n",
        "    return X_returned, Y_returned\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H23SYSNC3y6c",
        "colab_type": "code",
        "outputId": "25720a83-83d4-43b7-c221-1a0071badc59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "####### MLP session##################\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 77])   #create variable objects\n",
        "y = tf.placeholder(tf.float32, [None, num_periods_output])\n",
        "learning_rate=tf.placeholder(tf.float32, None)\n",
        "keep_prob = tf.placeholder(tf.float32, None)\n",
        "\n",
        "\n",
        "MLP1= tf.layers.dense(X, units=100,activation=tf.nn.relu) \n",
        "MLP2= tf.layers.dense(MLP1, units=50,activation=tf.nn.relu)  \n",
        "Dropout = tf.nn.dropout(MLP2,keep_prob=keep_probab)\n",
        "output= tf.layers.dense(Dropout, units=num_periods_output)  \n",
        "\n",
        "\n",
        "outputs = tf.reshape(output, [-1, num_periods_output])          #shape of results\n",
        "#Regularization part\n",
        "tv = tf.trainable_variables()\n",
        "regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
        "Error=tf.square(outputs - y)\n",
        "#Total_err=Error+regularization_cost\n",
        "loss = tf.reduce_mean(tf.square(outputs - y))+ lamda*regularization_cost   #define the cost function which evaluates the quality of our model\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  \n",
        "\n",
        "training_op = optimizer.minimize(loss)    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-7f278615ae37>:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-7f278615ae37>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3QbiznjKFdN",
        "colab_type": "code",
        "outputId": "96710a02-7539-4616-e6ee-ac72051b1129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#=================Testing=====================\n",
        "All_Testing_Instances=[]\n",
        "All_Validation_Instances=[]\n",
        "#=============== change each window into Instance =================================\n",
        "print(\"**1**\")\n",
        "print(len(X_Test_Full))\n",
        "for i in range(0,len(X_Test_Full)):\n",
        "  hold=[]\n",
        "  temp=[]\n",
        "  for j in range(0,len(X_Test_Full[i])):\n",
        "       #print(len(hold))\n",
        "      if j==(len(X_Test_Full[i])-1):\n",
        "          index=int(X_Test_Full[i][j][0])\n",
        "          hold=np.concatenate((hold, Static_Features[index-1]), axis=None)\n",
        "          temp=np.delete(X_Test_Full[i][j], [0], axis=0) \n",
        "          hold=np.concatenate((hold, temp), axis=None)\n",
        "      else:\n",
        "          hold=np.concatenate((hold, X_Test_Full[i][j][1]), axis=None)\n",
        "   \n",
        "  All_Testing_Instances.append(hold)\n",
        "\n",
        "#=============== change each window into Instance validation =================================\n",
        "print(\"**2**\")\n",
        "print(len(X_Valid_Full))\n",
        "for i in range(0,len(X_Valid_Full)):\n",
        "  hold=[]\n",
        "  temp=[]\n",
        "  for j in range(0,len(X_Valid_Full[i])):\n",
        "       #print(len(hold))\n",
        "      if j==(len(X_Valid_Full[i])-1):\n",
        "          index=int(X_Valid_Full[i][j][0])\n",
        "          hold=np.concatenate((hold, Static_Features[index-1]), axis=None)\n",
        "          temp=np.delete(X_Valid_Full[i][j], [0], axis=0) \n",
        "          hold=np.concatenate((hold, temp), axis=None)\n",
        "      else:\n",
        "          hold=np.concatenate((hold, X_Valid_Full[i][j][1]), axis=None)\n",
        "   \n",
        "  All_Validation_Instances.append(hold)\n",
        "\n",
        "\n",
        "#prediction=multioutput.predict(All_Testing_Instances)\n",
        "print(\"**3**\")\n",
        "print(len(All_Testing_Instances[0]))\n",
        "#===========================calling MultiOutput XGoost=========================\n",
        "All_Testing_Instances=np.reshape(All_Testing_Instances, (len(All_Testing_Instances),len(All_Testing_Instances[0])))\n",
        "Y_Test_Full=np.reshape(Y_Test_Full, (len(Y_Test_Full),num_periods_output))\n",
        "#===========================  Validation set =========================\n",
        "All_Validation_Instances=np.reshape(All_Validation_Instances, (len(All_Validation_Instances),len(All_Validation_Instances[0])))\n",
        "Y_Valid_Full=np.reshape(Y_Valid_Full, (len(Y_Valid_Full),num_periods_output))\n",
        "#========== reshape train ==============================\n",
        "All_Training_Instances=np.reshape(All_Training_Instances, (len(All_Training_Instances),len(All_Training_Instances[0])))\n",
        "shuffled_batch_y=np.reshape(shuffled_batch_y, (len(shuffled_batch_y),num_periods_output))\n",
        "\n",
        "# ======= mini batches for MLP=======\n",
        "All_Training_Instances_batches,shuffled_batch_y_batches=batch_features_labels(All_Training_Instances,shuffled_batch_y,MiniBatches_size)\n",
        "\n",
        "Training_Error=[]\n",
        "Validation_Error=[]\n",
        "train_mse=[]\n",
        "validation_mse=[]\n",
        "\n",
        "\n",
        "print(All_Training_Instances.shape)\n",
        "with tf.Session() as sess:\n",
        "    init = tf.global_variables_initializer()           #initialize all the variables\n",
        "    init.run()\n",
        "    for ep in range(epochs):\n",
        "        for i in range(0,len(All_Training_Instances_batches)): \n",
        "            _,Train_Batch_error=sess.run([training_op,Error],\n",
        "                                                        feed_dict={\n",
        "                                                            keep_prob:keep_probab,\n",
        "                                                            X: All_Training_Instances_batches[i],\n",
        "                                                            y: shuffled_batch_y_batches[i],\n",
        "                                                            learning_rate: l_rate                                                     \n",
        "                                                            })  \n",
        "            Training_Error.append(Train_Batch_error)\n",
        "        if ep % 3 == 0:\n",
        "            Sum_train=np.sum(Training_Error,axis=2)\n",
        "            Sum_train_1=np.sum(Sum_train,axis=1)\n",
        "            Sum_train_2=np.sum(Sum_train_1,axis=0)\n",
        "            Mean_train=Sum_train_2/(len(Training_Error)*MiniBatches_size*num_periods_output)\n",
        "            print(\"epoch:\",int(ep+1))\n",
        "            print(\"\\tRMSE Training:\", (Mean_train)**0.5)\n",
        "            train_mse.append((Mean_train)**0.5)\n",
        "            All_Validation_Instances_batches,Y_Validation_Full_batches=batch_features_labels(All_Validation_Instances,Y_Valid_Full,MiniBatches_size)\n",
        "            for i in range(0,len(All_Validation_Instances_batches)): \n",
        "                y_predict,Valid_error_batch=sess.run([outputs,Error], \n",
        "                                                            feed_dict={\n",
        "                                                            keep_prob:keep_prob_testval,\n",
        "                                                            X: All_Validation_Instances_batches[i], \n",
        "                                                            y: Y_Validation_Full_batches[i]\n",
        "                                                            })\n",
        "                Validation_Error.append(Valid_error_batch)\n",
        "            Sum_valid=np.sum(Validation_Error,axis=2)\n",
        "            Sum_valid_1=np.sum(Sum_valid,axis=1)\n",
        "            Sum_valid_2=np.sum(Sum_valid_1,axis=0)  \n",
        "            Mean_valid=Sum_valid_2/(len(Validation_Error)*MiniBatches_size*num_periods_output)\n",
        "            print(\"\\tRMSE Validation:\", (Mean_valid)**0.5)\n",
        "            validation_mse.append((Mean_valid)**0.5)\n",
        "\n",
        "    print('Fitting Done!')\n",
        "    ################################################# Testing  ###########################################\n",
        "    Testing_Error=[]\n",
        "    All_Testing_Instances_batches,Y_Test_Full_batches=batch_features_labels(All_Testing_Instances,Y_Test_Full,MiniBatches_size)\n",
        "    for i in range(0,len(All_Testing_Instances_batches)): \n",
        "          y_predict,Test_error_batch=sess.run([outputs,Error], \n",
        "                                                            feed_dict={\n",
        "                                                            keep_prob:keep_prob_testval,\n",
        "                                                            X: All_Testing_Instances_batches[i], \n",
        "                                                            y: Y_Test_Full_batches[i]\n",
        "                                                            })\n",
        "          Testing_Error.append(Test_error_batch)\n",
        "    Sum_test=np.sum(Testing_Error,axis=2)\n",
        "    Sum_test_1=np.sum(Sum_test,axis=1)\n",
        "    Sum_test_2=np.sum(Sum_test_1,axis=0)  \n",
        "    Mean_test=Sum_test_2/(len(Testing_Error)*MiniBatches_size*num_periods_output)\n",
        "    print(\"\\tRMSE Testing:\", (Mean_test)**0.5)\n",
        "    #testing_mse.append((Mean_test)**0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**1**\n",
            "1083\n",
            "**2**\n",
            "1083\n",
            "**3**\n",
            "77\n",
            "(420, 77)\n",
            "epoch: 1\n",
            "\tRMSE Training: 67.67590890289789\n",
            "\tRMSE Validation: 62.86315587995483\n",
            "epoch: 4\n",
            "\tRMSE Training: 65.38952296462841\n",
            "\tRMSE Validation: 60.50781199564235\n",
            "epoch: 7\n",
            "\tRMSE Training: 63.15261654270927\n",
            "\tRMSE Validation: 58.232318601335976\n",
            "epoch: 10\n",
            "\tRMSE Training: 61.03273754374232\n",
            "\tRMSE Validation: 56.118513858229086\n",
            "epoch: 13\n",
            "\tRMSE Training: 59.13568166643424\n",
            "\tRMSE Validation: 54.262617340347674\n",
            "epoch: 16\n",
            "\tRMSE Training: 57.316560879397386\n",
            "\tRMSE Validation: 52.53790794115553\n",
            "epoch: 19\n",
            "\tRMSE Training: 55.57864962249127\n",
            "\tRMSE Validation: 50.9618204429271\n",
            "epoch: 22\n",
            "\tRMSE Training: 53.94529136289165\n",
            "\tRMSE Validation: 49.51816911261588\n",
            "epoch: 25\n",
            "\tRMSE Training: 52.45863846879749\n",
            "\tRMSE Validation: 48.28502434905556\n",
            "epoch: 28\n",
            "\tRMSE Training: 51.071356768181296\n",
            "\tRMSE Validation: 47.20090041514039\n",
            "epoch: 31\n",
            "\tRMSE Training: 49.87351777785115\n",
            "\tRMSE Validation: 46.28103611607321\n",
            "epoch: 34\n",
            "\tRMSE Training: 48.8059664917731\n",
            "\tRMSE Validation: 45.50284911237702\n",
            "epoch: 37\n",
            "\tRMSE Training: 47.85002465238899\n",
            "\tRMSE Validation: 44.86611191977835\n",
            "epoch: 40\n",
            "\tRMSE Training: 47.04091470464834\n",
            "\tRMSE Validation: 44.38494135372057\n",
            "epoch: 43\n",
            "\tRMSE Training: 46.317531359522064\n",
            "\tRMSE Validation: 43.93528769916425\n",
            "epoch: 46\n",
            "\tRMSE Training: 45.67061448211435\n",
            "\tRMSE Validation: 43.540001027252224\n",
            "epoch: 49\n",
            "\tRMSE Training: 45.08328932310148\n",
            "\tRMSE Validation: 43.20756163396566\n",
            "epoch: 52\n",
            "\tRMSE Training: 44.57131997262998\n",
            "\tRMSE Validation: 42.86636665994682\n",
            "epoch: 55\n",
            "\tRMSE Training: 44.084985934538814\n",
            "\tRMSE Validation: 42.56077311204223\n",
            "epoch: 58\n",
            "\tRMSE Training: 43.632461157567846\n",
            "\tRMSE Validation: 42.27609447503991\n",
            "epoch: 61\n",
            "\tRMSE Training: 43.24115879815954\n",
            "\tRMSE Validation: 42.0123303364336\n",
            "epoch: 64\n",
            "\tRMSE Training: 42.85456608852103\n",
            "\tRMSE Validation: 41.78265768180078\n",
            "epoch: 67\n",
            "\tRMSE Training: 42.497574557656606\n",
            "\tRMSE Validation: 41.56953601771688\n",
            "epoch: 70\n",
            "\tRMSE Training: 42.18354346526278\n",
            "\tRMSE Validation: 41.37607981030526\n",
            "epoch: 73\n",
            "\tRMSE Training: 41.873256114441006\n",
            "\tRMSE Validation: 41.19795390853774\n",
            "epoch: 76\n",
            "\tRMSE Training: 41.59524251115028\n",
            "\tRMSE Validation: 41.0223339293319\n",
            "epoch: 79\n",
            "\tRMSE Training: 41.31459269580487\n",
            "\tRMSE Validation: 40.854561517158146\n",
            "epoch: 82\n",
            "\tRMSE Training: 41.05330970585536\n",
            "\tRMSE Validation: 40.703070588803776\n",
            "epoch: 85\n",
            "\tRMSE Training: 40.82048367247627\n",
            "\tRMSE Validation: 40.54828964461323\n",
            "epoch: 88\n",
            "\tRMSE Training: 40.57667872141097\n",
            "\tRMSE Validation: 40.41197352476945\n",
            "epoch: 91\n",
            "\tRMSE Training: 40.360492097400424\n",
            "\tRMSE Validation: 40.283396283444524\n",
            "epoch: 94\n",
            "\tRMSE Training: 40.15548514946187\n",
            "\tRMSE Validation: 40.15172791901754\n",
            "epoch: 97\n",
            "\tRMSE Training: 39.947539965718974\n",
            "\tRMSE Validation: 40.03217219444956\n",
            "epoch: 100\n",
            "\tRMSE Training: 39.75715868452708\n",
            "\tRMSE Validation: 39.90771178054216\n",
            "epoch: 103\n",
            "\tRMSE Training: 39.58650302417287\n",
            "\tRMSE Validation: 39.80314001881187\n",
            "epoch: 106\n",
            "\tRMSE Training: 39.42053995223539\n",
            "\tRMSE Validation: 39.70425472014233\n",
            "epoch: 109\n",
            "\tRMSE Training: 39.25615833376188\n",
            "\tRMSE Validation: 39.607162250283345\n",
            "epoch: 112\n",
            "\tRMSE Training: 39.09800053498047\n",
            "\tRMSE Validation: 39.51161164480306\n",
            "epoch: 115\n",
            "\tRMSE Training: 38.950123718432\n",
            "\tRMSE Validation: 39.419484181976266\n",
            "epoch: 118\n",
            "\tRMSE Training: 38.79631367542875\n",
            "\tRMSE Validation: 39.32532580920341\n",
            "epoch: 121\n",
            "\tRMSE Training: 38.652933167151005\n",
            "\tRMSE Validation: 39.2475701244132\n",
            "epoch: 124\n",
            "\tRMSE Training: 38.520792807192116\n",
            "\tRMSE Validation: 39.16748748506671\n",
            "epoch: 127\n",
            "\tRMSE Training: 38.39604664073888\n",
            "\tRMSE Validation: 39.089370990316596\n",
            "epoch: 130\n",
            "\tRMSE Training: 38.268604072951334\n",
            "\tRMSE Validation: 38.998504396584934\n",
            "epoch: 133\n",
            "\tRMSE Training: 38.14114402017747\n",
            "\tRMSE Validation: 38.92910668410235\n",
            "epoch: 136\n",
            "\tRMSE Training: 38.02537207666254\n",
            "\tRMSE Validation: 38.85633201993567\n",
            "epoch: 139\n",
            "\tRMSE Training: 37.903211964399866\n",
            "\tRMSE Validation: 38.785474067880266\n",
            "epoch: 142\n",
            "\tRMSE Training: 37.795022975744956\n",
            "\tRMSE Validation: 38.70745312059854\n",
            "epoch: 145\n",
            "\tRMSE Training: 37.68786276773996\n",
            "\tRMSE Validation: 38.65142374347883\n",
            "epoch: 148\n",
            "\tRMSE Training: 37.58263043428919\n",
            "\tRMSE Validation: 38.583651006611596\n",
            "epoch: 151\n",
            "\tRMSE Training: 37.475930465278786\n",
            "\tRMSE Validation: 38.51197451926542\n",
            "epoch: 154\n",
            "\tRMSE Training: 37.37230060905875\n",
            "\tRMSE Validation: 38.45365318808624\n",
            "epoch: 157\n",
            "\tRMSE Training: 37.27455587828736\n",
            "\tRMSE Validation: 38.40369832205384\n",
            "epoch: 160\n",
            "\tRMSE Training: 37.17892233006492\n",
            "\tRMSE Validation: 38.34736495908885\n",
            "epoch: 163\n",
            "\tRMSE Training: 37.08896237233998\n",
            "\tRMSE Validation: 38.28286615326876\n",
            "epoch: 166\n",
            "\tRMSE Training: 37.00032053752397\n",
            "\tRMSE Validation: 38.23100383220217\n",
            "epoch: 169\n",
            "\tRMSE Training: 36.9173072415161\n",
            "\tRMSE Validation: 38.174776967144524\n",
            "epoch: 172\n",
            "\tRMSE Training: 36.82941769498858\n",
            "\tRMSE Validation: 38.12230770595592\n",
            "epoch: 175\n",
            "\tRMSE Training: 36.750821176442535\n",
            "\tRMSE Validation: 38.0801660528177\n",
            "epoch: 178\n",
            "\tRMSE Training: 36.67621066630182\n",
            "\tRMSE Validation: 38.0364648232456\n",
            "epoch: 181\n",
            "\tRMSE Training: 36.592952858371895\n",
            "\tRMSE Validation: 37.99002073183059\n",
            "epoch: 184\n",
            "\tRMSE Training: 36.5213265321328\n",
            "\tRMSE Validation: 37.94245696212332\n",
            "epoch: 187\n",
            "\tRMSE Training: 36.45271092374118\n",
            "\tRMSE Validation: 37.89998651945147\n",
            "epoch: 190\n",
            "\tRMSE Training: 36.38292025064663\n",
            "\tRMSE Validation: 37.849825005271654\n",
            "epoch: 193\n",
            "\tRMSE Training: 36.30706900771413\n",
            "\tRMSE Validation: 37.81108786301467\n",
            "epoch: 196\n",
            "\tRMSE Training: 36.2359402713237\n",
            "\tRMSE Validation: 37.7683485660823\n",
            "epoch: 199\n",
            "\tRMSE Training: 36.16652289838579\n",
            "\tRMSE Validation: 37.724123470327015\n",
            "epoch: 202\n",
            "\tRMSE Training: 36.099234105037425\n",
            "\tRMSE Validation: 37.684885835098555\n",
            "epoch: 205\n",
            "\tRMSE Training: 36.03685585168047\n",
            "\tRMSE Validation: 37.64551928560169\n",
            "epoch: 208\n",
            "\tRMSE Training: 35.97222402691148\n",
            "\tRMSE Validation: 37.61285399586537\n",
            "epoch: 211\n",
            "\tRMSE Training: 35.910792414653585\n",
            "\tRMSE Validation: 37.58005246550168\n",
            "epoch: 214\n",
            "\tRMSE Training: 35.83931070192038\n",
            "\tRMSE Validation: 37.543337226981954\n",
            "epoch: 217\n",
            "\tRMSE Training: 35.78111259356226\n",
            "\tRMSE Validation: 37.51422960618018\n",
            "epoch: 220\n",
            "\tRMSE Training: 35.722100524872424\n",
            "\tRMSE Validation: 37.48138051266435\n",
            "epoch: 223\n",
            "\tRMSE Training: 35.658203457851805\n",
            "\tRMSE Validation: 37.45167441739643\n",
            "epoch: 226\n",
            "\tRMSE Training: 35.600584838671644\n",
            "\tRMSE Validation: 37.422540614616636\n",
            "epoch: 229\n",
            "\tRMSE Training: 35.54364769628318\n",
            "\tRMSE Validation: 37.386410758664496\n",
            "epoch: 232\n",
            "\tRMSE Training: 35.48595318662327\n",
            "\tRMSE Validation: 37.35570529315058\n",
            "epoch: 235\n",
            "\tRMSE Training: 35.43081861602154\n",
            "\tRMSE Validation: 37.327093466349204\n",
            "epoch: 238\n",
            "\tRMSE Training: 35.37892122757407\n",
            "\tRMSE Validation: 37.29136755001082\n",
            "epoch: 241\n",
            "\tRMSE Training: 35.32434676554078\n",
            "\tRMSE Validation: 37.26257917936928\n",
            "epoch: 244\n",
            "\tRMSE Training: 35.27154008971747\n",
            "\tRMSE Validation: 37.233824139631096\n",
            "epoch: 247\n",
            "\tRMSE Training: 35.2212474020442\n",
            "\tRMSE Validation: 37.20694856928406\n",
            "epoch: 250\n",
            "\tRMSE Training: 35.16796601075094\n",
            "\tRMSE Validation: 37.17945466192764\n",
            "epoch: 253\n",
            "\tRMSE Training: 35.117460063585504\n",
            "\tRMSE Validation: 37.150403518907396\n",
            "epoch: 256\n",
            "\tRMSE Training: 35.06595580488883\n",
            "\tRMSE Validation: 37.12754841108475\n",
            "epoch: 259\n",
            "\tRMSE Training: 35.0128584580045\n",
            "\tRMSE Validation: 37.1007433624446\n",
            "epoch: 262\n",
            "\tRMSE Training: 34.96487354925685\n",
            "\tRMSE Validation: 37.06992490397524\n",
            "epoch: 265\n",
            "\tRMSE Training: 34.91682164748482\n",
            "\tRMSE Validation: 37.04714744928702\n",
            "epoch: 268\n",
            "\tRMSE Training: 34.87364585719615\n",
            "\tRMSE Validation: 37.02698668613955\n",
            "epoch: 271\n",
            "\tRMSE Training: 34.82395322658218\n",
            "\tRMSE Validation: 37.00240840839928\n",
            "epoch: 274\n",
            "\tRMSE Training: 34.774960840522226\n",
            "\tRMSE Validation: 36.9790788935476\n",
            "epoch: 277\n",
            "\tRMSE Training: 34.73411124175358\n",
            "\tRMSE Validation: 36.95778251156369\n",
            "epoch: 280\n",
            "\tRMSE Training: 34.69375801550036\n",
            "\tRMSE Validation: 36.93769687998796\n",
            "epoch: 283\n",
            "\tRMSE Training: 34.654481427931785\n",
            "\tRMSE Validation: 36.91722827381618\n",
            "epoch: 286\n",
            "\tRMSE Training: 34.61081911099186\n",
            "\tRMSE Validation: 36.89570613920293\n",
            "epoch: 289\n",
            "\tRMSE Training: 34.57187696737465\n",
            "\tRMSE Validation: 36.87508955082609\n",
            "epoch: 292\n",
            "\tRMSE Training: 34.52778106865708\n",
            "\tRMSE Validation: 36.85443044421318\n",
            "epoch: 295\n",
            "\tRMSE Training: 34.486589549520005\n",
            "\tRMSE Validation: 36.82929242197073\n",
            "epoch: 298\n",
            "\tRMSE Training: 34.444354988938706\n",
            "\tRMSE Validation: 36.81054536406653\n",
            "epoch: 301\n",
            "\tRMSE Training: 34.40364028872932\n",
            "\tRMSE Validation: 36.78865541276561\n",
            "epoch: 304\n",
            "\tRMSE Training: 34.36375015276132\n",
            "\tRMSE Validation: 36.77562840201028\n",
            "epoch: 307\n",
            "\tRMSE Training: 34.32820845551763\n",
            "\tRMSE Validation: 36.75658954527746\n",
            "epoch: 310\n",
            "\tRMSE Training: 34.288431071956964\n",
            "\tRMSE Validation: 36.73830596257808\n",
            "epoch: 313\n",
            "\tRMSE Training: 34.251065917821045\n",
            "\tRMSE Validation: 36.72243053995616\n",
            "epoch: 316\n",
            "\tRMSE Training: 34.214095027096754\n",
            "\tRMSE Validation: 36.707783639399715\n",
            "epoch: 319\n",
            "\tRMSE Training: 34.17722267291879\n",
            "\tRMSE Validation: 36.694710141060504\n",
            "epoch: 322\n",
            "\tRMSE Training: 34.14064238899027\n",
            "\tRMSE Validation: 36.674474389679524\n",
            "epoch: 325\n",
            "\tRMSE Training: 34.10331023860835\n",
            "\tRMSE Validation: 36.65992909671467\n",
            "epoch: 328\n",
            "\tRMSE Training: 34.0671190088181\n",
            "\tRMSE Validation: 36.64677641472588\n",
            "epoch: 331\n",
            "\tRMSE Training: 34.03245629646789\n",
            "\tRMSE Validation: 36.63087037478655\n",
            "epoch: 334\n",
            "\tRMSE Training: 33.99963491937375\n",
            "\tRMSE Validation: 36.61501494191186\n",
            "epoch: 337\n",
            "\tRMSE Training: 33.97010780863329\n",
            "\tRMSE Validation: 36.600585734468716\n",
            "epoch: 340\n",
            "\tRMSE Training: 33.93569286164642\n",
            "\tRMSE Validation: 36.58629736124254\n",
            "epoch: 343\n",
            "\tRMSE Training: 33.902347545505016\n",
            "\tRMSE Validation: 36.56958636270214\n",
            "epoch: 346\n",
            "\tRMSE Training: 33.870848009667945\n",
            "\tRMSE Validation: 36.554291003010285\n",
            "epoch: 349\n",
            "\tRMSE Training: 33.83939220994507\n",
            "\tRMSE Validation: 36.54133226464538\n",
            "epoch: 352\n",
            "\tRMSE Training: 33.80646231032455\n",
            "\tRMSE Validation: 36.52838568572508\n",
            "epoch: 355\n",
            "\tRMSE Training: 33.7714668297216\n",
            "\tRMSE Validation: 36.51675970695919\n",
            "epoch: 358\n",
            "\tRMSE Training: 33.73841617884549\n",
            "\tRMSE Validation: 36.503217609319506\n",
            "epoch: 361\n",
            "\tRMSE Training: 33.70540383174124\n",
            "\tRMSE Validation: 36.488427563741084\n",
            "epoch: 364\n",
            "\tRMSE Training: 33.67466323720542\n",
            "\tRMSE Validation: 36.472624053224756\n",
            "epoch: 367\n",
            "\tRMSE Training: 33.64531566387374\n",
            "\tRMSE Validation: 36.46167522430369\n",
            "epoch: 370\n",
            "\tRMSE Training: 33.615060572566236\n",
            "\tRMSE Validation: 36.45105534115399\n",
            "epoch: 373\n",
            "\tRMSE Training: 33.58494459021472\n",
            "\tRMSE Validation: 36.4385664509459\n",
            "epoch: 376\n",
            "\tRMSE Training: 33.55308327356997\n",
            "\tRMSE Validation: 36.426584815889704\n",
            "epoch: 379\n",
            "\tRMSE Training: 33.522036228856386\n",
            "\tRMSE Validation: 36.41643167668947\n",
            "epoch: 382\n",
            "\tRMSE Training: 33.49311779740095\n",
            "\tRMSE Validation: 36.40533461832036\n",
            "epoch: 385\n",
            "\tRMSE Training: 33.46617792540799\n",
            "\tRMSE Validation: 36.392808781512755\n",
            "epoch: 388\n",
            "\tRMSE Training: 33.437634285307\n",
            "\tRMSE Validation: 36.381490631596215\n",
            "epoch: 391\n",
            "\tRMSE Training: 33.4128442154776\n",
            "\tRMSE Validation: 36.37182247866949\n",
            "epoch: 394\n",
            "\tRMSE Training: 33.38321722134308\n",
            "\tRMSE Validation: 36.36426121030389\n",
            "epoch: 397\n",
            "\tRMSE Training: 33.35374480011856\n",
            "\tRMSE Validation: 36.35498635530946\n",
            "epoch: 400\n",
            "\tRMSE Training: 33.3254719896558\n",
            "\tRMSE Validation: 36.346368944473134\n",
            "Fitting Done!\n",
            "\tRMSE Testing: 32.597101787150876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffvx1P9i34te",
        "colab_type": "code",
        "outputId": "60d8da1a-7eeb-4888-d3c9-597e1cb81fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "Train_draw=[]\n",
        "Valid_draw=[]\n",
        "for i in range(0,len(train_mse)):\n",
        "  if i%1==0:\n",
        "    Train_draw.append(train_mse[i])\n",
        "    Valid_draw.append(validation_mse[i])\n",
        "\n",
        "plt.title(\"Training vs. Validation Error\", fontsize=14)\n",
        "#plt.legend(loc=\"lower right\")\n",
        "plt.plot(Train_draw[1:], markersize=10, label=\"Training Error\",color='red')\n",
        "plt.plot(Valid_draw[1:], markersize=10, label=\"Validation Error\",color='blue')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.savefig('Training vs Testing Error.png')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEJCAYAAACNNHw2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVIh7VtcZW2D",
        "colab_type": "code",
        "outputId": "c730e722-2eff-4c61-e626-b18df2069d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('With Features for {} weeks'.format(No_Of_weeks))\n",
        "print(\"RMSE Testing:\", (Mean_test)**0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Features for 0.5 weeks\n",
            "RMSE Testing: 32.597101787150876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ypi7wBMTF7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}