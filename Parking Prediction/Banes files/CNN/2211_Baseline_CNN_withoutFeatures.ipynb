{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2211_Baseline_CNN_withoutFeatures.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "TensorFlow-GPU-1.13",
      "language": "python",
      "name": "tf-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PuuRX58dsI_3",
        "outputId": "fa090c6f-d4e9-440b-8fef-7ea82a1a4c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lVbzKDghsFuf",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.version\n",
        "#Import Libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import tensorflow.contrib.learn as tflearn\n",
        "import tensorflow.contrib.layers as tflayers\n",
        "from tensorflow.contrib.learn.python.learn import learn_runner\n",
        "import tensorflow.contrib.metrics as metrics\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "from random import shuffle\n",
        "#TF Version\n",
        "tf.__version__\n",
        "\n",
        "#np.random.seed(1)\n",
        "#tf.random.set_random_seed(1)\n",
        "#with warnings.catch_warnings():\n",
        "#    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "#    import h5py\n",
        "\n",
        "#num_periods_output = 4 #to predict\n",
        "#num_periods_input=8 #input\n",
        "\n",
        "ALL_Test_Data=[]\n",
        "ALL_Test_Prediction=[]\n",
        "Event_Based_StartIndex=0\n",
        "Number_of_EventBased=0\n",
        "Number_of_TimeFeatures=2\n",
        "\n",
        "\n",
        "No_Of_weeks=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7VWsYwOysFuq"
      },
      "source": [
        "<h5>Preprocessing data</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TnP7bj4HsFut",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "def preprocessing(df_,num_features):\n",
        "    \n",
        "    if df_.ID[0]!=7 and df_.ID[0]!=8:\n",
        "        print(df_.Year.unique())\n",
        "        df=df_[(df_.Year==2017) | (df_.Year==2018)]\n",
        "        #.isin(years)\n",
        "        #print(df.loc[df['Year'].isin([2017,2018])])\n",
        "        print(df.Year.unique())\n",
        "        print(df.Capacity.unique())\n",
        "    else:\n",
        "        df=df_[(df_.Year==2015) | (df_.Year==2016)]\n",
        "        print(df.Year.unique())\n",
        "        print(df.Capacity.unique())\n",
        "    \n",
        "    cols=df.columns\n",
        "    #df_part=df[['Occupancy_m5', 'Occupancy_m6', 'Occupancy_m7']]\n",
        "    print(cols[20:])\n",
        "    '''df_=df[['ID','Occupancy','Year', 'Month', 'Day', 'Hour','Minute', 'Capacity', \n",
        "    'DayOfWeek','IsWeekend', 'temperature', 'dew_point', 'humidity', 'wind_speed', \n",
        "    'feels_like', 'Status', 'light_snow','snow_shower', 'fog', \n",
        "    'thunder', 'mostly_cloudy','rain', 'heavy_rain', 'mist', 'shallow_fog','light_freezing_rain',\n",
        "    'partly_cloudy', 'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower']]'''\n",
        "    \n",
        "    # select features\n",
        "    df=df[['ID','Occupancy']]\n",
        "\n",
        "    ################################################encoding########################\n",
        "    df['Occupancy'] = pd.to_numeric(df['Occupancy'],errors='coerce')\n",
        "    df['Occupancy'] = df['Occupancy'].abs()\n",
        "    \n",
        "    \n",
        "    Number_Of_Features=num_features\n",
        "    df=df.values\n",
        "    df = df.astype('float32')\n",
        "    split=num_periods_output+num_periods_input\n",
        "    \n",
        "    \n",
        "    ##################################SPLIT##############################################\n",
        "   ########################## SPLITTING FOR TESTING & VALIDATION ##########################\n",
        "    #test_len=np.floor(len(df)*0.2)\n",
        "    test_val_len=np.floor(len(df)*0.2)\n",
        "    #mod=test_len%(num_periods_input+num_periods_output)\n",
        "    mod=test_val_len%(num_periods_input+num_periods_output)\n",
        "    #let thelength be divisable by 12\n",
        "    test_val_len=int(test_val_len-mod)\n",
        "    Test_Val=df[(len(df)-test_val_len):,:]\n",
        "    \n",
        "    ############################ VALIDATION & TESTING ##################################\n",
        "    valid_len=np.floor(len(Test_Val)*0.5)\n",
        "    Valid=Test_Val[0:(len(Test_Val)-int(valid_len)),:]\n",
        "    Test=Test_Val[(len(Test_Val)-int(valid_len)):,:]\n",
        "    \n",
        "    ########################### SPLITTING FOR TRAIN ###########################\n",
        "    \n",
        "    new_cutted_df=df[:(len(df)-test_val_len),:]\n",
        "    Start_train_index=12*24*7*No_Of_weeks\n",
        "    #Start_train_index=12*24*1 # 1 day\n",
        "    Start_train_index=np.floor(Start_train_index)\n",
        "    Start_train_index=int(Start_train_index)\n",
        "    print('instances',Start_train_index)\n",
        "    Train=new_cutted_df[len(new_cutted_df)-Start_train_index:,:]\n",
        "    train_len=len(Train)\n",
        "    mod=train_len%(num_periods_input+num_periods_output)\n",
        "    #let thelength be divisable by 12\n",
        "    train_len=int(train_len-mod)\n",
        "    Train=Train[0:train_len,:]\n",
        "    print('len Train',len(Train))\n",
        "\n",
        "    ############################################ TRAIN minibatches ##################################\n",
        "    \n",
        "    end=len(Train)\n",
        "    start=0\n",
        "    next=0\n",
        "    x_batches=[]\n",
        "    y_batches=[]\n",
        "    \n",
        "    count=0\n",
        "    #print('lennnn',len(Train))\n",
        "    while next+(num_periods_input+num_periods_output)<end:\n",
        "        next=start+num_periods_input\n",
        "        x_batches.append(Train[start:next,:])\n",
        "        y_batches.append(Train[next:next+num_periods_output,1])\n",
        "        start=start+1\n",
        "    y_batches=np.asarray(y_batches)\n",
        "    y_batches = y_batches.reshape(-1, num_periods_output, 1)   \n",
        "    x_batches=np.asarray(x_batches)\n",
        "    x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
        "    print('len x_batches ',len(x_batches))\n",
        "    \n",
        "    ############################################ VALID minibatches ##################################\n",
        "    \n",
        "    end_val=len(Valid)\n",
        "    start_val=0\n",
        "    next_val=0\n",
        "    x_validbatches=[]\n",
        "    y_validbatches=[]\n",
        "    \n",
        "    while next_val+(num_periods_input+num_periods_output)<end_val:\n",
        "        next_val=start_val+num_periods_input\n",
        "        x_validbatches.append(Valid[start_val:next_val,:])\n",
        "        y_validbatches.append(Valid[next_val:next_val+num_periods_output,1])\n",
        "        start_val=start_val+1\n",
        "    y_validbatches=np.asarray(y_validbatches)\n",
        "    y_validbatches = y_validbatches.reshape(-1, num_periods_output, 1)   \n",
        "    x_validbatches=np.asarray(x_validbatches)\n",
        "    x_validbatches = x_validbatches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
        "\n",
        "    ###########################################TEST#####################################\n",
        "    \n",
        "    ID_Test=Test[:,0]\n",
        "    Test=np.delete(Test,[0],1)\n",
        "    #X_test=X_test.drop(columns=['ID'], axis=1)\n",
        "    occ_Test=Test[:,0]\n",
        "    Test=np.delete(Test,[0],1)\n",
        "    #X_test=X_test.drop(columns=['Occupancy'], axis=1)\n",
        "    #Test = Test.astype('float32')\n",
        "    #Test=normalizer.transform(Test)\n",
        "    \n",
        "    #------------------\n",
        "    ID_Test=np.reshape(ID_Test,(len(ID_Test),1))\n",
        "    occ_Test=np.reshape(occ_Test,(len(occ_Test),1))\n",
        "    \n",
        "    Test=np.append(occ_Test,Test, axis=1)\n",
        "    Test=np.append(ID_Test, Test, axis=1)\n",
        "    \n",
        "    ############################################ TEST minibatches ##################################\n",
        "    end_test=len(Test)\n",
        "    start_test=0\n",
        "    next_test=0\n",
        "    x_testbatches=[]\n",
        "    y_testbatches=[]\n",
        "    \n",
        "    \n",
        "    #print('lennnn',len(Train))\n",
        "    while next_test+(num_periods_input+num_periods_output)<end_test:\n",
        "        next_test=start_test+num_periods_input\n",
        "        x_testbatches.append(Test[start_test:next_test,:])\n",
        "        y_testbatches.append(Test[next_test:next_test+num_periods_output,1])\n",
        "        start_test=start_test+1\n",
        "    y_testbatches=np.asarray(y_testbatches)\n",
        "    y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)   \n",
        "    x_testbatches=np.asarray(x_testbatches)\n",
        "    x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features) \n",
        "    print('len Test',len(Test))\n",
        "    print('len xTestbatches',len(x_testbatches))\n",
        "    ######################## Sampling##########################################\n",
        "    \n",
        "    #x_batches, y_batches, x_validbatches, y_validbatches, x_testbatches, y_testbatches\n",
        "    \n",
        "    return x_batches, y_batches,x_validbatches, y_validbatches, x_testbatches, y_testbatches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TmhRJEHVsFu1",
        "colab": {}
      },
      "source": [
        "def load_locationfiles(path,loc_id):\n",
        "    filename=path + '/BN00'+str(loc_id)+'.csv'\n",
        "    print(filename)\n",
        "    data_loc=pd.read_csv(filename)\n",
        "    #mod=len(data_loc)%(num_periods_input+num_periods_output)\n",
        "    #let thelength be divisable by 12\n",
        "    #data_loc=data_loc[:len(data_loc)-mod]\n",
        "    return data_loc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7MYuE1zOsFu8"
      },
      "source": [
        "# Creating Tensorflow Graph + Run Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NKje0imlsFu_"
      },
      "source": [
        "##### Training Params:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nso4-lghsFvB",
        "colab": {}
      },
      "source": [
        "##### Prediction Params #####\n",
        "num_periods_output = 12    #to predict\n",
        "num_periods_input=24       #input\n",
        "#num_periods = 4           #number of periods per vector we are using to predict one period ahead\n",
        "\n",
        "##### Graph Params #####\n",
        "inputs = Number_of_TimeFeatures-1                #number of vectors submitted\n",
        "hidden = 128               #number of neurons we will recursively work through, can be changed to improve accuracy\n",
        "hidden_event=128\n",
        "output = 1                 #number of output vectors\n",
        "num_layers=1\n",
        "num_layers_EventBased=1\n",
        "\n",
        "##### Static Features #####\n",
        "#Number_Of_Static_Features=18\n",
        "no_sequences=128\n",
        "#128            #re-iterating factor for static features\n",
        "\n",
        "##### Optimization Params #####\n",
        "batchsize=128\n",
        "#128\n",
        "l_rate = 0.00001         #small learning rate so we don't overshoot the minimum\n",
        "#keep_prob_static=0.7       #number of epochs using the constant init_learning_rate\n",
        "#keep_prob_event=0.7\n",
        "lamda=0.0001                #regularization param \n",
        "keep_probab=0.9            #(1-dropout_rate)\n",
        "keep_prob_testval=1.0      #(1-dropout_rate) for testing and validation runs\n",
        "epochs = 130                #number of iterations or training cycles, includes both the FeedFoward and Backpropogation\n",
        "\n",
        "\n",
        "#where to save logs\n",
        "#logs_path = '/tmp/tf_logs_3_LSTM_Fully_0410_ConnEnd_Shift_FSTop3/example/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BkLBQDYosFvI",
        "colab": {}
      },
      "source": [
        "# model decaying learning rate, instead of fixed one\n",
        "#def compute_LR(init_epoch,max_epoch,learning_rate_decay,init_learning_rate):\n",
        "#    LR_to_use = [\n",
        "#        init_learning_rate * (\n",
        "#            learning_rate_decay ** max(float(i+1-init_epoch),0.0)\n",
        "#        ) for i in range(max_epoch)\n",
        "#    ]\n",
        "#    print(\"Middle LR:\", LR_to_use[len(LR_to_use) // 2])\n",
        "#    return LR_to_use"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IWGs1v9usFvO",
        "outputId": "fc7934c6-8332-40a1-dd56-fd7b80883963",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_mse=[]\n",
        "validation_mse=[]\n",
        "test_mse=[]\n",
        "tf.reset_default_graph()   #We didn't have any previous graph objects running, but this would reset the graphs\n",
        "\n",
        "\n",
        "#=============================LSTM part===========================================\n",
        "\n",
        "lstm_graph=tf.Graph()\n",
        "with lstm_graph.as_default():\n",
        "    X = tf.placeholder(tf.float32, [None, num_periods_input, inputs])   #create variable objects\n",
        "    y = tf.placeholder(tf.float32, [None, num_periods_output, output])\n",
        "    learning_rate=tf.placeholder(tf.float32, None)\n",
        "    #batchsize = tf.placeholder(tf.int16)\n",
        "    #dropout = tf.placeholder(tf.float32)\n",
        "    is_train = tf.placeholder(tf.bool)\n",
        "    #EventBased_X=tf.placeholder(tf.float32, [None,num_periods_input,Number_of_EventBased])\n",
        "    #static_X = tf.placeholder(tf.float32, [None,Number_Of_Static_Features])\n",
        "    keep_prob = tf.placeholder(tf.float32, None)\n",
        "\n",
        "    \n",
        "    #====================================================================================\n",
        "    #=========================Static Features part=======================================\n",
        "    '''\n",
        "    Layer1 = tf.layers.dense(static_X, units=100,activation=tf.nn.relu)  \n",
        "    Static_Output_1 = tf.layers.dense(Layer1,units= 50,activation=tf.nn.relu) \n",
        "    Static_Output = tf.nn.dropout(Static_Output_1,keep_prob=keep_prob_static) # dropout \n",
        "    #===================================== Combine before LSTM ===========================\n",
        "    Static_Output=tf.reshape(Static_Output, [-1, num_periods_input,50])\n",
        "\n",
        "    Combined_output=tf.concat([X,Static_Output],2)\n",
        "    '''\n",
        "    #Static_Output=tf.reshape(static_X, [-1, num_periods_input,Number_Of_Static_Features])\n",
        "    #Combined_output=tf.concat([X,Static_Output],2)\n",
        "    #========================================= **Time CNN** ===================================\n",
        "    with tf.variable_scope('Time'):\n",
        "        conv1 = tf.layers.conv1d(inputs=X, filters=128, kernel_size=8, padding=\"same\", activation=tf.nn.relu)\n",
        "        # Pooling Layer #1\n",
        "        pool1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=1)\n",
        "        conv2 = tf.layers.conv1d(inputs=pool1, filters=128, kernel_size=8, padding=\"same\", activation=tf.nn.relu)\n",
        "        flat=tf.contrib.layers.flatten(conv2)\n",
        "        ####################  Fully connected after CNN #################################\n",
        "        #flat = tf.reshape(flat, [-1,(hidden_event*num_periods_input)])# to be able to concat. the static features\n",
        "        CNN_Output_1= tf.layers.dense(flat, units=100,activation=tf.nn.relu)  \n",
        "        CNN_Output = tf.nn.dropout(CNN_Output_1,keep_prob=keep_probab)\n",
        "    #========================CNN Event Based============================================\n",
        "    '''with tf.variable_scope('Event'):\n",
        "        conv1_event = tf.layers.conv1d(inputs=EventBased_X, filters=128, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n",
        "        # Pooling Layer #1\n",
        "        pool1_event = tf.layers.max_pooling1d(inputs=conv1_event, pool_size=2, strides=1)\n",
        "        conv2_event = tf.layers.conv1d(inputs=pool1_event, filters=64, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n",
        "        flat=tf.contrib.layers.flatten(conv2_event)\n",
        "        ####################  Fully connected after CNN #################################\n",
        "        #flat = tf.reshape(flat, [-1,(hidden_event*num_periods_input)])# to be able to concat. the static features\n",
        "        CNN_Output_event_1= tf.layers.dense(flat, units=100,activation=tf.nn.relu)  \n",
        "        CNN_Output_event = tf.nn.dropout(CNN_Output_event_1,keep_prob=keep_prob_event)\n",
        "    '''\n",
        "        #====================================================================================\n",
        "    #=========================Combination part===========================================\n",
        "\n",
        "    #Combined_output=tf.concat([CNN_Output,CNN_Output_event],1)\n",
        "    #Combined_output=tf.multiply(LSTM_Output,LSTM_Output_event)\n",
        "    stacked_outputs = tf.layers.dense(CNN_Output, units=num_periods_output) #specify the type of layer (dense)\n",
        "    outputs = tf.reshape(stacked_outputs, [-1, num_periods_output, output])          #shape of results\n",
        "    #Regularization part\n",
        "    tv = tf.trainable_variables()\n",
        "    regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
        "    Error=tf.square(outputs - y)\n",
        "    #Total_err=Error+regularization_cost\n",
        "    loss = tf.reduce_mean(tf.square(outputs - y))+ lamda*regularization_cost   #define the cost function which evaluates the quality of our model\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)          #gradient descent method\n",
        "    gvs = optimizer.compute_gradients(loss)\n",
        "    capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
        "    \n",
        "    #opt to get gradient info:\n",
        "    grads=tf.gradients(loss,tv)\n",
        "    grads=list(zip(grads,tv))\n",
        "    \n",
        "    training_op = optimizer.apply_gradients(capped_gvs)\n",
        "    #training_op = optimizer.minimize(loss)          #train the result of the application of the cost_function                                 \n",
        "    \n",
        "    #Before running session, set variables to track in Tensorboard\n",
        "    #with lstm_graph.as_default():\n",
        "    saver = tf.train.Saver()\n",
        "    #Creat Summary to monitor scalar values (loss):\n",
        "    #tf.summary.scalar(\"loss\", loss)\n",
        "    \n",
        "    # Create a summary to monitor prediction tensor\n",
        "    #tf.summary.histogram(\"Prediction\", predictions)\n",
        "    \n",
        "    # Gradient Info\n",
        "    for var in tv:\n",
        "        tf.summary.histogram(var.name,var)\n",
        "    \n",
        "    # Merge all summaries into a single op\n",
        "    merged_summary_op = tf.summary.merge_all()\n",
        "\n",
        "#====================================================================================\n",
        "\n",
        "def batch_features_labels(features, labels, batch_size):\n",
        "    \"\"\"\n",
        "    Split features and labels into batches\n",
        "    \"\"\"\n",
        "    #batch_size=\n",
        "    X_returned=[]\n",
        "    Y_returned=[]\n",
        "    for start in range(0, len(features), batch_size):\n",
        "        if (start + batch_size)>len(features):\n",
        "            break\n",
        "        else:\n",
        "            end = start + batch_size\n",
        "        X_returned.append(features[start:end])\n",
        "        Y_returned.append(labels[start:end])\n",
        "    return X_returned, Y_returned\n",
        "\n",
        "\n",
        "# COMPUTE LEARNING RATE schedule beforehand\n",
        "#LR_schedule = compute_LR(init_epoch,epochs,learning_rate_decay,initial_LR) \n",
        "with tf.Session(graph=lstm_graph) as sess:    \n",
        "    \n",
        "    init = tf.global_variables_initializer()           #initialize all the variables\n",
        "    init.run()\n",
        "    \n",
        "    # creating the writer inside the session\n",
        "    #writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "    \n",
        "    #### LOOP OVER LOCATIONS ####\n",
        "    data_path=r'/content/drive/My Drive/FINAL_DATA_EVENTS'\n",
        "    #r'/content/drive/My Drive/FINAL_DATA_EVENTS'\n",
        "    #r'/home/shero/Desktop/OurProject/BanesData/Model/occupation_loc/'\n",
        "    data_All=pd.DataFrame()\n",
        "    x_batches_Full=[]\n",
        "    y_batches_Full=[]\n",
        "    X_Valid_Full=[]\n",
        "    Y_Valid_Full=[]\n",
        "    X_Test_Full=[]\n",
        "    Y_Test_Full=[]\n",
        "    for loc_id in range(1,9):\n",
        "        #========\n",
        "        data=load_locationfiles(data_path,loc_id)\n",
        "        header=list(data.columns.values)\n",
        "        data=pd.DataFrame(data,columns=header)\n",
        "        x_batches, y_batches, X_Valid, Y_Valid,X_Test,Y_Test=preprocessing(data,(Number_of_TimeFeatures+Number_of_EventBased))\n",
        "        #===============================\n",
        "        for element1 in (x_batches):\n",
        "            x_batches_Full.append(element1)\n",
        "            \n",
        "        for element2 in (y_batches):\n",
        "            y_batches_Full.append(element2)\n",
        "            \n",
        "        for element3 in (X_Valid):\n",
        "            X_Valid_Full.append(element3)\n",
        "            \n",
        "        for element4 in (Y_Valid):\n",
        "            Y_Valid_Full.append(element4)\n",
        "            \n",
        "        for element5 in (X_Test):\n",
        "            X_Test_Full.append(element5)\n",
        "            \n",
        "        for element6 in (Y_Test):\n",
        "            Y_Test_Full.append(element6)            \n",
        "    \n",
        "    for ep in range(epochs):\n",
        "        #CALCULATE LR TO USE!!\n",
        "        #curr_lr=LR_schedule[ep]\n",
        "        Training_Error=[]\n",
        "        #even though NOT SHUFFLED YET\n",
        "        shuffled_batch_features,shuffled_batch_y=batch_features_labels(x_batches_Full,y_batches_Full,batchsize)\n",
        "        #---------------------shuffle minibatches X and Y together-------------------------------------\n",
        "        combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
        "        random.shuffle(combined)\n",
        "        shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
        "        #===========================================================================================\n",
        "        print(len(shuffled_batch_features))\n",
        "        \n",
        "        for i in range(0,len(shuffled_batch_features)): \n",
        "            #print('====================')\n",
        "            batch_features=shuffled_batch_features[i]\n",
        "            #print(batch_features)\n",
        "            batch_y=shuffled_batch_y[i] \n",
        "            batch_features=np.delete(batch_features,[0], axis=2) \n",
        "            #print('X',len(batch_features))\n",
        "            #print('Y',len(batch_y[0]))\n",
        "\n",
        "            _,Train_Batch_error,summary=sess.run([training_op,Error,merged_summary_op],\n",
        "                                                 feed_dict={\n",
        "                                                     keep_prob:keep_probab,\n",
        "                                                     X: batch_features,\n",
        "                                                     y: batch_y,\n",
        "                                                     learning_rate: l_rate})  \n",
        "            Training_Error.append(Train_Batch_error)\n",
        "            \n",
        "        \n",
        "        #write logs (per epoch)\n",
        "        #writer.add_summary(summary, ep)\n",
        "        \n",
        "        if ep % 3 == 0:\n",
        "            ################  evaluate training error\n",
        "            #print('Length of whole:',len(Training_Error),'Length of each: ',len(Training_Error[0][0]))\n",
        "            Sum_train=np.sum(Training_Error,axis=2)\n",
        "            Sum_train_1=np.sum(Sum_train,axis=1)\n",
        "            Sum_train_2=np.sum(Sum_train_1,axis=0)\n",
        "            '''print('Sum_train shape:',Sum_train.shape)\n",
        "            print('Sum_train_1 shape:',Sum_train_1.shape)\n",
        "            print('Sum_train_2 shape:',Sum_train_2.shape)'''\n",
        "            Mean_train=Sum_train_2/(len(Training_Error)*batchsize*num_periods_output)\n",
        "            print(\"epoch:\",int(ep+1))\n",
        "            print(\"\\tRMSE Training:\", (Mean_train)**0.5)\n",
        "            #mse = loss.eval(feed_dict={\n",
        "            #                              X: batch_features,\n",
        "            #                             y: batch_y,\n",
        "            #                            static_X:static_train,\n",
        "            #                           is_train:True})\n",
        "            train_mse.append((Mean_train)**0.5)\n",
        "                \n",
        "            \n",
        "            Validation_Error=[]\n",
        "            unshuffled_valid_batch_features,unshuffled_valid_batch_y=batch_features_labels(X_Valid_Full,Y_Valid_Full,batchsize)\n",
        "\n",
        "            for i in range(0,len(unshuffled_valid_batch_features)):\n",
        "                batch_features_valid=unshuffled_valid_batch_features[i]\n",
        "                #print(batch_features)\n",
        "                batch_y_valid=unshuffled_valid_batch_y[i]\n",
        "                batch_features_valid=np.delete(batch_features_valid,[0], axis=2)\n",
        "                \n",
        "                \n",
        "                y_predict,Valid_error_batch=sess.run([outputs,Error], \n",
        "                                                     feed_dict={\n",
        "                                                     keep_prob:keep_prob_testval,\n",
        "                                                     X: batch_features_valid, \n",
        "                                                     y: batch_y_valid})\n",
        "                #print('Valid_error_batch',Valid_error_batch)\n",
        "                Validation_Error.append(Valid_error_batch)\n",
        "            \n",
        "            Sum_valid=np.sum(Validation_Error,axis=2)\n",
        "            Sum_valid_1=np.sum(Sum_valid,axis=1)\n",
        "            Sum_valid_2=np.sum(Sum_valid_1,axis=0)\n",
        "            Mean_valid=Sum_valid_2/(len(Validation_Error)*batchsize*num_periods_output)\n",
        "            print(\"\\tRMSE Validation:\", (Mean_valid)**0.5)\n",
        "            \n",
        "            validation_mse.append((Mean_valid)**0.5)\n",
        "              \n",
        "    # save training session --> TO RESTORE\n",
        "    saver.save(sess,\"checkpoints-conn_beg/har.ckpt\")\n",
        "    print(\"Run the command line:\\n\" \\\n",
        "          \"--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \" \\\n",
        "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Summary name Time/conv1d/kernel:0 is illegal; using Time/conv1d/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name Time/conv1d/bias:0 is illegal; using Time/conv1d/bias_0 instead.\n",
            "INFO:tensorflow:Summary name Time/conv1d_1/kernel:0 is illegal; using Time/conv1d_1/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name Time/conv1d_1/bias:0 is illegal; using Time/conv1d_1/bias_0 instead.\n",
            "INFO:tensorflow:Summary name Time/dense/kernel:0 is illegal; using Time/dense/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name Time/dense/bias:0 is illegal; using Time/dense/bias_0 instead.\n",
            "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN001.csv\n",
            "[2014 2015 2016 2017 2018 2019]\n",
            "[2017 2018]\n",
            "[628]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 18288\n",
            "len xTestbatches 18229\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN002.csv\n",
            "[2014 2015 2016 2017 2018 2019]\n",
            "[2017 2018]\n",
            "[1056]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 19134\n",
            "len xTestbatches 19075\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN003.csv\n",
            "[2014 2015 2016 2017 2018 2019]\n",
            "[2017 2018]\n",
            "[ 860 1500 1160 1360]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 14832\n",
            "len xTestbatches 14773\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN004.csv\n",
            "[2015 2016 2017 2018 2019]\n",
            "[2017 2018]\n",
            "[698]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 19674\n",
            "len xTestbatches 19615\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN005.csv\n",
            "[2014 2015 2016 2017 2018 2019]\n",
            "[2017 2018]\n",
            "[1320 1230]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 14706\n",
            "len xTestbatches 14647\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN006.csv\n",
            "[2014 2015 2016 2017 2018 2019]\n",
            "[2017 2018]\n",
            "[521 519 525 513]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 19638\n",
            "len xTestbatches 19579\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN007.csv\n",
            "[2015 2016]\n",
            "[720 626 800 860 700 623 519 528 563 638 603 630 596 602 840]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 9684\n",
            "len xTestbatches 9625\n",
            "/content/drive/My Drive/FINAL_DATA_EVENTS/BN008.csv\n",
            "[2015 2016]\n",
            "[140 180 132]\n",
            "Index(['fog', 'thunder', 'mostly_cloudy', 'rain', 'heavy_rain', 'mist',\n",
            "       'shallow_fog', 'patches_of_fog', 'light_freezing_rain', 'partly_cloudy',\n",
            "       'haze', 'light_rain', 'rain_shower', 'snow', 'light_snow_shower',\n",
            "       'Events_Rugby', 'Events_Football', 'Events_Other_Sport',\n",
            "       'Events_Exhibitions'],\n",
            "      dtype='object')\n",
            "instances 2016\n",
            "len Train 2016\n",
            "len x_batches  1957\n",
            "len Test 9684\n",
            "len xTestbatches 9625\n",
            "122\n",
            "epoch: 1\n",
            "\tRMSE Training: [44.30731099]\n",
            "\tRMSE Validation: [35.18964074]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 4\n",
            "\tRMSE Training: [18.11502988]\n",
            "\tRMSE Validation: [16.7351801]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 7\n",
            "\tRMSE Training: [15.47580685]\n",
            "\tRMSE Validation: [14.70060225]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 10\n",
            "\tRMSE Training: [13.91825842]\n",
            "\tRMSE Validation: [13.36966859]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 13\n",
            "\tRMSE Training: [12.98937539]\n",
            "\tRMSE Validation: [12.56216672]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 16\n",
            "\tRMSE Training: [12.38153004]\n",
            "\tRMSE Validation: [11.99256947]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 19\n",
            "\tRMSE Training: [11.90056746]\n",
            "\tRMSE Validation: [11.56773161]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 22\n",
            "\tRMSE Training: [11.57910905]\n",
            "\tRMSE Validation: [11.29962424]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 25\n",
            "\tRMSE Training: [11.41430095]\n",
            "\tRMSE Validation: [11.09085086]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 28\n",
            "\tRMSE Training: [11.21496423]\n",
            "\tRMSE Validation: [11.07763152]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 31\n",
            "\tRMSE Training: [11.02721403]\n",
            "\tRMSE Validation: [10.83915546]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 34\n",
            "\tRMSE Training: [10.96404517]\n",
            "\tRMSE Validation: [10.68547848]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 37\n",
            "\tRMSE Training: [10.84042302]\n",
            "\tRMSE Validation: [10.57566944]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 40\n",
            "\tRMSE Training: [10.67340109]\n",
            "\tRMSE Validation: [10.48255179]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 43\n",
            "\tRMSE Training: [10.62861609]\n",
            "\tRMSE Validation: [10.47451355]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 46\n",
            "\tRMSE Training: [10.54775997]\n",
            "\tRMSE Validation: [10.33688296]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 49\n",
            "\tRMSE Training: [10.44906114]\n",
            "\tRMSE Validation: [10.2742762]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 52\n",
            "\tRMSE Training: [10.33835195]\n",
            "\tRMSE Validation: [10.17722153]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 55\n",
            "\tRMSE Training: [10.33889083]\n",
            "\tRMSE Validation: [10.15266968]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 58\n",
            "\tRMSE Training: [10.25545834]\n",
            "\tRMSE Validation: [10.07922811]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 61\n",
            "\tRMSE Training: [10.23405074]\n",
            "\tRMSE Validation: [10.05852034]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 64\n",
            "\tRMSE Training: [10.09670095]\n",
            "\tRMSE Validation: [10.08071422]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 67\n",
            "\tRMSE Training: [10.13004685]\n",
            "\tRMSE Validation: [9.9419615]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 70\n",
            "\tRMSE Training: [10.0834981]\n",
            "\tRMSE Validation: [9.90762951]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 73\n",
            "\tRMSE Training: [10.05475001]\n",
            "\tRMSE Validation: [9.96096955]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 76\n",
            "\tRMSE Training: [9.9878539]\n",
            "\tRMSE Validation: [9.84676176]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 79\n",
            "\tRMSE Training: [9.93094755]\n",
            "\tRMSE Validation: [9.84540494]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 82\n",
            "\tRMSE Training: [9.87413533]\n",
            "\tRMSE Validation: [9.80162761]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 85\n",
            "\tRMSE Training: [9.86001535]\n",
            "\tRMSE Validation: [9.7850714]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 88\n",
            "\tRMSE Training: [9.82153931]\n",
            "\tRMSE Validation: [9.81034436]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 91\n",
            "\tRMSE Training: [9.82239829]\n",
            "\tRMSE Validation: [9.72407518]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 94\n",
            "\tRMSE Training: [9.81209483]\n",
            "\tRMSE Validation: [9.88068911]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 97\n",
            "\tRMSE Training: [9.83847249]\n",
            "\tRMSE Validation: [9.78559059]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 100\n",
            "\tRMSE Training: [9.75420309]\n",
            "\tRMSE Validation: [9.72197856]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 103\n",
            "\tRMSE Training: [9.72647391]\n",
            "\tRMSE Validation: [9.64876716]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 106\n",
            "\tRMSE Training: [9.68636021]\n",
            "\tRMSE Validation: [9.75801226]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 109\n",
            "\tRMSE Training: [9.67020314]\n",
            "\tRMSE Validation: [9.86887494]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 112\n",
            "\tRMSE Training: [9.70899805]\n",
            "\tRMSE Validation: [9.60581301]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 115\n",
            "\tRMSE Training: [9.70187711]\n",
            "\tRMSE Validation: [9.63034359]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 118\n",
            "\tRMSE Training: [9.66549093]\n",
            "\tRMSE Validation: [9.61722975]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 121\n",
            "\tRMSE Training: [9.66060353]\n",
            "\tRMSE Validation: [9.60494833]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 124\n",
            "\tRMSE Training: [9.63583637]\n",
            "\tRMSE Validation: [9.59668385]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 127\n",
            "\tRMSE Training: [9.60963774]\n",
            "\tRMSE Validation: [9.57879734]\n",
            "122\n",
            "122\n",
            "122\n",
            "epoch: 130\n",
            "\tRMSE Training: [9.63109128]\n",
            "\tRMSE Validation: [9.61582169]\n",
            "Run the command line:\n",
            "--> tensorboard --logdir=/tmp/tf_logs_1_LSTM_Fully_1110_ConnBeg_Shift_FS4/example \n",
            "Then open http://0.0.0.0:6006/ into your web browser\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_irySJICsFvV",
        "outputId": "b14d72d3-5873-49ad-b4ee-0e97dadf231a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('min training RMSE:',min(train_mse))\n",
        "print('min validation RMSE:',min(validation_mse))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min training RMSE: [9.60963774]\n",
            "min validation RMSE: [9.57879734]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zeoeBeZxsFvZ"
      },
      "source": [
        "### Plot Training + Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DgI4Lq9asFva",
        "outputId": "da602516-b2bd-41ff-96ed-cfeb24f6f49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "Train_draw=[]\n",
        "Valid_draw=[]\n",
        "for i in range(0,len(train_mse)):\n",
        "  if i%1==0:\n",
        "    Train_draw.append(train_mse[i])\n",
        "    Valid_draw.append(validation_mse[i])\n",
        "\n",
        "plt.title(\"Training vs. Validation Error\", fontsize=14)\n",
        "#plt.legend(loc=\"lower right\")\n",
        "plt.plot(Train_draw[1:], markersize=10, label=\"Training Error\",color='red')\n",
        "plt.plot(Valid_draw[1:], markersize=10, label=\"Validation Error\",color='blue')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.savefig('Training vs Testing Error.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEJCAYAAACNNHw2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhU5fXA8e8hJAQSlgAhrAmo7HuI\niAIquKFVEIooQnEtLbVWsbal1lZrtbXqz6XV2lpEpbJoVdC61BULqKiACEhAUNn3NSwhkOT9/XHu\nJJMhO0kmd+Z8nuc+M/fOnXvfuYEz75z7LuKcwxhjjP/UCXcBjDHGVI4FcGOM8SkL4MYY41MWwI0x\nxqcsgBtjjE9ZADfGGJ+yAB7hRGS2iLxUwfcsEpGHqqtMfiQiL4nI7JLWS3jPhyLyeFWf25gAC+Bh\nJiKujOXZkzzFj4AbK/ieS4Dfn+R5w0pE6ovIfhH5RQmvTxaRLBFJqOQpbkSvbZURkUu9v3l8dZ+r\nhPMvLuHf4NTqPrepnLrhLoChVdDzS4F/hmzLLu5NIhLrnDte1sGdcwcqWiDn3N6Kvqe2cc5li8gs\n4DrgwWJ2uQGY7Zw7XMnj7z+Z8tXWcwGPA/eFbDtS0s7F/TsUkRjAOefyK3ry8v67Nspq4GHmnNse\nWID9oduccwdEpItXE7pCRP4nIkeBa0QkRUReEJEtInJERFaKyLjg44emULz0yCMi8qCI7BWR7SLy\nJxGRkH0eClrfLiK/EpFpInJQRDaJyM9CztNNRD4SkaMiskpELhCRXBG5qrjPLSLDRSRbRBqFbH9Y\nRD7znjcTkZkisss77joRmVSByzsV6CoiZ4ac4wygu/c6ItJKRF4Muo4rRGRsaQcuJqXSyCvrYRHZ\nKiKTi3nPjSKyVEQOedd0hoi08F7rAfzH2zXb+3s/XsK5GojIk0HXZaGInB70eqAmf7Z3viMi8omI\ndC/HNTsc8u9vu3MuK1BG77jfF5EF3r/DcSLyU+/zjBKRTCAHSBWRGBG517uuOSLyhYgMCypnsccr\nRxmNxwK4v9wPPAJ0Bd4E6gOLgO8BPYAngedEZFAZx7keOACcAfwc+CVweRnvuR34DOgLPAY8JiLp\nACJSF3gVOAj0ByYCf6T0f19vAYeBUYENIlIHuAp4PujzdgQuBrp4x91RRjkLOOeWAF+inzfYDcAK\n59xn3noD4GP0OvYEngL+JSIDynsutOZ6JnAZcBEwFEgP2acu8GugFzAS6AA85722GviB97w9+ivs\n1yWc669eWccB/YDvgLdFpGnIfvcBtwAZwHFgegU+T2n+DDyE/jt829vWBJiM/uLpAewE7gB+AtyK\nfub3gddEpFM5jmfKwzlnSy1ZgNH6JzlhexfAATeV4xhzgceD1mcDLwWtLwLmhbxnQch7FgEPBa1v\nB54Jec8m4Hbv+QjgGNAi6PWhXpmvKqWsfwPeDVo/Hw00Lbz1d4AnT/Ka/hTIAhK89Qbe+i1lvO91\n4NGg9ZfQlMsJ60AykAuMCHq9KZp6eLyUc2R416ixt36ptx4fsl/wuZoDecCooNfjgK3AlJDjDAza\n5yJvW5NSyrPY+zseClmu8V7v4R3jR8VcYwd0Dtom6C/K24o5x99LO54t5V+sBu4vi4NXRKSuiNzl\n/eTfKyKH0JpZahnHWR6yvhVocRLv6QKsd87tDHr90zKOB1rTHioigZz/ODSgB47zBHCt99P7gXL8\nsijpHLHAFd76FWjAC9TyEZFYEfl9yHW8iLKvY0AnIAb4JLDB6X2ENcE7icgAEXlDRDaKyEHgf95L\naRX4PJ3QXzYfBZ3rGPrrqFvIvsF/s63eY1l/52lAn5BlTsg+i0PfBBxyzgV/3lZA4+ByehYWU87i\njmfKwQK4v4TecPsNcBPwJ2AI+p/tTTRAlSb0JpGj7H8LlXlPqZxzHwPrgatEW16MIiiwOudeRYPb\nY2hAeFtEnqzgOfYDr1CYRrkBmOuc2xO02++AH6Npn8B1fJuyr2O5eemN/6KphavR2vdI7+WqOk/o\n0KLHi3mtrL/ZfufcupAlK2Sf4m78VuRmcGg5K3Uj2VgA97tBwBzn3Ezn3JfAt2gNraatBtJEJDlo\nW/9yvncGWvO+DP33ODf4RefcTufcs865H6D51Bu9XHlFTAUGi8j3gMHeerBBaJpplncdv6Ni1/Fr\nIB8oyJmLSFLIMXqiNdJfOucWerXVliHHOeY9xpRxrjxgYNC54tDrvaoCZa5u29D7LANDtg+idpXT\n16wZob99DXzPa2WxH7gNaA1sqOFyvAFsRG+gTgEaojcgHSfWtkI9D/wWuBP9MiposiYif0Tz8auA\neuiN1jXOa57mtcw46Jz7YRnn+BD4BvgXWuN/P+T1r4Fh3k3LLPSGbYq3vUzOuV0iMhN4RESygN1o\nbT64Gd13aJ78ZyIyDejtfeZg673HS0XkA+CIC2nm6JzbLdo34BEvDbMFvdkZjzZBPVkJIhL6xZLj\nnNtXkYM455xoS6Y7RWQjsAJtz94L/QViqoDVwP3tLjTP+S4apHaiN7xqlHMuF72R2QT4HK3h3uO9\nfLSM937tvacXQekTz3G0hcJyYD5aMx0V9Hp7oF05yufQ3G4SMM1bD/Zb9EviPeADYDMhvwTK4afe\n53gT/Xv8D1gSVIaNaAD7AZAJ/AJtARRczq/RL76/oK1t/lzCuW7xzjMLWIq2ZrnIVU37/Z+itefg\nZVYlj/UntGXUX9AAfj4w3PucpgrIif+WjTl5XlvrRUAP59xX4S6PMZHIAripEiJyBbAPWAecCjyK\npgDOCGvBjIlglgM3VaUx+pO5LbAHzTPfFtYSGRPhrAZujDE+ZTcxjTHGp2o0hdK8eXPXvn37mjyl\nMcb43pIlS3Y755JDt9doAG/fvj2LF1uvWWOMqQgRKbZvh6VQjDHGpyyAG2OMT1kAN8YYn7J24MZE\niOPHj7N582aOHi119AJTi8XHx9O2bVtiY2PLtb8FcGMixObNm2nYsCHt27dHCmfIMz7hnGPPnj1s\n3ryZDh06lOs9lkIxJkIcPXqUZs2aWfD2KRGhWbNmFfoFZQHcmAhiwdvfKvr380cAf+MNuP/+cJfC\nGGNqlTIDuIhME5GdIrIyaFsfEVkkIstEZLGIlHf2lcp57z24916wcVuMqbX27NlDnz596NOnDy1b\ntqRNmzYF68eOHSv7AMB1113HmjVrSt3niSeeYMaMGVVRZAYNGkTnzp0LynnllVdWyXFrSnluYj4L\nPA5MD9r2APB759xbInKJt35ulZcuIDUVDh+GffugadNqO40xpvKaNWvGsmXLALj77rtJTEzk9ttv\nL7JPwWzqdYqvOz7zzDNlnuemm246+cIGeeGFF+jTp0+Jr+fm5lK3bt0S18v7vupQZg3cOTcfCJ3p\nwwGNvOeNKZzxunqkeZN2b9xYracxxlS9devW0a1bN8aNG0f37t3Ztm0bEydOJCMjg+7du3PPPfcU\n7Dto0CCWLVtGbm4uTZo0YcqUKfTu3ZszzzyTnTt3AnDnnXfy6KOPFuw/ZcoU+vfvT+fOnfn4448B\nOHz4MN///vfp1q0bo0ePJiMjo+DLpTzGjx/PpEmT6N+/P3fccQd33nknEyZMYODAgVx77bVkZ2dz\nzTXX0LNnT9LT05k/fz4AU6dO5fLLL2fIkCFcdNFFVXUJS1TZr4db0RnCH0K/BM4qaUcRmQhMBEhN\nTa3c2QLv27ABSvmmNMZ4br0VKhCwyqVPH/ACZ0WtXr2a6dOnk5GRAcD9999P06ZNyc3NZciQIYwe\nPZpu3boVec+BAwc455xzuP/++7ntttuYNm0aU6ZMOeHYzjk+++wzXnvtNe655x7++9//8te//pWW\nLVvy8ssv8+WXX5Kenl5i2a688krq168PwLBhw7jfu9+2bds2Fi1aRJ06dbjzzjtZvXo18+fPJz4+\nnj//+c/Uq1ePFStW8NVXX3HJJZewdu1aAL744guWLVtGUlJSpa5VRVT2JuYkYLJzrh0wGXi6pB2d\nc0855zKccxnJyScMplU+gQBuNXBjfOnUU08tCN4As2bNIj09nfT0dDIzM1m16sSJ6uvXr8/FF18M\nQL9+/Vi/fn2xxx41atQJ+yxcuJCrrroKgN69e9O9e/cSy/bCCy+wbNkyli1bVhC8Aa644ooiqZ4R\nI0YQHx9fcPzx48cD0L17d1q3bs26desAuPDCC2skeEPla+DXoBOrAvwbncS2+iQnQ3y81sCNMWWr\nZE25uiQkJBQ8X7t2LY899hifffYZTZo0Yfz48cW2fY6Liyt4HhMTQ25ubrHHrlevXpn7nGyZi1sv\n7/uqU2Vr4FuBc7znQ4G1VVOcEohoLdxq4Mb4XlZWFg0bNqRRo0Zs27aNt99+u8rPMXDgQF588UUA\nVqxYUWwN/2QMHjy4oCVMZmYm27Zt47TTTqvSc5RHmTVwEZmFtjBpLiKbgbuAHwKPiUhd4Chejrta\nWQA3JiKkp6fTrVs3unTpQlpaGgMHDqzyc9x8881MmDCBbt26FSyNGzcudt/gHHhKSkq5vlBuvvlm\nfvSjH9GzZ09iY2OZPn16kV8MNaVG58TMyMhwlZ7Q4cYbtUPPtm1VWyhjIkRmZiZdu3YNdzFqhdzc\nXHJzc4mPj2ft2rVceOGFrF27ttqb9VWF4v6OIrLEOZcRum/t/zQBqamwfTvk5ICX8zLGmOIcOnSI\n8847j9zcXJxz/OMf//BF8K4o/3yiQFvwzZvh1FPDWxZjTK3WpEkTlixZEu5iVDt/jIUCRduCG2OM\n8WEAtxuZxhgD+CmAt22rzQktgBtjDOCnAF6vHrRsaSkUY4zx+CeAg7UFN6YWGzJkyAltqB999FEm\nTZpU6vsSExMB2Lp1K6NHjy52n3PPPZeymiA/+uijHDlypGD9kksuYf/+/eUpeqnuvvvuIkPj9unT\np0qOWxX8FcDT0iyAG1NLjR07ltmzZxfZNnv2bMaOHVuu97du3ZqXXnqp0ucPDeBvvvkmTZo0qfTx\ngk2ePLlgvJRly5adcNzQLvzl7dLvnCM/P7/S5fJXAA/UwG1iB2NqndGjR/PGG28UTN6wfv16tm7d\nyuDBgwvaZaenp9OzZ09effXVE96/fv16evToAUB2djZXXXUVXbt2ZeTIkWRnZxfsN2nSpIKhaO+6\n6y4A/vKXv7B161aGDBnCkCFDAGjfvj27d+8G4OGHH6ZHjx706NGjYCja9evX07VrV374wx/SvXt3\nLrzwwiLnKcuzzz7L8OHDGTp0KOeddx4ffvghgwcPZvjw4QUjK5Z03s6dOzNhwgR69OjBpk2bKnSd\ng/mnHThoAD96FHbtghYtwl0aY2qtcIwm27RpU/r3789bb73FiBEjmD17NmPGjEFEiI+PZ86cOTRq\n1Ijdu3czYMAAhg8fXuIckE8++SQNGjQgMzOT5cuXFxkO9r777qNp06bk5eVx3nnnsXz5cn72s5/x\n8MMPM2/ePJo3b17kWEuWLOGZZ57h008/xTnHGWecwTnnnENSUhJr165l1qxZ/POf/2TMmDG8/PLL\nBaMMBnvkkUd4/vnnAUhKSmLevHkALF26lOXLl9O0aVM+/PBDli5dysqVK+nQoUOZ533uuecYMGBA\nRf8MRfirBh7ozGM3Mo2plYLTKMHpE+ccd9xxB7169eL8889ny5Yt7Nixo8TjzJ8/vyCQ9urVi169\nehW89uKLL5Kenk7fvn356quvyhyoauHChYwcOZKEhAQSExMZNWoUCxYsAKBDhw4Fs/GUNmRtcAol\nELwBLrjgApoGzRLWv39/OnToUOZ509LSTjp4gx9r4KBplNNPD29ZjKnFwjWa7IgRI5g8eTJLly7l\nyJEj9OvXD4AZM2awa9culixZQmxsLO3bty92CNmyfPfddzz00EN8/vnnJCUlce2111bqOAH1gobl\niImJqVAKBcI/5Ky/auDWmceYWi0xMZEhQ4Zw/fXXF7l5eeDAAVq0aEFsbCzz5s1jQxm/os8++2xm\nzpwJwMqVK1m+fDmgQ9EmJCTQuHFjduzYwVtvvVXwnoYNG3Lw4METjjV48GDmzp3LkSNHOHz4MHPm\nzGHw4MFV8XFLVRPn9VcNPCkJEhMthWJMLTZ27FhGjhxZpEXKuHHjuOyyy+jZsycZGRl06dKl1GNM\nmjSJ6667jq5du9K1a9eCmnzv3r3p27cvXbp0oV27dkWGop04cSLDhg2jdevWRdIc6enpXHvttfTv\n3x+AG2+8kb59+5aYLilOcA4cYO7cuWW+pyrOWxb/DCcb0L07dO4Mr7xSNYUyJkLYcLKRoSLDyfor\nhQLWmccYYzz+C+BpaZZCMcYY/BjAU1Nh924I6nFljFE1mRI1Va+ifz9/BnCAk+i9ZEwkio+PZ8+e\nPRbEfco5x549e4iPjy/3e/zVCgWKdubp3Dm8ZTGmFmnbti2bN29m165d4S6KqaT4+Hjatm1b7v39\nF8CtLbgxxYqNjS3oBWiig/9SKK1bQ506FsCNMVHPFwH8lVfgt7/1VmJjoU0ba4lijIl6vgjgH38M\nDz0EeXneBmsLbowx/gjgnTvrKLIFMTs11Wrgxpio54sAHhg2Yc0ab0NaGmzeHFQlN8aY6OOLAB5o\nLbh6tbchNRWOH4dSxhM2xphI54sAnpwMTZoE1cADTQktjWKMiWK+COAimkYpkkIBu5FpjIlqvgjg\noGmUIikUsABujIlqvgngXbrAtm2QlQU0agSNG1sKxRgT1XwTwAM3Mr/+2tuQlmY1cGNMVPNdAC+S\nRrEAboyJYr4J4KeeCjExITcyLYVijIlivgng9epBhw4hNfD9+72kuDHGRB/fBHDQNMoJbcFtYgdj\nTJTyVQDv0gXWrvV60AdP7GCMMVGozAAuItNEZKeIrAzZfrOIrBaRr0TkgeorYqEig1pZW3BjTJQr\nTw38WWBY8AYRGQKMAHo757oDD1V90U5UZFCrli2hbl2rgRtjolaZAdw5Nx/YG7J5EnC/cy7H22dn\nNZTtBIGmhGvWoE1S2rWzGrgxJmpVNgfeCRgsIp+KyP9E5PSSdhSRiSKyWEQWn+xkq4FBrawtuDHG\nVD6A1wWaAgOAXwAviogUt6Nz7innXIZzLiM5ObmSp1MnDGplEzsYY6JYZQP4ZuAVpz4D8oHmVVes\nkhUZ1CotDbZsgdzcmji1McbUKpUN4HOBIQAi0gmIA3ZXVaFKU2RQq9RUyM+HrVtr4tTGGFOrlKcZ\n4SzgE6CziGwWkRuAacApXtPC2cA1zjlXvUVVRQa1sokdjDFRrG5ZOzjnxpbw0vgqLku5BA9qlZFh\nEzsYY6KXr3piQsigVu3a6UYL4MaYKOS7AB4Y1GrNGiAhAZo1sxSKMSYq+S6Ag97ILNISxWrgxpgo\n5MsA3rmzDmqVn4915jHGRC3fBvAig1pt2AA10wjGGGNqDV8G8MCgVqtXoymUQ4d0cgdjjIkivgzg\nRQa16tBBV9auDVt5jDEmHHwZwIsMatW3r25cujSsZTLGmJrmywBeZFCrtDRo2hQWLw53sYwxpkb5\nMoBD0PyYIpCRAUuWhLtIxhhTo3wbwLt00TGssrKAfv1g5UptmmKMMVHCtwG8yKBWGRk6pOzy5WEt\nkzHG1CTfB/A1a9AaOFge3BgTVXwbwAODWq1ejXbmad7c8uDGmKji2wBeZFArEa2FWwA3xkQR3wZw\nCBnUKnAjMzs7rGUyxpia4usAXmRQq4wMyMuzG5nGmKjh+wBeMKiV3cg0xkQZXwfwIoNatWunfewt\nD26MiRK+DuBFmhIGbmRaDdwYEyV8HcADg1qtWeNtyMiAVavsRqYxJir4OoAHBrUq0hIlLw++/DKs\n5TLGmJrg6wAOQYNagdbAwdIoxpio4PsAXmRQqzZtoEULu5FpjIkKvg/g3brp4/Ll2I1MY0xU8X0A\nP/NMffzoI29D4EbmkSNhK5MxxtQE3wfw5GRNoyxc6G3o10+7Zi5bFtZyGWNMdfN9AAcYNEhr4AVd\n6sHy4MaYiBcxAXzfPsjMBFq3hpQUC+DGmIgXMQEcvDRKYI5Mu5FpjIlwERHATzkFWraEBQu8Df36\naXX88OGwlssYY6pTRARwEa2FF9zIzMiwG5nGmIgXEQEcYPBg2LABNm2icGhZy4MbYyJYxATwQB78\no4/QG5ktW1oe3BgT0SImgPfqBYmJIWkUq4EbYyJYxATwunW1V2aRG5mrV8OhQ2EtlzHGVJeICeCg\naZQVK2D/fuxGpjEm4pUZwEVkmojsFJGVxbz2cxFxItK8eopXMYMGgXPwySfYjUxjTMQrTw38WWBY\n6EYRaQdcCGys4jJV2hlnaCpl4UKgVSu9mWk3Mo0xEarMAO6cmw/sLealR4BfAq6qC1VZCQmQnh4y\nsJXVwI0xEapSOXARGQFscc7VurnLBg2Czz6DnBw0D756NRw8GO5iGWNMlatwABeRBsAdwO/Kuf9E\nEVksIot37dpV0dNV2KBBcPSoV/Hu10+T4nYj0xgTgSpTAz8V6AB8KSLrgbbAUhFpWdzOzrmnnHMZ\nzrmM5OTkype0nAYO1MeFCykcWnb+/Go/rzHG1LQKB3Dn3ArnXAvnXHvnXHtgM5DunNte5aWrhBYt\noFMnL4CnpGjj8H//O9zFMsaYKleeZoSzgE+AziKyWURuqP5inZwiEzyMGQNffhk0db0xxkSG8rRC\nGeuca+Wci3XOtXXOPR3yenvn3O7qK2LFDR4Me/fq/UuuuEI3Wi3cGBNhIqonZkCRCR7atNENL7wQ\n1jIZY0xVi8gAfuqpmv4uGBdlzBhYuVJnqzfGmAgRkQH8hAkeRo/WjZZGMcZEkIgM4KABfP162LwZ\n7VZ/9tnw4ovhLpYxxlSZiA7g4E3wAJpGWbVKUynGGBMBIjaA9+mjY6MUpFG+/32oU8dq4caYiBGx\nAfyECR5SUuDcczWAu1oz/pYxxlRaxAZw0DTK8uVw4IC3YcwY7dCzYkVYy2WMMVUh4gO4c/Dxx96G\nUaMgJsbahBtjIkJEB/ABAzQP/sor3obkZBg61NIoxpiIENEBPCFBsyazZwfNbTxmDKxbZ0PMGmN8\nL6IDOMANN2jwLmh8MnKk3uG0NIoxxuciPoCfdRZ06QJPB4bgatYMzj/f0ijGGN+L+AAuorXwjz+G\nzExv45gx8N13Nl+mMcbXIj6AA0yYoFmTglr45ZdDbKx16jHG+FpUBPAWLeCyy2D6dDh2DEhKggsu\nsDSKMcbXoiKAA9x4I+zaBa+/7m248krYsEGnsDfGGB+KmgB+0UU6t0NBGmX4cIiLg5kzw1ouY4yp\nrKgJ4DExcO218N//ekPMNmmi44RPnQo7d4a7eMYYU2FRE8ABrr9eJzp+9llvw113wdGjcP/94SyW\nMcZUSlQF8FNO0Z7006Z5M9Z36gTXXAN/+xts2RLu4hljTIVEVQAHbRP+3Xfw4Yfeht/9TqP5ffeF\ns1jGGFNhURfAR47U9PfUqd6G9u01qk+dqnOwGWOMT0RdAK9fH8aN0xEK9+3zNv7mNzpbzx/+ENay\nGWNMRURdAAdtE56TAzNmeBvatoVJk+C55+Drr8NaNmOMKa+oDOB9+kB6elCbcIApU6BePfj978NW\nLmOMqYioDOCgae9ly2DpUm9DSgr87Gcwa5bNXG+M8YWoDeBXXw3x8fDkk0Ebb78dEhPh7rvDVSxj\njCm3qA3gTZpox55nntF5jgEdK/y22+Dll4Oq5sYYUztFbQAHbQJevz78+tdBGydP1tEKf/e7sJXL\nGGPKI6oDeEoK/OpXMGcOLFzobWzcGH75S3jjDfjkk7CWzxhjSiOuBsfDzsjIcIsXL66x85XH4cPQ\nsSOkpemsPSLexlNOge7d4f33vY3GGBMeIrLEOZcRuj2qa+CgM9f/4Q+waJGmvgs23nUXzJsH//pX\nWMtnjDElifoaOEBeHvTurQMTrlqlw4STnw9nn60bMjM132KMMWFgNfBSxMTAAw/AN9/A3//ubaxT\nR8dHOXIEfvrTsJbPGGOKYwHcc/HFOtTsPffAgQPexi5dNJXy0ks6eIoxxtQiFsA9IvDgg7BnT8j8\nDrffrn3vf/KToNGvjDEm/CyAB0lP15EKH30UNm3yNsbG6gwQu3drJx9jjKklygzgIjJNRHaKyMqg\nbQ+KyGoRWS4ic0SkSfUWs+bcd5/ev/ztb4M29u2rDcaffRbeeSdcRTPGmCLKUwN/FhgWsu1doIdz\nrhfwNfDr0Df5VVqajmk1fTp8+WXQC7/9rebEJ06EQ4fCVj5jjAkoM4A75+YDe0O2veOcy/VWFwFt\nq6FsYXPHHTpWym23QUEry/h4bZWycWNI33tjjAmPqsiBXw+8VdKLIjJRRBaLyOJdu3ZVwemqX1KS\nplI++AAeeyzohYEDtUnhE08E9b03xpjwKFdHHhFpD7zunOsRsv03QAYwypXjQLW1I09xnNP5M998\nU7vYZwSa0B86BD16aI3888+hYcOwltMYE/mqvCOPiFwLXAqMK0/w9hsRbXzSsiVcdRVkZXkvJCbq\nVD7r1sFll2lHH2OMCYNKBXARGQb8EhjunIvYCNa0KcycqZPV//jHQfnw887Tu5wLFsCIEdoH3xhj\nalh5mhHOAj4BOovIZhG5AXgcaAi8KyLLROTvpR7ExwYN0mkyZ83SyR8KXH21VtHffx9GjdJZko0x\npgbZYFblkJcHF16ow4MvXgzdugW9+M9/atPCESPg3//Wjj/GGFOFbDCrkxATA88/r+nvK6+E7Oyg\nF3/4Q3j8cXj1Va2V5+aWeBxjjKlKFsDLqVUrHRp85Uqdda2Im26Chx/WQa+uuUar7MYYU80sgFfA\nRRfpbGv/+IdmS4qYPBn+9Ce963njjdof3xhjqpEF8Aq691444wyN0SdMmTllCtx9t46Zcvrp8Pbb\nQU1XjDGmalkAr6DYWHjhBWjRAoYM0edF/O53MGMG7N0Lw4bBuedqTyBjjKliFsArIS1Na9+nn66d\nfP74x6CKtojezFyzRm9urlmjXfAvuwyWLw9ruY0xkcUCeCU1bw7vvaex+je/gRtugGPHgnaIi9Ob\nm998oxF+4UKdGOLqq+Hbb8NWbmNM5LAAfhLq1dPmhXfdpZ18hg0rZtKehAQdvfDbb3VM8blzdSyV\nBx6wJofGmJNiAfwkieh9y2GOiV8AABFCSURBVOnTtZJ91lklVLCTkrSVytdfa6+gX/0K+veHpUtr\nusjGmAhhAbyK/OAH8O67sGOHtlJ5990SdmzbFubM0Tbj27ZpIv322+Hw4RotrzHG/yyAV6FzzoFF\niyA5WSvZP/pR0CiGwUTg+9+HzExtj/h//wc9e9p0bcaYCrEAXsU6ddKsyC9+oRP49OxZSm28SRPt\nFfS//+lNz4sugvHjYfv2Gi2zMcafLIBXg/h4vUf50UdQv34ZtXGAs8+GZct03s1//xs6d9apgOwm\npzGmFBbAq9GAAfDFF+WsjcfHwz336GArZ54Jt94K6ek65rgxxhTDhpOtIYsWwbXXar+ebt10ZMOE\nBGjQQB8DS58+cN21jjqvzdUgvnGjplUefFCnBzLGRJ2ShpO1AF6DsrM1Di9bpo1OjhzRx8By6BAc\nOKCdNp97DpLqHdFOQA8+qDX03/wGvvc96NJFx7g1xkQFC+A+4Jz2vv/5z6FNG02HZ2QAa9fCzTfr\n4Fig1fa+ffXFfv30sVMnC+rGRCib0MEHRDROL1igo9EOHAh/+xu40zrCW29ps8Pp03USCdDZgCZM\n0JxMUpKORb5woY2AaEyUsBp4LbVnj3YOeustHTDrqaegYcOQnfLyYPVqnedtwQJ48UU4eBC6dtX2\n5RMm6KAtxhhfsxq4zzRrBq+/Dvfdp3H59NO1gUoRMTHQvbvWvKdO1Z6dTz8NjRsX5mHGjoUPPrAJ\nJoyJQBbAa7E6deCOO3TUw/37NYjfeits3VrCGxIS4PrrdazbFSvgxz/WvPl552nO/M03Lb1iTASx\nAO4DQ4Zoe/KrrtKbnKecAj/9KWzaVMqbevTQzkBbtugMQYcOaQuWc88tZiohY4wfWQD3iVatdMja\nr7/W1PZTT8Gpp2ole/36Ut5Yv76mWDIz4YkntCH6WWfB5ZfDV1/VVPGNMdXAArjPnHKKBu9167Qx\nyjPPQMeOOqHE4sWlZEji4uAnP9E3/uEPMG8e9OoF112ngdy67RvjO9YKxee2bNFxV556Co4e1WB+\n9dV677Jz51LeuHu3jk/+xBOQkwN160L79nqAjh3htNP0sUsXnUNOpKY+kjEmhHXkiXD79sErr8DM\nmVq5dk6HUrn6arjySh2GvFibNukALevWaYehwGPw+OSpqTB0aOHSpk2NfCZjjLIAHkW2btWmhzNn\nwuefa+X5zDPh0ku1m3737mVUqJ3TmSnWrtWJmOfN02XvXn29Uydt2TJ0KFxwgTZbNMZUGwvgUWrt\nWpg1C157DZYs0W1paRrML71UG6XEx5fjQPn5Gsw/+ECX//1PW7bExmogHzkShg/Xu63GmCplAdyw\nZYs2BX/9dc2aZGdr0/G+fTWI16unS1xc4WOzZtrqpWvXkIMdPw6ffaaTNM+ZA998o9X6AQM0mI8c\nqXl0Y8xJswBuisjOhg8/hP/8R1sY5uTocuxY0cc9ezRWDxsGkydrxuSE9Itz2pJlzhxdvvhCt/fu\nDePGaQP2du1q+iMaEzEsgJtK2blTZ3174glNi3frpr1Bx4/XJubF2rBBA/msWVpLF9FZh8aN07lA\nmzat0c9gjN9ZADcnJScHXngBHnlExzNv1kynibv4Yk3BJCSU8MZ16/Ru6owZ2gspNhYuuUST7zEx\nhQ3Xg/8d1q8PgwdrE0ZrvmiMBXBTNZyD+fM1kL/2mq7XqaOxtl+/wuHJ+/QJCerO6WzPM2dqzXzb\ntrJP1qYNnH++LuedZzdITdSyAG6q3Pbt2kxx8WJt4bJkiW4DDeqnnw4jRmiv/SKV6fx8bZIY2BD6\nuGePNlt87z14/31dB23/OHSodjhKStJUTOAx8LzEvI4x/mUB3NSIrVs1kH/+uY5lHvhzd+xYGMwH\nDKjA5EH5+Zqzee89XRYs0C6nJenXT5P0Y8ZoMxpjIoAFcBMWmzdrS5e5c7VSffw4JCdrirtFC33e\nvHnRpXXrUuZvzs/XSSv27tXup/v2FT7fsUNTNKtXa7rlpps0UW+TWhifswBuwu7AAfjvfzWYL1um\nw7Hs2VP8AFxpaTBokE4rN2iQZk/qlGfotfx8eOcdTdK/8442cP/BD+CWW/Qg+fmwa5c2it+yRb9h\ntmyBrCwdKaxTJ13at9fxYYypBSodwEVkGnApsNM518Pb1hR4AWgPrAfGOOf2lVUIC+AmVF6eTlax\ne7cuu3bp8Lgff6zZkkBOvUkTHQX3rLN0XJekpBOX+vX1yyArSyvlez//hr3T/8Oed79g7/FEUprm\nMiLrX8TmZhctREyMThR98GDhttjYwoDesaPeUG3ZElJS9LFlSz1pub5VjDk5JxPAzwYOAdODAvgD\nwF7n3P0iMgVIcs79qqxCWAA3FeEcfPedztMcWDIzS94/Lk5HxS1t9rg2DQ9w85CvmHjFPpI6t9DA\nnJKigXjPHm3qGLqsXVt83r1uXX1vly7Qvz+ccYYuJeZ/jKmck0qhiEh74PWgAL4GONc5t01EWgEf\nOudKG7wUsABuTt6BA1pL37dPa+6BNHhgiYsrbJTSrFnRBipLlsDDD2vDlgYNdCj0W27RCnapnNMT\nb9+uefbgx23bdIyY5csLx1RPTS0M6BkZ2iM1Kanar42JXFUdwPc755p4zwXYF1gv5r0TgYkAqamp\n/TZs2FDZz2BMlVi+XFPkM2fqTdVLL4VJk3S8l9atS2+8kp+vHU2/+konmc7M1JmRxo8+yin7lmjP\n008/1SV4qqR27XQCjd69Cx87dqxAcxwTzaotgHvr+5xzZVYxrAZuapPt2+Fvf4Mnn9T8e0BKiubZ\nA0uLFhqLV66EVauKDpXesqVWxp3TG64TJsAVV3gV7p07tfPS8uXw5Zf6mJmpiX/QG6w9ehQN6r16\nWW3dnMBSKMaUIDtbb5hu2qSNUkKX/fs1qPfooQ1ZAo/du+tQ6Js26UgB06drfI6L03HXJ0zQCalj\nYjTFLgJyLAfJXIWsXEHMimXICi+4B3+DtGunJ2neXLuzJiae+JiSoi1lUlPLOR5wyY4fh+efh+ee\n09MOHw7nnKMjUobLunU6auagQZqFinZVHcAfBPYE3cRs6pz7ZVnHsQBu/OjYsfL1CQqMFvCvf2l6\nZteu0vcPzGJ32mmO01od4bS4jZyas4rTdn1Ch03zqZe1S6v7hw7pt0xJWrYkP60D+1p1Y3fzLjRM\naUDrRoe0QIElUEARDfj163O8bn2eX9yFe+f24NsdCXRse4Qtu+I4klOXhvVyuKjtKoY3/5hLYt+l\n2YFvoUMHHY7yggu0dU4Vj1OzY4eOtzNjhmaiQK/700/r4GnR7GRaocwCzgWaAzuAu4C5wItAKrAB\nbUa4t6xCWAA30eL4cW2GvnJl0TgavBw5At9+q7XNdeu0+WOwxERo2BAaNYKGDR2NEvJoGJ9Lw3rH\nyD6Qw+4deezaE8Pug/XYk5NAnivMp3fjKy7kHS7ibc5mPg0o/AI4Tl2eZzz3ciffcirpLOFu7uZS\nXuco8XzAUF5jOP+R4WxzrahDHoOaZjIk/30y9r9LBotp2S5Ox6i54AJ9TE6u1HU6eFAHrpwxQzva\n5ufrODpXX61DGN9yi3YAu+MOnYs7WlttWkceY2ox5zSLsm6dzo3x7beausnK0iB38GDh86wsbfPe\nvLnGzUBv1uRkSG6Wz7aNx3nngxjmfxTD0aNCvXqOwQMdF12QT6OGjgf+rw7ffBdDeo8c7p60k0sH\n7EaOZuuQk0lJmvRv3pz8unEsWaI9af/zH03hB5potqm/h4zcRWQc/4QMFnN66k6atYnX96ak6BJ4\n3qqV/tRo1QpiYsjJ0WEWZs7UNEl2tr589dU64nC3boXX5dgx7VA7daqORDx9urYgijYWwI2JMoHc\n/ttvF/4aAJ3s+u67tfVNRbIghw5pD9rFiwOLY82awgN0bbCBQfU+Z1Duhww6+BYd+JbAq3nUYV7M\nBcxscCOvZA/jQG4iyQmHGTNwC1cP28eZ/fOQRg31J0dgiYuDQ4dw6zfwyKPC7dO6kt5iM6+efi9t\ndnyh32ZxcdrpKi6u6NKggd5LSE0tfExN1W85Hw5RbAHcmCgXGDmgf/+qi2FZWdq+/tNPtaPVRx/p\nLweAVil5DOx1iOZxB5izoDk7shrQsO4RRjX+gLHHp3Ne1ivUJa/kg8fGai7K8zrfYyyzaBRzhP+c\nfg/p7Xbp68eO6eI9dznHyMs6TN0tG068dxAfr21F69fXmxDFLY0bFw7MEzpYT+AnT0V+Bjin9zIC\nXy6VYAHcGFPt8vO1qWVw79nt27W2P3aszuVRMOLvoUOwcaN2kgrOEQUvTZpofsVblm9vwWUj6rBr\nl6ZWsrMLh2EIXnJyoG5dR0IDR4O4PBJic0iok02CO0yDvIMk1MmmQZ2jNKiTTQM5SgPJpgFHaMAR\n4nMOEHd4H/UO7aGey6YeOdQjhziOkcBhGpFF4/rHaZRcj8QWDaiT4gX1xETy9x1g+3bYsCOejXsT\n2XigMRuOJLPRteXevyfT60dnVuq6WgA3xoRFXl7V9lfasUPb2i9YoCn74ka0TEzU4H74sN4sPny4\n6JKdrduDl5ycipdFyKdRjAb1Ovl5bHUtOU7RWnaTetmkNj3I44/kMvjK1pX6zCUFcBtuzRhTraq6\ns2lKis4KlZtbtQNG5uUVBvLgib2D1w8f1h8MWVn6eOBAHbKyGnLgQENyc7XjV1paYco9NRUaNaoP\nVM9EIxbAjTG+VNWj/cbEFN4/9YsobVVpjDH+ZwHcGGN8ygK4Mcb4lAVwY4zxKQvgxhjjUxbAjTHG\npyyAG2OMT1kAN8YYn6rRrvQisgsdP7wymgO7y9wrutk1Kp1dn7LZNSpduK5PmnPuhEHXazSAnwwR\nWVzcWACmkF2j0tn1KZtdo9LVtutjKRRjjPEpC+DGGONTfgrgT4W7AD5g16h0dn3KZteodLXq+vgm\nB26MMaYoP9XAjTHGBLEAbowxPuWLAC4iw0RkjYisE5Ep4S5PuInINBHZKSIrg7Y1FZF3RWSt95gU\nzjKGm4i0E5F5IrJKRL4SkVu87XadABGJF5HPRORL7/r83tveQUQ+9f6vvSAilZuFN0KISIyIfCEi\nr3vrter61PoALiIxwBPAxUA3YKyIdAtvqcLuWWBYyLYpwPvOuY7A+956NMsFfu6c6wYMAG7y/t3Y\ndVI5wFDnXG+gDzBMRAYAfwYecc6dBuwDbghjGWuDW4DMoPVadX1qfQAH+gPrnHPfOueOAbOBEWEu\nU1g55+YDe0M2jwCe854/B1xeo4WqZZxz25xzS73nB9H/hG2w6wSAU4e81VhvccBQ4CVve9ReHwAR\naQt8D5jqrQu17Pr4IYC3ATYFrW/2tpmiUpxz27zn24GUcBamNhGR9kBf4FPsOhXw0gPLgJ3Au8A3\nwH7nXK63S7T/X3sU+CWQ7603o5ZdHz8EcFNBTtuGWvtQQEQSgZeBW51zWcGvRft1cs7lOef6AG3R\nX7pdwlykWkNELgV2OueWhLsspfHDrPRbgHZB6229baaoHSLSyjm3TURaobWqqCYisWjwnuGce8Xb\nbNcphHNuv4jMA84EmohIXa+WGc3/1wYCw0XkEiAeaAQ8Ri27Pn6ogX8OdPTu/sYBVwGvhblMtdFr\nwDXe82uAV8NYlrDz8pVPA5nOuYeDXrLrBIhIsog08Z7XBy5A7xPMA0Z7u0Xt9XHO/do519Y51x6N\nOR8458ZRy66PL3piet+CjwIxwDTn3H1hLlJYicgs4Fx0aMsdwF3AXOBFIBUdsneMcy70RmfUEJFB\nwAJgBYU5zDvQPHjUXycR6YXehItBK3IvOufuEZFT0IYCTYEvgPHOuZzwlTT8RORc4Hbn3KW17fr4\nIoAbY4w5kR9SKMYYY4phAdwYY3zKArgxxviUBXBjjPEpC+DGGONTFsCNMcanLIAbY4xP/T8wyaBC\nsezF0gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FpSktO3hsFvd"
      },
      "source": [
        "### Testing Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-MESF4QjsFve",
        "outputId": "b992a209-9757-4932-e35e-ef78bf31e8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "Test_Error=[]\n",
        "with tf.Session(graph=lstm_graph) as sess: \n",
        "    # Restore\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-conn_beg'))\n",
        "    test_batch_features,test_batch_y=batch_features_labels(X_Test_Full,Y_Test_Full,batchsize)\n",
        "    #---------------------shuffle minibatches X and Y together-------------------------------------\n",
        "    #combined = list(zip(shuffled_batch_features, shuffled_batch_y))\n",
        "    #random.shuffle(combined)\n",
        "    #shuffled_batch_features[:], shuffled_batch_y[:] = zip(*combined)\n",
        "    #===========================================================================================\n",
        "    print(len(test_batch_features))\n",
        "    \n",
        "    for i in range(0,len(test_batch_features)):\n",
        "        batch_features_test=test_batch_features[i]\n",
        "        #print(batch_features)\n",
        "        batch_y_test=test_batch_y[i]\n",
        "        batch_features_test=np.delete(batch_features_test, [0], axis=2) \n",
        "        #print('X',len(batch_features[0]))\n",
        "        #print('Y',len(batch_y[0]))\n",
        "        Test_Batch_error,y_predict_test,summary=sess.run([Error,outputs,merged_summary_op],\n",
        "                                             feed_dict={\n",
        "                                                 keep_prob:keep_prob_testval,\n",
        "                                                 X: batch_features_test,\n",
        "                                                 y: batch_y_test})\n",
        "\n",
        "        #print('error:',Train_Batch_error[0])\n",
        "        Test_Error.append(Test_Batch_error)\n",
        "\n",
        "    Sum_test=np.sum(Test_Error,axis=2)\n",
        "    Sum_test_1=np.sum(Sum_test,axis=1)\n",
        "    Sum_test_2=np.sum(Sum_test_1,axis=0)\n",
        "    print('Sum_test shape:',Sum_test.shape)\n",
        "    print('Sum_test_1 shape:',Sum_test_1.shape)\n",
        "    print('Sum_test_2 shape:',Sum_test_2.shape)\n",
        "    Mean_test=Sum_test_2/(len(Test_Error)*batchsize*num_periods_output)\n",
        "    print(\"\\tRMSE Testing:\", (Mean_test)**0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from checkpoints-conn_beg/har.ckpt\n",
            "977\n",
            "Sum_test shape: (977, 128, 1)\n",
            "Sum_test_1 shape: (977, 1)\n",
            "Sum_test_2 shape: (1,)\n",
            "\tRMSE Testing: [10.41717877]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "15SGHOrMsFvg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}